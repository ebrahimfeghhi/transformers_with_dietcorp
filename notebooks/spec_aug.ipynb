{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def sorted_indices_by_euclidean_distance_torch(coords: torch.Tensor):\n",
    "    \"\"\"\n",
    "    coords: LongTensor of shape (N,2) with (row, col) pairs.\n",
    "    Returns: dict {i: LongTensor([i, j1, j2, ...])} with all N indices\n",
    "             sorted by distance from coords[i].\n",
    "    \"\"\"\n",
    "    N = coords.shape[0]\n",
    "    dist_dict = {}\n",
    "    # Convert to float for distance computation\n",
    "    coords_f = coords.float()\n",
    "    for i in range(N):\n",
    "        # compute vector differences\n",
    "        diff = coords_f - coords_f[i:i+1]         # shape (N,2)\n",
    "        dists = diff.norm(dim=1)                 # shape (N,)\n",
    "        order = torch.argsort(dists)             # indices sorted by distance\n",
    "        dist_dict[i] = order                     # LongTensor of length N\n",
    "    return dist_dict\n",
    "\n",
    "def build_distance_dict_torch(shape=(8, 8), traversal=None):\n",
    "    \"\"\"\n",
    "    shape: tuple (H, W)\n",
    "    traversal: optional list or tensor of length H*W giving (row, col) coords\n",
    "               in the order your 1D array uses. If None, assumes standard\n",
    "               row-major flatten.\n",
    "    Returns: dict from flat-index -> LongTensor of neighbors sorted by distance.\n",
    "    \"\"\"\n",
    "    H, W = shape\n",
    "    N = H * W\n",
    "\n",
    "    if traversal is None:\n",
    "        # build row‚Äêmajor coords\n",
    "        # coords[i] = (i//W, i%W)\n",
    "        rows = torch.arange(N, dtype=torch.long) // W\n",
    "        cols = torch.arange(N, dtype=torch.long) % W\n",
    "        coords = torch.stack([rows, cols], dim=1)  # (N,2)\n",
    "    else:\n",
    "        coords = torch.tensor(traversal, dtype=torch.long)\n",
    "        assert coords.shape == (N, 2), \"Traversal must be (H*W, 2)\"\n",
    "\n",
    "    return sorted_indices_by_euclidean_distance_torch(coords)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_dict = build_distance_dict_torch((8,8))\n",
    "savePath = '/home3/skaasyap/willett/outputs/'\n",
    "torch.save(dist_dict, f'{savePath}dist_dict.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "import torch\n",
    "import random\n",
    "\n",
    "def channel_specaugment_masks(\n",
    "    x,            # tensor [B, T, D]\n",
    "    num_masks, max_channels_to_mask,\n",
    "    dist_dict,\n",
    "    num_channels=64,\n",
    "    features_per_channel=2\n",
    "):\n",
    "    B, T, D = x.shape\n",
    "    device = x.device\n",
    "    masks = torch.zeros(B, D, dtype=torch.bool, device=device)\n",
    "\n",
    "    # build a [B, num_channels] of uniform weights\n",
    "    weights = torch.ones(B, num_channels, device=device)\n",
    "\n",
    "    # now sample *per-row*:\n",
    "    # starts1: [B, N], starts2: [B, M]\n",
    "    starts1 = torch.multinomial(weights, num_masks, replacement=False)\n",
    "    starts2 = torch.multinomial(weights, num_masks, replacement=False)\n",
    "    \n",
    "    # widths per mask, per sample\n",
    "    widths1 = torch.randint(0, max_channels_to_mask+1, (B, num_masks), device=device)\n",
    "    widths2 = torch.randint(0, max_channels_to_mask+1, (B, num_masks), device=device)\n",
    "    \n",
    "\n",
    "    # precompute feature-block offsets\n",
    "    off1 = [feat * num_channels for feat in range(features_per_channel)]\n",
    "    off2 = [features_per_channel * num_channels + feat * num_channels\n",
    "            for feat in range(features_per_channel)]\n",
    "    \n",
    "\n",
    "    for b in range(B):\n",
    "        # electrode 1\n",
    "        for start_ch, w in zip(starts1[b], widths1[b]):\n",
    "            w = int(w)\n",
    "            if w == 0: \n",
    "                continue\n",
    "            nearest = dist_dict[int(start_ch.item())][:w]\n",
    "            idxs = torch.tensor(nearest, dtype=torch.long, device=device)\n",
    "            for base in off1:\n",
    "                masks[b, base + idxs] = True\n",
    "\n",
    "        # electrode 2\n",
    "        for start_ch, w in zip(starts2[b], widths2[b]):\n",
    "            w = int(w)\n",
    "            if w == 0:\n",
    "                continue\n",
    "            nearest = dist_dict[int(start_ch.item())][:w]\n",
    "            idxs = torch.tensor(nearest, dtype=torch.long, device=device)\n",
    "            for base in off2:\n",
    "                masks[b, base + idxs] = True\n",
    "\n",
    "    # broadcast mask over time\n",
    "    return masks.unsqueeze(1).expand(-1, T, -1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 64] [128, 192]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1174267/2953208141.py:54: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  idxs = torch.tensor(nearest, dtype=torch.long, device=device)\n",
      "/tmp/ipykernel_1174267/2953208141.py:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  idxs = torch.tensor(nearest, dtype=torch.long, device=device)\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "random.seed(0)\n",
    "\n",
    "B, T, D = 5, 10, 256\n",
    "x = torch.randn(B, T, D)\n",
    "\n",
    "mask = channel_specaugment_masks(x, 2, 5, dist_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.where(mask[0,0])[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 100, 4])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 'cpu'\n",
    "B, P, C = 10, 100, 4\n",
    "mask = torch.zeros(B, P, C, dtype=torch.bool, device=device)\n",
    "mask.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n"
     ]
    }
   ],
   "source": [
    "Z, B, N = 5, 10, 8\n",
    "hi = torch.Tensor([random.randint(0, Z) for _ in range(B*N)]).reshape(10,8)\n",
    "for row in hi:\n",
    "    print(row.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[42] [18, 58] [0] [0, 1]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([186, 250])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "channel_specaugment_indices(3, 2, dist_dict=dist_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([18, 26, 19, 10, 17, 25,  9, 11, 27,  2, 20, 34, 16, 12, 24, 28,  8, 33,\n",
       "        35,  3,  1,  0, 32, 36,  4, 21, 42, 43, 29, 41, 13, 44, 40, 37,  5, 22,\n",
       "        50, 30, 14, 51, 49, 45, 38, 52,  6, 48, 23, 58, 53, 46, 15, 31, 57, 59,\n",
       "         7, 56, 39, 60, 54, 47, 61, 55, 62, 63])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dist_dict[18]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "250-186"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "speech-bci",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
