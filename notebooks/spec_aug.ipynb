{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def sorted_indices_by_euclidean_distance_torch(coords: torch.Tensor):\n",
    "    \"\"\"\n",
    "    coords: LongTensor of shape (N,2) with (row, col) pairs.\n",
    "    Returns: dict {i: LongTensor([i, j1, j2, ...])} with all N indices\n",
    "             sorted by distance from coords[i].\n",
    "    \"\"\"\n",
    "    N = coords.shape[0]\n",
    "    dist_dict = {}\n",
    "    # Convert to float for distance computation\n",
    "    coords_f = coords.float()\n",
    "    for i in range(N):\n",
    "        # compute vector differences\n",
    "        diff = coords_f - coords_f[i:i+1]         # shape (N,2)\n",
    "        dists = diff.norm(dim=1)                 # shape (N,)\n",
    "        order = torch.argsort(dists)             # indices sorted by distance\n",
    "        dist_dict[i] = order                     # LongTensor of length N\n",
    "    return dist_dict\n",
    "\n",
    "def build_distance_dict_torch(shape=(8, 8), traversal=None):\n",
    "    \"\"\"\n",
    "    shape: tuple (H, W)\n",
    "    traversal: optional list or tensor of length H*W giving (row, col) coords\n",
    "               in the order your 1D array uses. If None, assumes standard\n",
    "               row-major flatten.\n",
    "    Returns: dict from flat-index -> LongTensor of neighbors sorted by distance.\n",
    "    \"\"\"\n",
    "    H, W = shape\n",
    "    N = H * W\n",
    "\n",
    "    if traversal is None:\n",
    "        # build row‚Äêmajor coords\n",
    "        # coords[i] = (i//W, i%W)\n",
    "        rows = torch.arange(N, dtype=torch.long) // W\n",
    "        cols = torch.arange(N, dtype=torch.long) % W\n",
    "        coords = torch.stack([rows, cols], dim=1)  # (N,2)\n",
    "    else:\n",
    "        coords = torch.tensor(traversal, dtype=torch.long)\n",
    "        assert coords.shape == (N, 2), \"Traversal must be (H*W, 2)\"\n",
    "\n",
    "    return sorted_indices_by_euclidean_distance_torch(coords)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_dict = build_distance_dict_torch((8,8))\n",
    "savePath = '/home3/skaasyap/willett/outputs/'\n",
    "torch.save(dist_dict, f'{savePath}dist_dict.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "import torch\n",
    "import random\n",
    "\n",
    "def channel_specaugment_masks(\n",
    "    x,            # tensor [B, T, D]\n",
    "    num_masks, max_channels_to_mask,\n",
    "    dist_dict,\n",
    "    num_channels=64,\n",
    "    features_per_channel=2\n",
    "):\n",
    "    B, T, D = x.shape\n",
    "    device = x.device\n",
    "    masks = torch.zeros(B, D, dtype=torch.bool, device=device)\n",
    "\n",
    "    # build a [B, num_channels] of uniform weights\n",
    "    weights = torch.ones(B, num_channels, device=device)\n",
    "\n",
    "    # now sample *per-row*:\n",
    "    # starts1: [B, N], starts2: [B, M]\n",
    "    starts1 = torch.multinomial(weights, num_masks, replacement=False)\n",
    "    starts2 = torch.multinomial(weights, num_masks, replacement=False)\n",
    "    \n",
    "    # widths per mask, per sample\n",
    "    widths1 = torch.randint(0, max_channels_to_mask+1, (B, num_masks), device=device)\n",
    "    widths2 = torch.randint(0, max_channels_to_mask+1, (B, num_masks), device=device)\n",
    "    \n",
    "    # precompute feature-block offsets\n",
    "    off1 = [feat * num_channels for feat in range(features_per_channel)]\n",
    "    off2 = [features_per_channel * num_channels + feat * num_channels\n",
    "            for feat in range(features_per_channel)]\n",
    "    \n",
    "\n",
    "    for b in range(B):\n",
    "        # electrode 1\n",
    "        for start_ch, w in zip(starts1[b], widths1[b]):\n",
    "            w = int(w)\n",
    "            if w == 0: \n",
    "                continue\n",
    "            nearest = dist_dict[int(start_ch.item())][:w]\n",
    "            idxs = torch.tensor(nearest, dtype=torch.long, device=device)\n",
    "            for base in off1:\n",
    "                masks[b, base + idxs] = True\n",
    "\n",
    "        # electrode 2\n",
    "        for start_ch, w in zip(starts2[b], widths2[b]):\n",
    "            w = int(w)\n",
    "            if w == 0:\n",
    "                continue\n",
    "            nearest = dist_dict[int(start_ch.item())][:w]\n",
    "            idxs = torch.tensor(nearest, dtype=torch.long, device=device)\n",
    "            for base in off2:\n",
    "                masks[b, base + idxs] = True\n",
    "\n",
    "    # broadcast mask over time\n",
    "    masks = masks.unsqueeze(1).expand(-1, T, -1)\n",
    "    X_masked = x.clone()\n",
    "    X_masked[masks] = 0\n",
    "    return X_masked, masks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1195562/3414989549.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  idxs = torch.tensor(nearest, dtype=torch.long, device=device)\n",
      "/tmp/ipykernel_1195562/3414989549.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  idxs = torch.tensor(nearest, dtype=torch.long, device=device)\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "random.seed(0)\n",
    "\n",
    "B, T, D = 5, 10, 256\n",
    "x = torch.randn(B, T, D)\n",
    "\n",
    "X_masked, masks = channel_specaugment_masks(x, 20, 5, dist_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 10, 256])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_masked.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_masked[0, :, 2+64]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([False, False,  True, False,  True, False, False, False,  True, False,\n",
       "        False, False,  True, False, False, False,  True, False,  True,  True,\n",
       "         True, False, False,  True,  True,  True, False,  True,  True, False,\n",
       "         True,  True, False, False,  True,  True,  True,  True,  True,  True,\n",
       "        False, False, False,  True, False, False,  True, False, False, False,\n",
       "        False,  True, False, False,  True,  True, False, False,  True,  True,\n",
       "         True,  True,  True,  True, False, False,  True, False,  True, False,\n",
       "        False, False,  True, False, False, False,  True, False, False, False,\n",
       "         True, False,  True,  True,  True, False, False,  True,  True,  True,\n",
       "        False,  True,  True, False,  True,  True, False, False,  True,  True,\n",
       "         True,  True,  True,  True, False, False, False,  True, False, False,\n",
       "         True, False, False, False, False,  True, False, False,  True,  True,\n",
       "        False, False,  True,  True,  True,  True,  True,  True, False, False,\n",
       "        False,  True,  True,  True,  True,  True, False,  True, False,  True,\n",
       "        False, False, False,  True, False, False,  True, False,  True, False,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True, False, False,  True,  True,\n",
       "         True,  True,  True, False, False, False, False,  True,  True, False,\n",
       "         True, False, False, False,  True, False,  True,  True,  True,  True,\n",
       "        False, False, False, False, False,  True,  True,  True,  True,  True,\n",
       "        False,  True, False,  True, False, False, False,  True, False, False,\n",
       "         True, False,  True, False,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        False, False,  True,  True,  True,  True,  True, False, False, False,\n",
       "        False,  True,  True, False,  True, False, False, False,  True, False,\n",
       "         True,  True,  True,  True, False, False])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masks[0, 0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "speech-bci",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
