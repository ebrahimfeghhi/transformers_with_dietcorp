{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "shape mismatch: indexing tensors could not be broadcast together with shapes [4], [4, 12]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 62\u001b[0m\n\u001b[1;32m     59\u001b[0m specaug \u001b[39m=\u001b[39m DummySpecAug(mask_token\u001b[39m=\u001b[39mmask_token, patch_height\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, max_mask_pct\u001b[39m=\u001b[39m\u001b[39m0.3\u001b[39m)\n\u001b[1;32m     61\u001b[0m \u001b[39m# Apply\u001b[39;00m\n\u001b[0;32m---> 62\u001b[0m X_masked, mask \u001b[39m=\u001b[39m specaug\u001b[39m.\u001b[39;49mapply_specaugment_mask(X, X_len, num_masks\u001b[39m=\u001b[39;49m\u001b[39m2\u001b[39;49m)\n\u001b[1;32m     64\u001b[0m \u001b[39m# --------------------------\u001b[39;00m\n\u001b[1;32m     65\u001b[0m \u001b[39m# Inspect the result\u001b[39;00m\n\u001b[1;32m     66\u001b[0m \u001b[39mfor\u001b[39;00m b \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(B):\n",
      "Cell \u001b[0;32mIn[2], line 43\u001b[0m, in \u001b[0;36mDummySpecAug.apply_specaugment_mask\u001b[0;34m(self, X, X_len, num_masks)\u001b[0m\n\u001b[1;32m     41\u001b[0m batch_idx \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39marange(B, device\u001b[39m=\u001b[39mdevice)\u001b[39m.\u001b[39mrepeat_interleave(num_masks)\n\u001b[1;32m     42\u001b[0m mask \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mzeros(B, P, dtype\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mbool, device\u001b[39m=\u001b[39mdevice)\n\u001b[0;32m---> 43\u001b[0m mask \u001b[39m=\u001b[39m mask\u001b[39m.\u001b[39;49mindex_put((batch_idx, arange\u001b[39m.\u001b[39;49mexpand(B_rep, \u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m)), mask_chunks, accumulate\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m     45\u001b[0m \u001b[39m# Apply mask token\u001b[39;00m\n\u001b[1;32m     46\u001b[0m X_masked \u001b[39m=\u001b[39m X\u001b[39m.\u001b[39mclone()\n",
      "\u001b[0;31mIndexError\u001b[0m: shape mismatch: indexing tensors could not be broadcast together with shapes [4], [4, 12]"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch\n",
    "\n",
    "\n",
    "class DummySpecAug:\n",
    "    def __init__(self, mask_token, patch_height=1, max_mask_pct=0.2):\n",
    "        self.mask_token = mask_token\n",
    "        self.patch_height = patch_height\n",
    "        self.max_mask_pct = max_mask_pct\n",
    "\n",
    "    def apply_specaugment_mask(self, X, X_len, num_masks=2):\n",
    "        \"\"\"\n",
    "        Fully vectorized SpecAugment-style time masking (no loops).\n",
    "        Args:\n",
    "            X: (B, P, D)\n",
    "            X_len: (B,) in timepoints\n",
    "        Returns:\n",
    "            X_masked: (B, P, D), mask: (B, P)\n",
    "        \"\"\"\n",
    "        B, P, D = X.shape\n",
    "        device = X.device\n",
    "\n",
    "        valid_lens = (X_len // self.patch_height).to(device)\n",
    "        max_mask_lens = (self.max_mask_pct * valid_lens).clamp(min=1).long()\n",
    "\n",
    "        B_rep = B * num_masks\n",
    "        valid_lens_rep = valid_lens.repeat_interleave(num_masks)\n",
    "        max_mask_lens_rep = max_mask_lens.repeat_interleave(num_masks)\n",
    "\n",
    "        t = (torch.rand(B_rep, device=device) * max_mask_lens_rep.float()).floor().long() + 1\n",
    "        max_start = (valid_lens_rep - t + 1).clamp(min=1)\n",
    "        t0 = (torch.rand(B_rep, device=device) * max_start.float()).floor().long()\n",
    "\n",
    "        # Build flattened mask indices\n",
    "        arange = torch.arange(P, device=device).unsqueeze(0)  # (1, P)\n",
    "        t0_exp = t0.unsqueeze(1)                              # (B_rep, 1)\n",
    "        t1_exp = (t0 + t).unsqueeze(1)                        # (B_rep, 1)\n",
    "        mask_chunks = (arange >= t0_exp) & (arange < t1_exp)  # (B_rep, P)\n",
    "\n",
    "        # Now gather the flat indices to write into (B, P)\n",
    "        batch_idx = torch.arange(B, device=device).repeat_interleave(num_masks)  # (B_rep,)\n",
    "        patch_idx = mask_chunks.nonzero(as_tuple=False)  # (N_masked, 2): [mask_row, patch_col]\n",
    "        b_indices = batch_idx[patch_idx[:, 0]]           # Map B_rep index â†’ actual batch index\n",
    "        p_indices = patch_idx[:, 1]                      # patch index\n",
    "\n",
    "        # Set those positions to True in the full mask\n",
    "        mask = torch.zeros(B, P, dtype=torch.bool, device=device)\n",
    "        mask[b_indices, p_indices] = True\n",
    "\n",
    "        # Apply mask token\n",
    "        X_masked = X.clone()\n",
    "        X_masked[mask] = self.mask_token\n",
    "\n",
    "        return X_masked, mask\n",
    "\n",
    "\n",
    "# --------------------------\n",
    "# Create dummy input\n",
    "B, P, D = 2, 12, 4  # batch, patches, dim\n",
    "X = torch.randn(B, P, D)\n",
    "X_len = torch.tensor([12, 10])  # valid lengths (in timepoints)\n",
    "\n",
    "# Define mask token and module\n",
    "mask_token = torch.tensor([-99.0] * D)\n",
    "specaug = DummySpecAug(mask_token=mask_token, patch_height=1, max_mask_pct=0.3)\n",
    "\n",
    "# Apply\n",
    "X_masked, mask = specaug.apply_specaugment_mask(X, X_len, num_masks=2)\n",
    "\n",
    "# --------------------------\n",
    "# Inspect the result\n",
    "for b in range(B):\n",
    "    print(f\"\\nSample {b}:\")\n",
    "    print(\"Original:\")\n",
    "    print(X[b])\n",
    "    print(\"Masked:\")\n",
    "    print(X_masked[b])\n",
    "    print(\"Mask positions:\", mask[b].nonzero(as_tuple=True)[0].tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "speech-bci",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
