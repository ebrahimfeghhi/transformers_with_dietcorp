{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn     \n",
    "import torch\n",
    "import sys\n",
    "import numpy as np\n",
    "import sys\n",
    "sys.path.append(\"/home3/ebrahim2/neural_seq_decoder/src/neural_decoder/\")\n",
    "from bit import Transformer, BiT_Phoneme, pad_to_multiple, create_temporal_mask, pair\n",
    "from einops import rearrange, repeat\n",
    "from einops.layers.torch import Rearrange\n",
    "from augmentations import GaussianSmoothing\n",
    "from dataset import pad_to_multiple\n",
    "import copy \n",
    "from torchtnt.utils.flops import FlopTensorDispatchMode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "neural_dim = 256\n",
    "kernel_len = 32\n",
    "layer_dim = 5\n",
    "hidden_dim = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "gru_decoder = nn.GRU(\n",
    "            (neural_dim) * kernel_len,\n",
    "            hidden_dim,\n",
    "            layer_dim,\n",
    "            batch_first=True,\n",
    "            dropout=0,\n",
    "            bidirectional=False\n",
    "        )\n",
    "\n",
    "fc_decoder_out = nn.Linear(hidden_dim, 40 + 1) \n",
    "\n",
    "fc_decoder_out_2 = nn.Linear(384, 40 + 1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = torch.randn(1,500,256) # 10 seconds of input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total forward FLOPs: 32,768,000\n",
      "≈ 3.28 MFLOPs\n"
     ]
    }
   ],
   "source": [
    "daySpecific = nn.Linear(256, 256)\n",
    "with FlopTensorDispatchMode(daySpecific) as ftdm:\n",
    "    res = daySpecific(inputs)\n",
    "    flops_forward = copy.deepcopy(ftdm.flop_counts)\n",
    "\n",
    "    \n",
    "total_flops = sum(                # outer sum\n",
    "    sum(inner.values())           #  ← inner sum\n",
    "    for inner in flops_forward.values()\n",
    ")\n",
    "\n",
    "print(f\"Total forward FLOPs: {total_flops:,}\")        # e.g. 53,502,976\n",
    "print(f\"≈ {total_flops/1e6/10:.2f} MFLOPs\")              # or /1e9 for GFLOPs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 118, 8192])"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unfolder = torch.nn.Unfold(\n",
    "            (kernel_len, 1), dilation=1, padding=0, stride=4\n",
    "        )\n",
    "stridedInputs = torch.permute(\n",
    "            unfolder(\n",
    "                torch.unsqueeze(torch.permute(inputs, (0, 2, 1)), 3)\n",
    "            ),\n",
    "            (0, 2, 1),\n",
    "        )\n",
    "stridedInputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "32*20 + (4*20)*117"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total forward FLOPs: 6,310,330,368\n",
      "≈ 631.03 MFLOPs\n"
     ]
    }
   ],
   "source": [
    "import copy \n",
    "from torchtnt.utils.flops import FlopTensorDispatchMode\n",
    "stridedInputs = torch.randn(1,118, neural_dim*kernel_len)\n",
    "with FlopTensorDispatchMode(gru_decoder) as ftdm:\n",
    "    res_gru, _ = gru_decoder(stridedInputs)\n",
    "    flops_forward = copy.deepcopy(ftdm.flop_counts)\n",
    "\n",
    "    \n",
    "total_flops = sum(                # outer sum\n",
    "    sum(inner.values())           #  ← inner sum\n",
    "    for inner in flops_forward.values()\n",
    ")\n",
    "\n",
    "print(f\"Total forward FLOPs: {total_flops:,}\")        # e.g. 53,502,976\n",
    "print(f\"≈ {total_flops/1e6/10:.2f} MFLOPs\")              # or /1e9 for GFLOPs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total forward FLOPs: 4,954,112\n",
      "≈ 0.50 MFLOPs\n"
     ]
    }
   ],
   "source": [
    "with FlopTensorDispatchMode(fc_decoder_out) as ftdm:\n",
    "    res2 = fc_decoder_out(res_gru)\n",
    "    flops_forward = copy.deepcopy(ftdm.flop_counts)\n",
    "\n",
    "    \n",
    "total_flops = sum(                # outer sum\n",
    "    sum(inner.values())           #  ← inner sum\n",
    "    for inner in flops_forward.values()\n",
    ")\n",
    "\n",
    "print(f\"Total forward FLOPs: {total_flops:,}\")        # e.g. 53,502,976\n",
    "print(f\"≈ {total_flops/1e6/10:.2f} MFLOPs\")              # or /1e9 for GFLOPs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "634.81"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "631.03 + 0.50 + 3.28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total forward FLOPs: 245,760,000\n",
      "≈ 24.58 MFLOPs\n"
     ]
    }
   ],
   "source": [
    "import copy \n",
    "from torchtnt.utils.flops import FlopTensorDispatchMode\n",
    "tf_inputs = torch.randn(1,500,256*5)\n",
    "patch_transform = nn.Linear(256*5, 384)\n",
    "with FlopTensorDispatchMode(patch_transform) as ftdm:\n",
    "    _ = patch_transform(tf_inputs)\n",
    "    #seq_out = fc_decoder_out_2(res)\n",
    "    flops_forward = copy.deepcopy(ftdm.flop_counts)\n",
    "    \n",
    "total_flops = sum(                # outer sum\n",
    "    sum(inner.values())           #  ← inner sum\n",
    "    for inner in flops_forward.values()\n",
    ")\n",
    "\n",
    "print(f\"Total forward FLOPs: {total_flops:,}\")        # e.g. 53,502,976\n",
    "print(f\"≈ {total_flops/1e6/10:.2f} MFLOPs\")              # or /1e9 for GFLOPs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total forward FLOPs: 1,875,148,800\n",
      "≈ 187.51 MFLOPs\n"
     ]
    }
   ],
   "source": [
    "model = Transformer(384, 7, 6, 64, 4, \n",
    "                                    0, use_relative_bias=True)\n",
    "\n",
    "import copy \n",
    "from torchtnt.utils.flops import FlopTensorDispatchMode\n",
    "tf_inputs = torch.randn(1,100,384)\n",
    "with FlopTensorDispatchMode(model) as ftdm:\n",
    "    res = model(tf_inputs)\n",
    "    #seq_out = fc_decoder_out_2(res)\n",
    "    flops_forward = copy.deepcopy(ftdm.flop_counts)\n",
    "    \n",
    "total_flops = sum(                # outer sum\n",
    "    sum(inner.values())           #  ← inner sum\n",
    "    for inner in flops_forward.values()\n",
    ")\n",
    "\n",
    "print(f\"Total forward FLOPs: {total_flops:,}\")        # e.g. 53,502,976\n",
    "print(f\"≈ {total_flops/1e6/10:.2f} MFLOPs\")              # or /1e9 for GFLOPs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total forward FLOPs: 629,760\n",
      "≈ 0.06 MFLOPs\n"
     ]
    }
   ],
   "source": [
    "with FlopTensorDispatchMode(fc_decoder_out_2) as ftdm:\n",
    "    res2 = fc_decoder_out_2(res)\n",
    "    #seq_out = fc_decoder_out(res)\n",
    "    flops_forward = copy.deepcopy(ftdm.flop_counts)\n",
    "\n",
    "    \n",
    "total_flops = sum(                # outer sum\n",
    "    sum(inner.values())           #  ← inner sum\n",
    "    for inner in flops_forward.values()\n",
    ")\n",
    "\n",
    "print(f\"Total forward FLOPs: {total_flops:,}\")        # e.g. 53,502,976\n",
    "print(f\"≈ {total_flops/1e6/10:.2f} MFLOPs\")              # or /1e9 for GFLOPs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "197.4"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "187.51 + 0.06 + 9.83"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "speech-bci",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
