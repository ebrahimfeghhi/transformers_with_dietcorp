{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home2/ebrahim/miniconda3/envs/speech-bci/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "INFO:speechbrain.utils.quirks:Applied quirks (see `speechbrain.utils.quirks`): [disable_jit_profiling, allow_tf32]\n",
      "INFO:speechbrain.utils.quirks:Excluded quirks specified by the `SB_DISABLE_QUIRKS` environment (comma-separated list): []\n"
     ]
    }
   ],
   "source": [
    "from speechbrain.dataio.sampler import DynamicBatchSampler\n",
    "import torch\n",
    "import torchaudio\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from g2p_en import G2p\n",
    "g2p = G2p()\n",
    "import numpy as np\n",
    "\n",
    "PHONE_DEF = [\n",
    "    'AA', 'AE', 'AH', 'AO', 'AW',\n",
    "    'AY', 'B',  'CH', 'D', 'DH',\n",
    "    'EH', 'ER', 'EY', 'F', 'G',\n",
    "    'HH', 'IH', 'IY', 'JH', 'K',\n",
    "    'L', 'M', 'N', 'NG', 'OW',\n",
    "    'OY', 'P', 'R', 'S', 'SH',\n",
    "    'T', 'TH', 'UH', 'UW', 'V',\n",
    "    'W', 'Y', 'Z', 'ZH'\n",
    "]\n",
    "PHONE_DEF_SIL = PHONE_DEF + ['SIL']\n",
    "\n",
    "def phoneToId(p):\n",
    "    return PHONE_DEF_SIL.index(p)\n",
    "\n",
    "def convert_to_phonemes(transcript):\n",
    "    \n",
    "    thisTranscription = transcript.strip()\n",
    "    thisTranscription = re.sub(r'[^a-zA-Z\\- \\']', '', thisTranscription)\n",
    "    thisTranscription = thisTranscription.replace('--', '').lower()\n",
    "    addInterWordSymbol = True\n",
    "\n",
    "    phonemes = []\n",
    "    \n",
    "    for p in g2p(thisTranscription):\n",
    "        if addInterWordSymbol and p==' ':\n",
    "            phonemes.append('SIL')\n",
    "        p = re.sub(r'[0-9]', '', p)  # Remove stress\n",
    "        if re.match(r'[A-Z]+', p):  # Only keep phonemes\n",
    "            phonemes.append(p)\n",
    "\n",
    "    #add one SIL symbol at the end so there's one at the end of each word\n",
    "    if addInterWordSymbol:\n",
    "        phonemes.append('SIL')\n",
    "        \n",
    "    seqLen = len(phonemes)\n",
    "    maxSeqLen = 500\n",
    "    seqClassIDs = np.zeros([maxSeqLen]).astype(np.int32)\n",
    "    seqClassIDs[0:seqLen] = [phoneToId(p) + 1 for p in phonemes]\n",
    "    return seqClassIDs, len(phonemes)\n",
    "\n",
    "# Custom collate function with padding\n",
    "def collate_fn(batch):\n",
    "    \n",
    "    waveforms = [item[0].squeeze(0) for item in batch]  # Remove channel dimension\n",
    "    lengths = torch.tensor([wav.shape[0] for wav in waveforms])\n",
    "    lengths = lengths / max(lengths)\n",
    "    \n",
    "    # Pad sequences to match longest in batch\n",
    "    padded_waveforms = torch.nn.utils.rnn.pad_sequence(\n",
    "        waveforms, \n",
    "        batch_first=True\n",
    "    )\n",
    "    \n",
    "    # Process batch in a single list comprehension (avoids intermediate lists)\n",
    "    processed_batch = [convert_to_phonemes(item[2]) for item in batch]\n",
    "\n",
    "    # Unpack using numpy for tensor conversion\n",
    "    transcripts, transcript_lengths = zip(*processed_batch)\n",
    "\n",
    "    # Convert using numpy stacking for better performance\n",
    "    transcripts = torch.from_numpy(np.stack(transcripts))  # For multi-dimensional arrays\n",
    "    transcript_lengths = torch.as_tensor(np.array(transcript_lengths), dtype=torch.long)\n",
    "    \n",
    "    return padded_waveforms, transcripts, lengths, transcript_lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "positional argument follows keyword argument (3304482115.py, line 93)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[3], line 93\u001b[0;36m\u001b[0m\n\u001b[0;31m    collate_fn=collate_fn,\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m positional argument follows keyword argument\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import torchaudio\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as npx\n",
    "\n",
    "# Dynamic Batch Sampler with Bucketing\n",
    "class DynamicBatchSampler:\n",
    "    def __init__(self, lengths, batch_size, shuffle=True, bucket_size=4000,\n",
    "                  min_bucket_size=16):\n",
    "        self.lengths = lengths\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.bucket_size = bucket_size\n",
    "\n",
    "        # Create buckets based on length ranges\n",
    "        self.buckets = {}\n",
    "        for idx, length in enumerate(lengths):\n",
    "            \n",
    "            # // returns floor(length / bucket_size)\n",
    "            # so all inputs from T:T+bucket_size in length\n",
    "            # are placed in the same bucket. \n",
    "            bucket_id = length // bucket_size\n",
    "            if bucket_id not in self.buckets:\n",
    "                self.buckets[bucket_id] = []\n",
    "            self.buckets[bucket_id].append(idx)\n",
    "            \n",
    "        # combine small buckets\n",
    "        prev_bucket_id = None\n",
    "        \n",
    "        for bucket_id, vals in sorted(self.buckets.items()):\n",
    "            \n",
    "            # if bucket is too small\n",
    "            if len(vals) < min_bucket_size:\n",
    "                # check if previous bucket exists\n",
    "                if prev_bucket_id is not None:\n",
    "                    \n",
    "                    # merge small bucket into previous big bucket\n",
    "                    self.buckets[prev_bucket_id].extend(vals)\n",
    "                   \n",
    "                # if no valid previous bucket, move ids\n",
    "                # to the next available bucket\n",
    "                elif prev_bucket_id is None: \n",
    "                    self.buckets[bucket_id+1].extend(vals)\n",
    "                    \n",
    "                # delete small bucket\n",
    "                del self.buckets[bucket_id]\n",
    "                    \n",
    "            # if bucket is big enough, mark it as the last\n",
    "            # valid bucket\n",
    "            else: \n",
    "                prev_bucket_id = bucket_id\n",
    "                    \n",
    "                    \n",
    "                \n",
    "\n",
    "    def __iter__(self):\n",
    "        \n",
    "        # shuffles inputs within a bucket\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(batches)\n",
    "            for bucket in self.buckets.values():\n",
    "                np.random.shuffle(bucket)\n",
    "\n",
    "        # divides each bucket into batches\n",
    "        batches = []\n",
    "        for bucket in self.buckets.values():\n",
    "            for i in range(0, len(bucket), self.batch_size):\n",
    "                batches.append(bucket[i:i + self.batch_size])\n",
    "\n",
    "\n",
    "        return iter(batches)\n",
    "\n",
    "    def __len__(self):\n",
    "        return sum(len(bucket) // self.batch_size for bucket in self.buckets.values())\n",
    "\n",
    "\n",
    "    def print_bucket_sizes(self):\n",
    "        print(\"Number of examples in each bucket:\")\n",
    "        for bucket_id, bucket in self.buckets.items():\n",
    "            print(f\"Bucket {bucket_id}: {len(bucket)} examples\")\n",
    "    #\n",
    "\n",
    "\n",
    "batch_sampler = DynamicBatchSampler(\n",
    "    lengths=np.load('/data/LLMs/librispeech/LibriSpeech/train-clean-100/lengths.npy'),\n",
    "    batch_size=64,\n",
    "    shuffle=True,\n",
    "    bucket_size=8000,\n",
    ")\n",
    "\n",
    "trainLoader = DataLoader(\n",
    "    trainDataset,\n",
    "    batch_sampler=batch_sampler,\n",
    "    collate_fn=collate_fn,\n",
    "    num_workers=4,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of examples in each bucket:\n",
      "Bucket 28: 2740 examples\n",
      "Bucket 31: 3066 examples\n",
      "Bucket 27: 2269 examples\n",
      "Bucket 29: 3273 examples\n",
      "Bucket 25: 1430 examples\n",
      "Bucket 30: 3361 examples\n",
      "Bucket 19: 424 examples\n",
      "Bucket 20: 429 examples\n",
      "Bucket 7: 353 examples\n",
      "Bucket 23: 756 examples\n",
      "Bucket 26: 1805 examples\n",
      "Bucket 32: 1289 examples\n",
      "Bucket 24: 1061 examples\n",
      "Bucket 16: 354 examples\n",
      "Bucket 33: 474 examples\n",
      "Bucket 14: 326 examples\n",
      "Bucket 22: 623 examples\n",
      "Bucket 13: 312 examples\n",
      "Bucket 18: 361 examples\n",
      "Bucket 6: 330 examples\n",
      "Bucket 9: 348 examples\n",
      "Bucket 11: 293 examples\n",
      "Bucket 15: 335 examples\n",
      "Bucket 21: 546 examples\n",
      "Bucket 5: 304 examples\n",
      "Bucket 10: 327 examples\n",
      "Bucket 17: 368 examples\n",
      "Bucket 8: 322 examples\n",
      "Bucket 4: 259 examples\n",
      "Bucket 34: 53 examples\n",
      "Bucket 12: 324 examples\n",
      "Bucket 3: 24 examples\n"
     ]
    }
   ],
   "source": [
    "batch_sampler.print_bucket_sizes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "speech-bci",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
