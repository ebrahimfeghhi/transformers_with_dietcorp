{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from speechbrain.dataio.sampler import DynamicBatchSampler\n",
    "import torch\n",
    "import torchaudio\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from g2p_en import G2p\n",
    "g2p = G2p()\n",
    "import numpy as np\n",
    "\n",
    "PHONE_DEF = [\n",
    "    'AA', 'AE', 'AH', 'AO', 'AW',\n",
    "    'AY', 'B',  'CH', 'D', 'DH',\n",
    "    'EH', 'ER', 'EY', 'F', 'G',\n",
    "    'HH', 'IH', 'IY', 'JH', 'K',\n",
    "    'L', 'M', 'N', 'NG', 'OW',\n",
    "    'OY', 'P', 'R', 'S', 'SH',\n",
    "    'T', 'TH', 'UH', 'UW', 'V',\n",
    "    'W', 'Y', 'Z', 'ZH'\n",
    "]\n",
    "PHONE_DEF_SIL = PHONE_DEF + ['SIL']\n",
    "\n",
    "def phoneToId(p):\n",
    "    return PHONE_DEF_SIL.index(p)\n",
    "\n",
    "def convert_to_phonemes(transcript):\n",
    "    \n",
    "    thisTranscription = transcript.strip()\n",
    "    thisTranscription = re.sub(r'[^a-zA-Z\\- \\']', '', thisTranscription)\n",
    "    thisTranscription = thisTranscription.replace('--', '').lower()\n",
    "    addInterWordSymbol = True\n",
    "\n",
    "    phonemes = []\n",
    "    \n",
    "    for p in g2p(thisTranscription):\n",
    "        if addInterWordSymbol and p==' ':\n",
    "            phonemes.append('SIL')\n",
    "        p = re.sub(r'[0-9]', '', p)  # Remove stress\n",
    "        if re.match(r'[A-Z]+', p):  # Only keep phonemes\n",
    "            phonemes.append(p)\n",
    "\n",
    "    #add one SIL symbol at the end so there's one at the end of each word\n",
    "    if addInterWordSymbol:\n",
    "        phonemes.append('SIL')\n",
    "        \n",
    "    seqLen = len(phonemes)\n",
    "    maxSeqLen = 500\n",
    "    seqClassIDs = np.zeros([maxSeqLen]).astype(np.int32)\n",
    "    seqClassIDs[0:seqLen] = [phoneToId(p) + 1 for p in phonemes]\n",
    "    return seqClassIDs, len(phonemes)\n",
    "\n",
    "# Custom collate function with padding\n",
    "def collate_fn(batch):\n",
    "    \n",
    "    waveforms = [item[0].squeeze(0) for item in batch]  # Remove channel dimension\n",
    "    lengths = torch.tensor([wav.shape[0] for wav in waveforms])\n",
    "    lengths = lengths / max(lengths)\n",
    "    \n",
    "    # Pad sequences to match longest in batch\n",
    "    padded_waveforms = torch.nn.utils.rnn.pad_sequence(\n",
    "        waveforms, \n",
    "        batch_first=True\n",
    "    )\n",
    "    \n",
    "    # Process batch in a single list comprehension (avoids intermediate lists)\n",
    "    processed_batch = [convert_to_phonemes(item[2]) for item in batch]\n",
    "\n",
    "    # Unpack using numpy for tensor conversion\n",
    "    transcripts, transcript_lengths = zip(*processed_batch)\n",
    "\n",
    "    # Convert using numpy stacking for better performance\n",
    "    transcripts = torch.from_numpy(np.stack(transcripts))  # For multi-dimensional arrays\n",
    "    transcript_lengths = torch.as_tensor(np.array(transcript_lengths), dtype=torch.long)\n",
    "    \n",
    "    return padded_waveforms, transcripts, lengths, transcript_lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Precompute all waveform lengths (time dimension is at index 1)\n",
    "# Dataset and DataLoader setup\n",
    "\n",
    "librispeech_path = \"/data/LLMs/librispeech/\"\n",
    "\n",
    "#trainDataset = torchaudio.datasets.LIBRISPEECH(\n",
    "#    root=librispeech_path,\n",
    "#    url=\"train-clean-100\",\n",
    "#    download=False,\n",
    "#)\n",
    "\n",
    "#lengths = [trainDataset[i][0].shape[1] for i in range(len(trainDataset))]\n",
    "\n",
    "valDataset = torchaudio.datasets.LIBRISPEECH(\n",
    "    root=librispeech_path,\n",
    "    url=\"dev-clean\",\n",
    "    download=False,\n",
    ")\n",
    "lengths = [valDataset[i][0].shape[1] for i in range(len(valDataset))]\n",
    "np.save('/data/LLMs/librispeech/LibriSpeech/dev-clean/lengths', lengths)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "6 // 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "ename": "AxisError",
     "evalue": "axis -1 is out of bounds for array of dimension 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAxisError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[51], line 82\u001b[0m\n\u001b[1;32m     78\u001b[0m             \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mBucket \u001b[39m\u001b[39m{\u001b[39;00mbucket_id\u001b[39m}\u001b[39;00m\u001b[39m: \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(bucket)\u001b[39m}\u001b[39;00m\u001b[39m examples\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     79\u001b[0m     \u001b[39m#\u001b[39;00m\n\u001b[0;32m---> 82\u001b[0m batch_sampler \u001b[39m=\u001b[39m DynamicBatchSampler(\n\u001b[1;32m     83\u001b[0m     lengths\u001b[39m=\u001b[39;49mnp\u001b[39m.\u001b[39;49mload(\u001b[39m'\u001b[39;49m\u001b[39m/data/LLMs/librispeech/LibriSpeech/train-clean-100/lengths.npy\u001b[39;49m\u001b[39m'\u001b[39;49m),\n\u001b[1;32m     84\u001b[0m     batch_size\u001b[39m=\u001b[39;49m\u001b[39m64\u001b[39;49m,\n\u001b[1;32m     85\u001b[0m     shuffle\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m     86\u001b[0m     bucket_size\u001b[39m=\u001b[39;49m\u001b[39m8000\u001b[39;49m,\n\u001b[1;32m     87\u001b[0m )\n\u001b[1;32m     89\u001b[0m trainLoader \u001b[39m=\u001b[39m DataLoader(\n\u001b[1;32m     90\u001b[0m     trainDataset,\n\u001b[1;32m     91\u001b[0m     batch_sampler\u001b[39m=\u001b[39mbatch_sampler,\n\u001b[1;32m     92\u001b[0m     collate_fn\u001b[39m=\u001b[39mcollate_fn,\n\u001b[1;32m     93\u001b[0m     num_workers\u001b[39m=\u001b[39m\u001b[39m4\u001b[39m,\n\u001b[1;32m     94\u001b[0m )\n",
      "Cell \u001b[0;32mIn[51], line 28\u001b[0m, in \u001b[0;36mDynamicBatchSampler.__init__\u001b[0;34m(self, lengths, batch_size, shuffle, bucket_size)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[39m# combine small buckets\u001b[39;00m\n\u001b[1;32m     26\u001b[0m prev_bucket_id \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m---> 28\u001b[0m \u001b[39mfor\u001b[39;00m bucket_id, vals \u001b[39min\u001b[39;00m np\u001b[39m.\u001b[39;49msort(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbuckets\u001b[39m.\u001b[39;49mitems()):\n\u001b[1;32m     29\u001b[0m     \n\u001b[1;32m     30\u001b[0m     \u001b[39m# if bucket is too small\u001b[39;00m\n\u001b[1;32m     31\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(vals) \u001b[39m<\u001b[39m min_bucket_size:\n\u001b[1;32m     32\u001b[0m         \u001b[39m# check if previous bucket exists\u001b[39;00m\n\u001b[1;32m     33\u001b[0m         \u001b[39mif\u001b[39;00m prev_bucket_id \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     34\u001b[0m             \n\u001b[1;32m     35\u001b[0m             \u001b[39m# merge small bucket into previous big bucket\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/speech-bci/lib/python3.9/site-packages/numpy/core/fromnumeric.py:1017\u001b[0m, in \u001b[0;36msort\u001b[0;34m(a, axis, kind, order)\u001b[0m\n\u001b[1;32m   1015\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1016\u001b[0m     a \u001b[39m=\u001b[39m asanyarray(a)\u001b[39m.\u001b[39mcopy(order\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mK\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m-> 1017\u001b[0m a\u001b[39m.\u001b[39;49msort(axis\u001b[39m=\u001b[39;49maxis, kind\u001b[39m=\u001b[39;49mkind, order\u001b[39m=\u001b[39;49morder)\n\u001b[1;32m   1018\u001b[0m \u001b[39mreturn\u001b[39;00m a\n",
      "\u001b[0;31mAxisError\u001b[0m: axis -1 is out of bounds for array of dimension 0"
     ]
    }
   ],
   "source": [
    "\n",
    "import torchaudio\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as npx\n",
    "\n",
    "# Dynamic Batch Sampler with Bucketing\n",
    "class DynamicBatchSampler:\n",
    "    def __init__(self, lengths, batch_size, shuffle=True, bucket_size=4000):\n",
    "        self.lengths = lengths\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.bucket_size = bucket_size\n",
    "\n",
    "        # Create buckets based on length ranges\n",
    "        self.buckets = {}\n",
    "        for idx, length in enumerate(lengths):\n",
    "            \n",
    "            # // returns floor(length / bucket_size)\n",
    "            # so all inputs from T:T+bucket_size in length\n",
    "            # are placed in the same bucket. \n",
    "            bucket_id = length // bucket_size\n",
    "            if bucket_id not in self.buckets:\n",
    "                self.buckets[bucket_id] = []\n",
    "            self.buckets[bucket_id].append(idx)\n",
    "            \n",
    "        # combine small buckets\n",
    "        prev_bucket_id = None\n",
    "        \n",
    "        for bucket_id, vals in sorted(self.buckets.items()):\n",
    "            \n",
    "            # if bucket is too small\n",
    "            if len(vals) < min_bucket_size:\n",
    "                # check if previous bucket exists\n",
    "                if prev_bucket_id is not None:\n",
    "                    \n",
    "                    # merge small bucket into previous big bucket\n",
    "                    self.buckets[prev_bucket_id].extend(vals)\n",
    "                   \n",
    "                    \n",
    "                elif prev_bucket_id is None: \n",
    "                    # add it to the next bucket\n",
    "                    self.buckets[bucket_id+1].extend(vals)\n",
    "                    \n",
    "                # delete small bucket\n",
    "                del self.buckets[bucket_id]\n",
    "                    \n",
    "            # if bucket is big enough, save its ids so future\n",
    "            # small buckets can be added\n",
    "            else: \n",
    "                prev_bucket_id = bucket_id\n",
    "                    \n",
    "                    \n",
    "                \n",
    "\n",
    "    def __iter__(self):\n",
    "        \n",
    "        # shuffles inputs within a bucket\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(batches)\n",
    "            for bucket in self.buckets.values():\n",
    "                np.random.shuffle(bucket)\n",
    "\n",
    "        # divides each bucket into batches\n",
    "        batches = []\n",
    "        for bucket in self.buckets.values():\n",
    "            for i in range(0, len(bucket), self.batch_size):\n",
    "                batches.append(bucket[i:i + self.batch_size])\n",
    "\n",
    "\n",
    "        return iter(batches)\n",
    "\n",
    "    def __len__(self):\n",
    "        return sum(len(bucket) // self.batch_size for bucket in self.buckets.values())\n",
    "\n",
    "\n",
    "    def print_bucket_sizes(self):\n",
    "        print(\"Number of examples in each bucket:\")\n",
    "        for bucket_id, bucket in self.buckets.items():\n",
    "            print(f\"Bucket {bucket_id}: {len(bucket)} examples\")\n",
    "    #\n",
    "\n",
    "\n",
    "batch_sampler = DynamicBatchSampler(\n",
    "    lengths=np.load('/data/LLMs/librispeech/LibriSpeech/train-clean-100/lengths.npy'),\n",
    "    batch_size=64,\n",
    "    shuffle=True,\n",
    "    bucket_size=8000,\n",
    ")\n",
    "\n",
    "trainLoader = DataLoader(\n",
    "    trainDataset,\n",
    "    batch_sampler=batch_sampler,\n",
    "    collate_fn=collate_fn,\n",
    "    num_workers=4,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of examples in each bucket:\n",
      "Bucket 28: 2740 examples\n",
      "Bucket 31: 3066 examples\n",
      "Bucket 27: 2269 examples\n",
      "Bucket 29: 3273 examples\n",
      "Bucket 25: 1430 examples\n",
      "Bucket 30: 3361 examples\n",
      "Bucket 19: 424 examples\n",
      "Bucket 20: 429 examples\n",
      "Bucket 7: 353 examples\n",
      "Bucket 23: 756 examples\n",
      "Bucket 26: 1805 examples\n",
      "Bucket 32: 1289 examples\n",
      "Bucket 24: 1061 examples\n",
      "Bucket 16: 354 examples\n",
      "Bucket 33: 474 examples\n",
      "Bucket 14: 326 examples\n",
      "Bucket 22: 623 examples\n",
      "Bucket 13: 312 examples\n",
      "Bucket 18: 361 examples\n",
      "Bucket 6: 330 examples\n",
      "Bucket 9: 348 examples\n",
      "Bucket 11: 293 examples\n",
      "Bucket 15: 335 examples\n",
      "Bucket 21: 546 examples\n",
      "Bucket 5: 304 examples\n",
      "Bucket 10: 327 examples\n",
      "Bucket 17: 368 examples\n",
      "Bucket 8: 322 examples\n",
      "Bucket 4: 259 examples\n",
      "Bucket 34: 48 examples\n",
      "Bucket 12: 324 examples\n",
      "Bucket 3: 23 examples\n",
      "Bucket 2: 1 examples\n",
      "Bucket 38: 1 examples\n",
      "Bucket 35: 1 examples\n",
      "Bucket 36: 1 examples\n",
      "Bucket 39: 1 examples\n",
      "Bucket 49: 1 examples\n"
     ]
    }
   ],
   "source": [
    "batch_sampler.print_bucket_sizes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "speech-bci",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
