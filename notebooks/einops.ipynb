{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home2/ebrahim/miniconda3/envs/llm_brain/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home2/ebrahim/miniconda3/envs/llm_brain/lib/python3.11/site-packages/transformers/utils/generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from einops import rearrange\n",
    "\n",
    "# Example tensor with shape (b=1, c=1, h=2, w=2)\n",
    "input_tensor = torch.arange(1, (12*8)+1).reshape(1, 1, 12, 8)\n",
    "patch_height = 3\n",
    "patch_width = 4\n",
    "\n",
    "output_tensor = rearrange(input_tensor, 'b c (h p1) (w p2) -> b (h w) (p1 p2 c)', p1=patch_height, p2=patch_width)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 1,  2,  3,  4,  5,  6,  7,  8],\n",
       "          [ 9, 10, 11, 12, 13, 14, 15, 16],\n",
       "          [17, 18, 19, 20, 21, 22, 23, 24],\n",
       "          [25, 26, 27, 28, 29, 30, 31, 32],\n",
       "          [33, 34, 35, 36, 37, 38, 39, 40],\n",
       "          [41, 42, 43, 44, 45, 46, 47, 48],\n",
       "          [49, 50, 51, 52, 53, 54, 55, 56],\n",
       "          [57, 58, 59, 60, 61, 62, 63, 64],\n",
       "          [65, 66, 67, 68, 69, 70, 71, 72],\n",
       "          [73, 74, 75, 76, 77, 78, 79, 80],\n",
       "          [81, 82, 83, 84, 85, 86, 87, 88],\n",
       "          [89, 90, 91, 92, 93, 94, 95, 96]]]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1,  2,  3,  4,  9, 10, 11, 12, 17, 18, 19, 20],\n",
       "         [ 5,  6,  7,  8, 13, 14, 15, 16, 21, 22, 23, 24],\n",
       "         [25, 26, 27, 28, 33, 34, 35, 36, 41, 42, 43, 44],\n",
       "         [29, 30, 31, 32, 37, 38, 39, 40, 45, 46, 47, 48],\n",
       "         [49, 50, 51, 52, 57, 58, 59, 60, 65, 66, 67, 68],\n",
       "         [53, 54, 55, 56, 61, 62, 63, 64, 69, 70, 71, 72],\n",
       "         [73, 74, 75, 76, 81, 82, 83, 84, 89, 90, 91, 92],\n",
       "         [77, 78, 79, 80, 85, 86, 87, 88, 93, 94, 95, 96]]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_tensor"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What einops rearange does is it changes the input so to be of shape num patches.    \n",
    "Each patch is of shape patch width * patch height. Patches are arranged so that\n",
    "patches nearby in time are next to each other.      \n",
    "So every block of T/patch_height patches\n",
    "should be able to attend to each other. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 1, 1, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 1, 1, 1, 0, 0, 0],\n",
      "        [0, 0, 0, 1, 1, 1, 0, 0, 0],\n",
      "        [0, 0, 0, 1, 1, 1, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 1, 1, 1],\n",
      "        [0, 0, 0, 0, 0, 0, 1, 1, 1],\n",
      "        [0, 0, 0, 0, 0, 0, 1, 1, 1]], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "def make_blockwise_mask(num_patches, patch_width, num_features, device='cpu'):\n",
    "    \"\"\"\n",
    "    Creates a (num_patches, num_patches) boolean mask where each non-overlapping group of N patches\n",
    "    can attend only to each other.\n",
    "\n",
    "    Args:\n",
    "        num_patches (int): total number of tokens (patches)\n",
    "        N (int): number of patches per block (must divide num_patches evenly)\n",
    "        device (str or torch.device): where to create the mask\n",
    "\n",
    "    Returns:\n",
    "        mask (torch.Tensor): boolean tensor of shape (num_patches, num_patches)\n",
    "                             with True where attention is allowed\n",
    "    \"\"\"\n",
    "    \n",
    "    N = num_features / patch_width\n",
    "    assert num_patches % N == 0, \"num_patches must be divisible by N\"\n",
    "    \n",
    "    block_id = torch.arange(num_patches, device=device) // N  # Shape: (num_patches,)\n",
    "    mask = block_id.unsqueeze(0) == block_id.unsqueeze(1)     # Shape: (num_patches, num_patches)\n",
    "    \n",
    "    return mask  # dtype: bool\n",
    "\n",
    "mask = make_blockwise_mask(num_patches=9, num_features=6, patch_width=2)\n",
    "\n",
    "print(mask.int())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_brain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
