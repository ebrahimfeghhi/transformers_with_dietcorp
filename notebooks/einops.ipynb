{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from einops import rearrange\n",
    "\n",
    "# Example tensor with shape (b=1, c=1, h=2, w=2)\n",
    "input_tensor = torch.arange(1, (12*8)+1).reshape(1, 1, 12, 8)\n",
    "patch_height = 3\n",
    "patch_width = 4\n",
    "\n",
    "output_tensor = rearrange(input_tensor, 'b c (h p1) (w p2) -> b (h w) (p1 p2 c)', p1=patch_height, p2=patch_width)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 1,  2,  3,  4,  5,  6,  7,  8],\n",
       "          [ 9, 10, 11, 12, 13, 14, 15, 16],\n",
       "          [17, 18, 19, 20, 21, 22, 23, 24],\n",
       "          [25, 26, 27, 28, 29, 30, 31, 32],\n",
       "          [33, 34, 35, 36, 37, 38, 39, 40],\n",
       "          [41, 42, 43, 44, 45, 46, 47, 48],\n",
       "          [49, 50, 51, 52, 53, 54, 55, 56],\n",
       "          [57, 58, 59, 60, 61, 62, 63, 64],\n",
       "          [65, 66, 67, 68, 69, 70, 71, 72],\n",
       "          [73, 74, 75, 76, 77, 78, 79, 80],\n",
       "          [81, 82, 83, 84, 85, 86, 87, 88],\n",
       "          [89, 90, 91, 92, 93, 94, 95, 96]]]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1,  2,  3,  4,  9, 10, 11, 12, 17, 18, 19, 20],\n",
       "         [ 5,  6,  7,  8, 13, 14, 15, 16, 21, 22, 23, 24],\n",
       "         [25, 26, 27, 28, 33, 34, 35, 36, 41, 42, 43, 44],\n",
       "         [29, 30, 31, 32, 37, 38, 39, 40, 45, 46, 47, 48],\n",
       "         [49, 50, 51, 52, 57, 58, 59, 60, 65, 66, 67, 68],\n",
       "         [53, 54, 55, 56, 61, 62, 63, 64, 69, 70, 71, 72],\n",
       "         [73, 74, 75, 76, 81, 82, 83, 84, 89, 90, 91, 92],\n",
       "         [77, 78, 79, 80, 85, 86, 87, 88, 93, 94, 95, 96]]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sliding_chunks(x, chunk_size=32, stride=4):\n",
    "    \"\"\"\n",
    "    x: Tensor of shape (B, T, C)\n",
    "    Returns: Tensor of shape (B, M, chunk_size, C)\n",
    "    \"\"\"\n",
    "    B, T, C = x.shape\n",
    "\n",
    "    # Unfold the time dimension (dim=1) using torch.nn.functional.unfold logic\n",
    "    x = x.unfold(dimension=1, size=chunk_size, step=stride)  # (B, M, chunk_size, C)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "     \n",
    "X = torch.arange(4).unsqueeze(0).unsqueeze(0).float()\n",
    "X+=torch.randn([1, 1, 4], device='cpu')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input:\n",
      "tensor([[ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11.]])\n",
      "\n",
      "Sliding chunks (B x M x chunk_size x C):\n",
      "tensor([[[ 0.,  1.,  2.,  3.]],\n",
      "\n",
      "        [[ 2.,  3.,  4.,  5.]],\n",
      "\n",
      "        [[ 4.,  5.,  6.,  7.]],\n",
      "\n",
      "        [[ 6.,  7.,  8.,  9.]],\n",
      "\n",
      "        [[ 8.,  9., 10., 11.]]])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# B=1, T=12, C=1 -> weâ€™ll fill time dimension with ascending numbers\n",
    "T = 12\n",
    "x = torch.arange(T).view(1, T, 1).float()\n",
    "\n",
    "# Apply sliding\n",
    "chunks = sliding_chunks(x, chunk_size=4, stride=2)\n",
    "\n",
    "print(\"Input:\")\n",
    "print(x.squeeze(-1))  # just to see time steps clearly\n",
    "\n",
    "print(\"\\nSliding chunks (B x M x chunk_size x C):\")\n",
    "print(chunks.squeeze(0).squeeze(-1))  # Remove batch and channel dims for display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "100/4"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What einops rearange does is it changes the input so to be of shape num patches.    \n",
    "Each patch is of shape patch width * patch height. Patches are arranged so that\n",
    "patches nearby in time are next to each other.      \n",
    "So every block of T/patch_height patches\n",
    "should be able to attend to each other. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 1, 1, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 1, 1, 1, 0, 0, 0],\n",
      "        [0, 0, 0, 1, 1, 1, 0, 0, 0],\n",
      "        [0, 0, 0, 1, 1, 1, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 1, 1, 1],\n",
      "        [0, 0, 0, 0, 0, 0, 1, 1, 1],\n",
      "        [0, 0, 0, 0, 0, 0, 1, 1, 1]], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "def make_blockwise_mask(num_patches, patch_width, num_features, device='cpu'):\n",
    "    \"\"\"\n",
    "    Creates a (num_patches, num_patches) boolean mask where each non-overlapping group of N patches\n",
    "    can attend only to each other.\n",
    "\n",
    "    Args:\n",
    "        num_patches (int): total number of tokens (patches)\n",
    "        N (int): number of patches per block (must divide num_patches evenly)\n",
    "        device (str or torch.device): where to create the mask\n",
    "\n",
    "    Returns:\n",
    "        mask (torch.Tensor): boolean tensor of shape (num_patches, num_patches)\n",
    "                             with True where attention is allowed\n",
    "    \"\"\"\n",
    "    \n",
    "    N = num_features / patch_width\n",
    "    assert num_patches % N == 0, \"num_patches must be divisible by N\"\n",
    "    \n",
    "    block_id = torch.arange(num_patches, device=device) // N  # Shape: (num_patches,)\n",
    "    mask = block_id.unsqueeze(0) == block_id.unsqueeze(1)     # Shape: (num_patches, num_patches)\n",
    "    \n",
    "    return mask  # dtype: bool\n",
    "\n",
    "mask = make_blockwise_mask(num_patches=9, num_features=6, patch_width=2)\n",
    "\n",
    "print(mask.int())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_brain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
