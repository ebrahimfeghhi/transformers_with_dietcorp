{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home3/ebrahim/miniconda3/envs/speech-bci/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from einops import rearrange\n",
    "\n",
    "# Example tensor with shape (b=1, c=1, h=2, w=2)\n",
    "input_tensor = torch.arange(1, (12*8)+1).reshape(1, 1, 12, 8)\n",
    "patch_height = 3\n",
    "patch_width = 4\n",
    "\n",
    "output_tensor = rearrange(input_tensor, 'b c (h p1) (w p2) -> b (h w) (p1 p2 c)', p1=patch_height, p2=patch_width)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sliding_chunks(x, chunk_size=32, stride=4):\n",
    "    \"\"\"\n",
    "    x: Tensor of shape (B, T, C)\n",
    "    Returns: Tensor of shape (B, M, chunk_size, C)\n",
    "    \"\"\"\n",
    "    B, T, C = x.shape\n",
    "\n",
    "    # Unfold the time dimension (dim=1) using torch.nn.functional.unfold logic\n",
    "    x = x.unfold(dimension=1, size=chunk_size, step=stride)  # (B, M, chunk_size, C)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input:\n",
      "tensor([[ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11.]])\n",
      "\n",
      "Sliding chunks (B x M x chunk_size x C):\n",
      "tensor([[[ 0.,  1.,  2.,  3.]],\n",
      "\n",
      "        [[ 2.,  3.,  4.,  5.]],\n",
      "\n",
      "        [[ 4.,  5.,  6.,  7.]],\n",
      "\n",
      "        [[ 6.,  7.,  8.,  9.]],\n",
      "\n",
      "        [[ 8.,  9., 10., 11.]]])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# B=1, T=12, C=1 -> weâ€™ll fill time dimension with ascending numbers\n",
    "T = 12\n",
    "x = torch.arange(T).view(1, T, 1).float()\n",
    "\n",
    "# Apply sliding\n",
    "chunks = sliding_chunks(x, chunk_size=4, stride=2)\n",
    "\n",
    "print(\"Input:\")\n",
    "print(x.squeeze(-1))  # just to see time steps clearly\n",
    "\n",
    "print(\"\\nSliding chunks (B x M x chunk_size x C):\")\n",
    "print(chunks.squeeze(0).squeeze(-1))  # Remove batch and channel dims for display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "100/4"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What einops rearange does is it changes the input so to be of shape num patches.    \n",
    "Each patch is of shape patch width * patch height. Patches are arranged so that\n",
    "patches nearby in time are next to each other.      \n",
    "So every block of T/patch_height patches\n",
    "should be able to attend to each other. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 1, 1, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 1, 1, 1, 0, 0, 0],\n",
      "        [0, 0, 0, 1, 1, 1, 0, 0, 0],\n",
      "        [0, 0, 0, 1, 1, 1, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 1, 1, 1],\n",
      "        [0, 0, 0, 0, 0, 0, 1, 1, 1],\n",
      "        [0, 0, 0, 0, 0, 0, 1, 1, 1]], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "def make_blockwise_mask(num_patches, patch_width, num_features, device='cpu'):\n",
    "    \"\"\"\n",
    "    Creates a (num_patches, num_patches) boolean mask where each non-overlapping group of N patches\n",
    "    can attend only to each other.\n",
    "\n",
    "    Args:\n",
    "        num_patches (int): total number of tokens (patches)\n",
    "        N (int): number of patches per block (must divide num_patches evenly)\n",
    "        device (str or torch.device): where to create the mask\n",
    "\n",
    "    Returns:\n",
    "        mask (torch.Tensor): boolean tensor of shape (num_patches, num_patches)\n",
    "                             with True where attention is allowed\n",
    "    \"\"\"\n",
    "    \n",
    "    N = num_features / patch_width\n",
    "    assert num_patches % N == 0, \"num_patches must be divisible by N\"\n",
    "    \n",
    "    block_id = torch.arange(num_patches, device=device) // N  # Shape: (num_patches,)\n",
    "    mask = block_id.unsqueeze(0) == block_id.unsqueeze(1)     # Shape: (num_patches, num_patches)\n",
    "    \n",
    "    return mask  # dtype: bool\n",
    "\n",
    "mask = make_blockwise_mask(num_patches=9, num_features=6, patch_width=2)\n",
    "\n",
    "print(mask.int())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_brain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
