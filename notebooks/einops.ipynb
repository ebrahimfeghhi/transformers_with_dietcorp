{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from einops import rearrange\n",
    "\n",
    "# Example tensor with shape (b=1, c=1, h=2, w=2)\n",
    "input_tensor = torch.arange(1, 73).reshape(1, 1, 12, 6)\n",
    "patch_height = 3\n",
    "patch_width = 2\n",
    "\n",
    "output_tensor = rearrange(input_tensor, 'b c (h p1) (w p2) -> b (h w) (p1 p2 c)', p1=patch_height, p2=patch_width)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 1,  2,  3,  4,  5,  6],\n",
       "          [ 7,  8,  9, 10, 11, 12],\n",
       "          [13, 14, 15, 16, 17, 18],\n",
       "          [19, 20, 21, 22, 23, 24],\n",
       "          [25, 26, 27, 28, 29, 30],\n",
       "          [31, 32, 33, 34, 35, 36],\n",
       "          [37, 38, 39, 40, 41, 42],\n",
       "          [43, 44, 45, 46, 47, 48],\n",
       "          [49, 50, 51, 52, 53, 54],\n",
       "          [55, 56, 57, 58, 59, 60],\n",
       "          [61, 62, 63, 64, 65, 66],\n",
       "          [67, 68, 69, 70, 71, 72]]]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1,  2,  7,  8, 13, 14],\n",
       "         [ 3,  4,  9, 10, 15, 16],\n",
       "         [ 5,  6, 11, 12, 17, 18],\n",
       "         [19, 20, 25, 26, 31, 32],\n",
       "         [21, 22, 27, 28, 33, 34],\n",
       "         [23, 24, 29, 30, 35, 36],\n",
       "         [37, 38, 43, 44, 49, 50],\n",
       "         [39, 40, 45, 46, 51, 52],\n",
       "         [41, 42, 47, 48, 53, 54],\n",
       "         [55, 56, 61, 62, 67, 68],\n",
       "         [57, 58, 63, 64, 69, 70],\n",
       "         [59, 60, 65, 66, 71, 72]]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_tensor"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What einops rearange does is it changes the input so to be of shape num patches.    \n",
    "Each patch is of shape patch width * patch height. Patches are arranged so that\n",
    "patches nearby in time are next to each other.      \n",
    "So every block of T/patch_height patches\n",
    "should be able to attend to each other. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 1, 1, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 1, 1, 1, 0, 0, 0],\n",
      "        [0, 0, 0, 1, 1, 1, 0, 0, 0],\n",
      "        [0, 0, 0, 1, 1, 1, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 1, 1, 1],\n",
      "        [0, 0, 0, 0, 0, 0, 1, 1, 1],\n",
      "        [0, 0, 0, 0, 0, 0, 1, 1, 1]], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "def make_blockwise_mask(num_patches, patch_width, num_features, device='cpu'):\n",
    "    \"\"\"\n",
    "    Creates a (num_patches, num_patches) boolean mask where each non-overlapping group of N patches\n",
    "    can attend only to each other.\n",
    "\n",
    "    Args:\n",
    "        num_patches (int): total number of tokens (patches)\n",
    "        N (int): number of patches per block (must divide num_patches evenly)\n",
    "        device (str or torch.device): where to create the mask\n",
    "\n",
    "    Returns:\n",
    "        mask (torch.Tensor): boolean tensor of shape (num_patches, num_patches)\n",
    "                             with True where attention is allowed\n",
    "    \"\"\"\n",
    "    assert num_patches % N == 0, \"num_patches must be divisible by N\"\n",
    "    \n",
    "    block_id = torch.arange(num_patches, device=device) // N  # Shape: (num_patches,)\n",
    "    mask = block_id.unsqueeze(0) == block_id.unsqueeze(1)     # Shape: (num_patches, num_patches)\n",
    "    \n",
    "    return mask  # dtype: bool\n",
    "\n",
    "mask = make_blockwise_mask(num_patches=9, N=3)\n",
    "\n",
    "print(mask.int())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_brain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
