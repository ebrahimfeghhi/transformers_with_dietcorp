{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import sys\n",
    "sys.path.append(\"/home3/ebrahim/neural_seq_decoder/src\")\n",
    "from neural_decoder.bit import BiT_Phoneme\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"/home3/skaasyap/willett/outputs/enc_7_dec_3_no_cosine_4_17/save_best.pth\"\n",
    "pretrained_state = torch.load(f'{model_path}', map_location='cpu')['model_state_dict']\n",
    "# Step 2: Extract the transformer weights from encoder.transformer\n",
    "transformer_weights = OrderedDict()\n",
    "prefix = \"encoder.transformer.\"\n",
    "for k, v in pretrained_state.items():\n",
    "    if k.startswith(prefix):\n",
    "        new_key = k[len(prefix):]  # strip the prefix\n",
    "        transformer_weights[new_key] = v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BiT_Phoneme(patch_size=(5,256), dim=384, depth=7, heads=6, mlp_dim_ratio=4, dim_head=64, dropout=0.4, input_dropout=0.2, look_ahead=0, nDays=24, gaussianSmoothWidth=2.0, \n",
    "            nClasses=40, T5_style_pos=True, max_mask_pct=0.05, num_masks=20, mae_mode=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.transformer.load_state_dict(transformer_weights, strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([-0.9647, -0.4466,  0.1040,  ...,  0.7947,  1.3381,  1.7217],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.mask_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    model.mask_token.copy_(pretrained_state[\"encoder.mask_token\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([-0.3003,  0.3955, -0.5775,  ..., -0.0681, -0.9625,  0.5753],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.mask_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "speech-bci",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
