{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda/envs/speech-bci/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "\n",
    "# Reload all modules (except those excluded by %aimport) automatically before executing code\n",
    "%autoreload 2\n",
    "import re\n",
    "import time\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "from edit_distance import SequenceMatcher\n",
    "import torch\n",
    "from dataset import SpeechDataset\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from neural_decoder.dataset import getDatasetLoaders\n",
    "import neural_decoder.lm_utils as lmDecoderUtils\n",
    "from neural_decoder.model import GRUDecoder\n",
    "import pickle\n",
    "import argparse\n",
    "import matplotlib.pyplot as plt\n",
    "from neural_decoder.dataset import getDatasetLoaders\n",
    "import neural_decoder.lm_utils as lmDecoderUtils\n",
    "from neural_decoder.lm_utils import build_llama_1B\n",
    "from neural_decoder.model import GRUDecoder\n",
    "from neural_decoder.bit import BiT_Phoneme\n",
    "import pickle\n",
    "import argparse\n",
    "from lm_utils import _cer_and_wer\n",
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "import copy\n",
    "from augmentations import GaussianSmoothing\n",
    "from torch.utils.data import ConcatDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.25.0'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_sentence(s):\n",
    "    s = s.lower()\n",
    "    charMarks = ['a','b','c','d','e','f','g','h','i','j','k','l','m','n','o','p','q','r','s','t','u','v','w','x','y','z',\n",
    "                 \"'\", ' ']\n",
    "    ans = []\n",
    "    for i in s:\n",
    "        if(i in charMarks):\n",
    "            ans.append(i)\n",
    "    \n",
    "    return ''.join(ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUNNING IN LLM MODE\n"
     ]
    }
   ],
   "source": [
    "base_dir = \"/home/ubuntu/data/speech_5gram/lang_test\"\n",
    "\n",
    "load_lm = True\n",
    "# LM decoding hyperparameters\n",
    "acoustic_scale = 0.5\n",
    "blank_penalty = np.log(7)\n",
    "\n",
    "run_for_llm = True\n",
    "\n",
    "if run_for_llm:\n",
    "    return_n_best = True\n",
    "    rescore = True\n",
    "    nbest = 100\n",
    "    print(\"RUNNING IN LLM MODE\")\n",
    "else:\n",
    "    return_n_best = True\n",
    "    rescore = True\n",
    "    nbest = 100\n",
    "    print(\"RUNNING IN N-GRAM MODE\")\n",
    "    print(\"RESCORE\", rescore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded LM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before InitGoogleLogging() is written to STDERR\n",
      "I0807 14:05:59.370102  7640 brain_speech_decoder.h:52] Reading fst /home/ubuntu/data/speech_5gram/lang_test/TLG.fst\n",
      "I0807 14:09:13.403996  7640 brain_speech_decoder.h:58] Reading lm fst /home/ubuntu/data/speech_5gram/lang_test/G.fst\n",
      "I0807 14:09:56.009298  7640 brain_speech_decoder.h:70] Reading rescore fst /home/ubuntu/data/speech_5gram/lang_test/G_no_prune.fst\n",
      "I0807 14:20:18.699311  7640 brain_speech_decoder.h:81] Reading symbol table /home/ubuntu/data/speech_5gram/lang_test/words.txt\n"
     ]
    }
   ],
   "source": [
    "if load_lm and 'ngramDecoder' not in globals():\n",
    "        \n",
    "    lmDir = base_dir\n",
    "    ngramDecoder = lmDecoderUtils.build_lm_decoder(\n",
    "        lmDir,\n",
    "        acoustic_scale=acoustic_scale, #1.2\n",
    "        nbest=nbest,\n",
    "        beam=18\n",
    "    )\n",
    "    print(\"loaded LM\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get model predictions\n",
    "## Always check to make sure val perf matches wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/model_transcriptions/\n",
      "Running model: transformer_short_training_fixed_seed_0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda/envs/speech-bci/lib/python3.9/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3190.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
      "/home/ubuntu/transformers_with_dietcorp/src/neural_decoder/augmentations.py:170: UserWarning: Using padding='same' with even kernel lengths and odd dilation may require a zero-padded copy of the input be created (Triggered internally at ../aten/src/ATen/native/Convolution.cpp:895.)\n",
      "  return self.conv(input, weight=self.weight, groups=self.groups, padding=\"same\")\n",
      "/tmp/ipykernel_7640/1875747173.py:203: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(pred[iterIdx, 0 : adjustedLens[iterIdx], :]),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CER DAY:  0.34675615212527966\n",
      "CER DAY:  0.26091954022988506\n",
      "CER DAY:  0.21884984025559107\n",
      "CER DAY:  0.23390894819466249\n",
      "CER DAY:  0.11300448430493273\n",
      "CER DAY:  0.10357815442561205\n",
      "CER DAY:  0.130558183538316\n",
      "CER DAY:  0.1586452762923351\n",
      "CER DAY:  0.14900398406374502\n",
      "CER DAY:  0.18083333333333335\n",
      "CER DAY:  0.16185476815398075\n",
      "CER DAY:  0.19209558823529413\n",
      "CER DAY:  0.1524163568773234\n",
      "CER DAY:  0.13137032842582105\n",
      "CER DAY:  0.12132024977698483\n",
      "CER DAY:  0.11913357400722022\n",
      "CER DAY:  0.12380952380952381\n",
      "CER DAY:  0.1648568608094768\n",
      "CER DAY:  0.11751662971175167\n",
      "CER DAY:  0.1125370187561698\n",
      "CER DAY:  0.10653266331658291\n",
      "CER DAY:  0.1274601686972821\n",
      "CER DAY:  0.12696941612604262\n",
      "CER DAY:  0.17083333333333334\n",
      "Model performance:  0.15550328092113408\n",
      "Running n-gram LM\n",
      "N-gram decoding took 0.2270938984372399 seconds per sample\n",
      "SAVING OUTPUTS FOR LLM\n",
      "Running model: transformer_short_training_fixed_seed_1\n",
      "CER DAY:  0.3523489932885906\n",
      "CER DAY:  0.2770114942528736\n",
      "CER DAY:  0.2220447284345048\n",
      "CER DAY:  0.24175824175824176\n",
      "CER DAY:  0.11390134529147983\n",
      "CER DAY:  0.11864406779661017\n",
      "CER DAY:  0.13812677388836328\n",
      "CER DAY:  0.16310160427807488\n",
      "CER DAY:  0.15458167330677292\n",
      "CER DAY:  0.18833333333333332\n",
      "CER DAY:  0.1662292213473316\n",
      "CER DAY:  0.19761029411764705\n",
      "CER DAY:  0.15985130111524162\n",
      "CER DAY:  0.1392978482446206\n",
      "CER DAY:  0.11329170383586083\n",
      "CER DAY:  0.11371841155234658\n",
      "CER DAY:  0.11534391534391535\n",
      "CER DAY:  0.15992102665350444\n",
      "CER DAY:  0.12084257206208426\n",
      "CER DAY:  0.11648568608094768\n",
      "CER DAY:  0.08844221105527639\n",
      "CER DAY:  0.13776944704779756\n",
      "CER DAY:  0.13623725671918444\n",
      "CER DAY:  0.171875\n",
      "Model performance:  0.15884610622755974\n",
      "Running n-gram LM\n",
      "N-gram decoding took 0.19700796333226292 seconds per sample\n",
      "SAVING OUTPUTS FOR LLM\n",
      "Running model: transformer_short_training_fixed_seed_2\n",
      "CER DAY:  0.3624161073825503\n",
      "CER DAY:  0.27241379310344827\n",
      "CER DAY:  0.21405750798722045\n",
      "CER DAY:  0.24489795918367346\n",
      "CER DAY:  0.12376681614349776\n",
      "CER DAY:  0.10263653483992467\n",
      "CER DAY:  0.12015137180700095\n",
      "CER DAY:  0.15062388591800357\n",
      "CER DAY:  0.15856573705179283\n",
      "CER DAY:  0.17583333333333334\n",
      "CER DAY:  0.14698162729658792\n",
      "CER DAY:  0.1948529411764706\n",
      "CER DAY:  0.15520446096654275\n",
      "CER DAY:  0.13023782559456398\n",
      "CER DAY:  0.11418376449598573\n",
      "CER DAY:  0.11010830324909747\n",
      "CER DAY:  0.11851851851851852\n",
      "CER DAY:  0.17374136229022705\n",
      "CER DAY:  0.12638580931263857\n",
      "CER DAY:  0.10760118460019744\n",
      "CER DAY:  0.10050251256281408\n",
      "CER DAY:  0.13964386129334583\n",
      "CER DAY:  0.12882298424467098\n",
      "CER DAY:  0.16979166666666667\n",
      "Model performance:  0.15591597540340885\n",
      "Running n-gram LM\n",
      "N-gram decoding took 0.2246670823205601 seconds per sample\n",
      "SAVING OUTPUTS FOR LLM\n",
      "Running model: transformer_short_training_fixed_seed_3\n",
      "CER DAY:  0.32662192393736017\n",
      "CER DAY:  0.2689655172413793\n",
      "CER DAY:  0.2268370607028754\n",
      "CER DAY:  0.24489795918367346\n",
      "CER DAY:  0.11928251121076233\n",
      "CER DAY:  0.10734463276836158\n",
      "CER DAY:  0.11920529801324503\n",
      "CER DAY:  0.15775401069518716\n",
      "CER DAY:  0.1609561752988048\n",
      "CER DAY:  0.18083333333333335\n",
      "CER DAY:  0.13823272090988625\n",
      "CER DAY:  0.19209558823529413\n",
      "CER DAY:  0.16821561338289961\n",
      "CER DAY:  0.13816534541336353\n",
      "CER DAY:  0.10526315789473684\n",
      "CER DAY:  0.13176895306859207\n",
      "CER DAY:  0.11005291005291006\n",
      "CER DAY:  0.1648568608094768\n",
      "CER DAY:  0.1164079822616408\n",
      "CER DAY:  0.12537018756169793\n",
      "CER DAY:  0.10050251256281408\n",
      "CER DAY:  0.15182755388940955\n",
      "CER DAY:  0.12140871177015755\n",
      "CER DAY:  0.16458333333333333\n",
      "Model performance:  0.1560397837480913\n",
      "Running n-gram LM\n",
      "N-gram decoding took 0.22764137305996635 seconds per sample\n",
      "SAVING OUTPUTS FOR LLM\n",
      "Running model: transformer_short_training_fixed_seed_4\n",
      "CER DAY:  0.3534675615212528\n",
      "CER DAY:  0.2885057471264368\n",
      "CER DAY:  0.2220447284345048\n",
      "CER DAY:  0.24646781789638933\n",
      "CER DAY:  0.11210762331838565\n",
      "CER DAY:  0.12429378531073447\n",
      "CER DAY:  0.13339640491958374\n",
      "CER DAY:  0.16934046345811052\n",
      "CER DAY:  0.16334661354581673\n",
      "CER DAY:  0.1725\n",
      "CER DAY:  0.1679790026246719\n",
      "CER DAY:  0.19761029411764705\n",
      "CER DAY:  0.1570631970260223\n",
      "CER DAY:  0.13590033975084936\n",
      "CER DAY:  0.11329170383586083\n",
      "CER DAY:  0.13628158844765342\n",
      "CER DAY:  0.11851851851851852\n",
      "CER DAY:  0.1549851924975321\n",
      "CER DAY:  0.13747228381374724\n",
      "CER DAY:  0.11846001974333663\n",
      "CER DAY:  0.10753768844221105\n",
      "CER DAY:  0.1415182755388941\n",
      "CER DAY:  0.12233549582947173\n",
      "CER DAY:  0.17291666666666666\n",
      "Model performance:  0.16119846477652594\n",
      "Running n-gram LM\n",
      "N-gram decoding took 0.22725800302895632 seconds per sample\n",
      "SAVING OUTPUTS FOR LLM\n"
     ]
    }
   ],
   "source": [
    "output_file = 'obi'\n",
    "    \n",
    "device = \"cuda\"\n",
    "\n",
    "time_per_sample_arr = []\n",
    "\n",
    "log_data = True\n",
    "rnn_mode = False\n",
    "model_storage_path = '/home/ubuntu/data/transformer_short/'\n",
    "    \n",
    "models_to_run = ['transformer_short_training_fixed']\n",
    "\n",
    "shared_output_file = ''\n",
    "\n",
    "if len(shared_output_file) > 0:\n",
    "    print(\"Writing to shared output file\")\n",
    "    write_mode = \"a\"\n",
    "else:\n",
    "    write_mode = \"w\"\n",
    "    \n",
    "seeds_list = [0,1,2,3,4,5,6,7,8,9]\n",
    "partition_list = [\"competition\"] # \"test\"\n",
    "run_lm = False\n",
    "\n",
    "day_edit_distance = 0\n",
    "day_seq_length = 0\n",
    "prev_day = None\n",
    "\n",
    "day_cer_dict = {}\n",
    "total_wer_dict = {}\n",
    "\n",
    "for partition in partition_list:\n",
    "    \n",
    "    if partition == 'train':\n",
    "        saveFolder_transcripts = \"/home/ubuntu/data/model_transcriptions_finetune/\"\n",
    "    if partition == 'test':\n",
    "        saveFolder_transcripts = \"/home/ubuntu/data/model_transcriptions/\"\n",
    "    if partition == 'competition':\n",
    "        saveFolder_transcripts = \"/home/ubuntu/data/model_transcriptions_comp/\"\n",
    "    \n",
    "    print(saveFolder_transcripts)\n",
    "\n",
    "    for seed in seeds_list:\n",
    "        \n",
    "        day_cer_dict[seed] = []\n",
    "        total_wer_dict[seed] = []\n",
    "                \n",
    "        for mn, model_name_str in enumerate(models_to_run):\n",
    "            \n",
    "            modelPath = f\"{model_storage_path}{model_name_str}_seed_{seed}\"\n",
    "            \n",
    "            if len(shared_output_file) > 0:\n",
    "                output_file = f\"{shared_output_file}_seed_{seed}\"\n",
    "                print(output_file)\n",
    "            else:\n",
    "                output_file = f\"{model_name_str}_seed_{seed}\"\n",
    "                \n",
    "            print(f\"Running model: {model_name_str}_seed_{seed}\")\n",
    "                \n",
    "            with open(modelPath + \"/args\", \"rb\") as handle:\n",
    "                args = pickle.load(handle)\n",
    "                \n",
    "            if log_data == False:\n",
    "                print(\"USING ORIGINAL DATA, MAKE SURE THIS IS CORRECT.\")\n",
    "                data_file = \"/home/ubuntu/data/ptDecoder_ctc\"\n",
    "            else:\n",
    "                data_file = \"/home/ubuntu/data/ptDecoder_ctc_both\"\n",
    "        \n",
    "            trainLoaders, testLoaders, loadedData = getDatasetLoaders(\n",
    "                data_file, 8\n",
    "            )\n",
    "            \n",
    "            # if true, model is a GRU\n",
    "            if 'nInputFeatures' in args.keys():\n",
    "                \n",
    "                if 'max_mask_pct' not in args:\n",
    "                    args['max_mask_pct'] = 0\n",
    "                if 'num_masks' not in args:\n",
    "                    args['num_masks'] = 0\n",
    "                if 'input_dropout' not in args:\n",
    "                    args['input_dropout'] = 0\n",
    "                if 'linderman_lab' not in args:\n",
    "                    args['linderman_lab'] = False\n",
    "                    \n",
    "                print(\"Loading GRU\")\n",
    "                model = GRUDecoder(\n",
    "                    neural_dim=args[\"nInputFeatures\"],\n",
    "                    n_classes=args[\"nClasses\"],\n",
    "                    hidden_dim=args[\"nUnits\"],\n",
    "                    layer_dim=args[\"nLayers\"],\n",
    "                    nDays=args['nDays'],\n",
    "                    dropout=args[\"dropout\"],\n",
    "                    device=device,\n",
    "                    strideLen=args[\"strideLen\"],\n",
    "                    kernelLen=args[\"kernelLen\"],\n",
    "                    gaussianSmoothWidth=args[\"gaussianSmoothWidth\"],\n",
    "                    bidirectional=args[\"bidirectional\"],\n",
    "                    input_dropout=args['input_dropout'], \n",
    "                    max_mask_pct=args['max_mask_pct'],\n",
    "                    num_masks=args['num_masks'], \n",
    "                    linderman_lab=args['linderman_lab']\n",
    "                ).to(device)\n",
    "\n",
    "            else:\n",
    "                \n",
    "                if 'mask_token_zero' not in args:\n",
    "                    args['mask_token_zero'] = False\n",
    "                    \n",
    "                # Instantiate model\n",
    "                # set training relevant parameters for MEMO, doesn't matter for other runs because they are \n",
    "                # only run in eval mode.\n",
    "                model = BiT_Phoneme(\n",
    "                    patch_size=args['patch_size'],\n",
    "                    dim=args['dim'],\n",
    "                    dim_head=args['dim_head'],\n",
    "                    nClasses=args['nClasses'],\n",
    "                    depth=args['depth'],\n",
    "                    heads=args['heads'],\n",
    "                    mlp_dim_ratio=args['mlp_dim_ratio'],\n",
    "                    dropout=0,\n",
    "                    input_dropout=0,\n",
    "                    gaussianSmoothWidth=args['gaussianSmoothWidth'],\n",
    "                    T5_style_pos=args['T5_style_pos'],\n",
    "                    max_mask_pct=0.0,\n",
    "                    num_masks=0, \n",
    "                    mask_token_zeros=args['mask_token_zero'], \n",
    "                    num_masks_channels=0, \n",
    "                    max_mask_channels=0, \n",
    "                    dist_dict_path=0\n",
    "                ).to(device)\n",
    "                \n",
    "                \n",
    "            ckpt_path = modelPath + '/modelWeights'\n",
    "            model.load_state_dict(torch.load(ckpt_path, map_location=device), strict=True)\n",
    "            model = model.to(device)\n",
    "            \n",
    "            \n",
    "            model.eval()\n",
    "\n",
    "            model_outputs = {\n",
    "                \"logits\": [],\n",
    "                \"logitLengths\": [],\n",
    "                \"trueSeqs\": [],\n",
    "                \"transcriptions\": [],\n",
    "                'decodedSeqs': []\n",
    "            }\n",
    "            \n",
    "            total_edit_distance = 0\n",
    "            total_seq_length = 0\n",
    "\n",
    "            if partition == \"competition\":\n",
    "\n",
    "                testDayIdxs = [4, 5, 6, 7, 8, 9, 10, 12, 13, 14, 15, 16, 18, 19, 20]\n",
    "                    \n",
    "            else:\n",
    "                \n",
    "                testDayIdxs = range(len(loadedData[partition])) \n",
    "\n",
    "            ground_truth_sentences = []\n",
    "            \n",
    "            #print(\"RESTRICTED DAYS: \", args['restricted_days'])\n",
    "            \n",
    "            for i, testDayIdx in enumerate(testDayIdxs):\n",
    "                \n",
    "                \n",
    "                test_ds = SpeechDataset([loadedData[partition][i]])\n",
    "                \n",
    "                test_loader = torch.utils.data.DataLoader(\n",
    "                    test_ds, batch_size=1, shuffle=False, num_workers=0\n",
    "                )\n",
    "                \n",
    "                for j, (X, y, X_len, y_len, _) in enumerate(test_loader):\n",
    "                            \n",
    "                    X, y, X_len, y_len, dayIdx = (\n",
    "                        X.to(device),\n",
    "                        y.to(device),\n",
    "                        X_len.to(device),\n",
    "                        y_len.to(device),\n",
    "                        torch.tensor([testDayIdx], dtype=torch.int64).to(device),\n",
    "                    )\n",
    "\n",
    "                    with torch.no_grad():\n",
    "                        \n",
    "                        pred = model.forward(X, X_len, dayIdx)\n",
    "                    \n",
    "                    if hasattr(model, 'compute_length'):\n",
    "                        adjustedLens = model.compute_length(X_len)\n",
    "                    else:\n",
    "                        adjustedLens = ((X_len - model.kernelLen) / model.strideLen).to(torch.int32)\n",
    "                        \n",
    "                    for iterIdx in range(pred.shape[0]):\n",
    "                        \n",
    "                        trueSeq = np.array(y[iterIdx][0 : y_len[iterIdx]].cpu().detach())\n",
    "                        model_outputs[\"logits\"].append(pred[iterIdx].cpu().detach().numpy())\n",
    "                        \n",
    "                        model_outputs[\"logitLengths\"].append(\n",
    "                            adjustedLens[iterIdx].cpu().detach().item()\n",
    "                        )\n",
    "                        \n",
    "                        model_outputs[\"trueSeqs\"].append(trueSeq)\n",
    "                        \n",
    "                        decodedSeq = torch.argmax(\n",
    "                            torch.tensor(pred[iterIdx, 0 : adjustedLens[iterIdx], :]),\n",
    "                            dim=-1,\n",
    "                        ) \n",
    "                        \n",
    "                        decodedSeq = torch.unique_consecutive(decodedSeq, dim=-1)\n",
    "                        decodedSeq = decodedSeq.cpu().detach().numpy()\n",
    "                        decodedSeq = np.array([i for i in decodedSeq if i != 0])\n",
    "                        \n",
    "                        matcher = SequenceMatcher(\n",
    "                            a=trueSeq.tolist(), b=decodedSeq.tolist()\n",
    "                        )\n",
    "                        \n",
    "                        model_outputs['decodedSeqs'].append(decodedSeq)\n",
    "                        \n",
    "                        total_edit_distance += matcher.distance()\n",
    "                        total_seq_length += len(trueSeq)\n",
    "                        \n",
    "                        day_edit_distance += matcher.distance()\n",
    "                        day_seq_length += len(trueSeq)\n",
    "                        \n",
    "                    transcript = loadedData[partition][i][\"transcriptions\"][j].strip()\n",
    "                    transcript = re.sub(r\"[^a-zA-Z\\- \\']\", \"\", transcript)\n",
    "                    transcript = transcript.replace(\"--\", \"\").lower()\n",
    "                    model_outputs[\"transcriptions\"].append(transcript)\n",
    "                    \n",
    "                cer_day = day_edit_distance / day_seq_length\n",
    "                day_cer_dict[seed].append(cer_day)\n",
    "                print(\"CER DAY: \", cer_day)\n",
    "                day_edit_distance = 0 \n",
    "                day_seq_length = 0\n",
    "\n",
    "            cer = total_edit_distance / total_seq_length\n",
    "            \n",
    "            print(\"Model performance: \", cer)\n",
    "\n",
    "            if run_lm:\n",
    "                \n",
    "                print(\"Running n-gram LM\")\n",
    "                \n",
    "                llm_outputs = []\n",
    "                start_t = time.time()\n",
    "                nbest_outputs = []\n",
    "                \n",
    "                for j in range(len(model_outputs[\"logits\"])):\n",
    "                    \n",
    "                    logits = model_outputs[\"logits\"][j]\n",
    "                    \n",
    "                    logits = np.concatenate(\n",
    "                        [logits[:, 1:], logits[:, 0:1]], axis=-1\n",
    "                    )  # Blank is last token\n",
    "                    \n",
    "                    logits = lmDecoderUtils.rearrange_speech_logits(logits[None, :, :], has_sil=True)\n",
    "                    \n",
    "                    nbest = lmDecoderUtils.lm_decode(\n",
    "                        ngramDecoder,\n",
    "                        logits[0],\n",
    "                        blankPenalty=blank_penalty,\n",
    "                        returnNBest=return_n_best,\n",
    "                        rescore=rescore,\n",
    "                    )\n",
    "                    \n",
    "                    nbest_outputs.append(nbest)\n",
    "                    \n",
    "                time_per_sample = (time.time() - start_t) / len(model_outputs[\"logits\"])\n",
    "                print(f\"N-gram decoding took {time_per_sample} seconds per sample\")\n",
    "                time_per_sample_arr.append(time_per_sample)\n",
    "                \n",
    "                if run_for_llm:\n",
    "                \n",
    "                    print(\"SAVING OUTPUTS FOR LLM\")\n",
    "                    with open(f\"{saveFolder_transcripts}{model_name_str}_seed_{seed}_model_outputs.pkl\", \"wb\") as f:\n",
    "                        pickle.dump(model_outputs, f)\n",
    "                        \n",
    "                    with open(f\"{saveFolder_transcripts}{model_name_str}_seed_{seed}_nbest.pkl\", \"wb\") as f:\n",
    "                        pickle.dump(nbest_outputs, f)\n",
    "                        \n",
    "                else: \n",
    "                \n",
    "                    for i in range(len(model_outputs[\"transcriptions\"])):\n",
    "                        model_outputs[\"transcriptions\"][i] = model_outputs[\"transcriptions\"][i].strip()\n",
    "                        nbest_outputs[i] = nbest_outputs[i].strip()\n",
    "                    \n",
    "                    # lower case + remove puncs\n",
    "                    for i in range(len(model_outputs[\"transcriptions\"])):\n",
    "                        model_outputs[\"transcriptions\"][i] = convert_sentence(model_outputs[\"transcriptions\"][i])\n",
    "\n",
    "                    cer, wer = _cer_and_wer(nbest_outputs, model_outputs[\"transcriptions\"], \n",
    "                                        outputType='speech', returnCI=True)\n",
    "\n",
    "                    print(\"CER and WER after 5-gram LM: \", cer, wer)       \n",
    "                    \n",
    "                    out_file = os.path.join(saveFolder_transcripts, output_file)   # no extension per your spec\n",
    "                    \n",
    "                    with open(out_file + '.txt', write_mode, encoding=\"utf-8\") as f:\n",
    "                        f.write(\"\\n\".join(nbest_outputs)+ \"\\n\")   # one line per LLM output  \n",
    "                        \n",
    "                    total_wer_dict[seed] = wer\n",
    "                    \n",
    "            else:\n",
    "                \n",
    "                with open(f\"{saveFolder_transcripts}{model_name_str}_seed_{seed}_model_outputs.pkl\", \"wb\") as f:\n",
    "                        pickle.dump(model_outputs, f)\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "speech-bci",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
