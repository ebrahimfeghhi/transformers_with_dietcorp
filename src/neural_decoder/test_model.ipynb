{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 122, 3584])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "def apply_unfolding(transformedNeural, kernelLen=3, strideLen=1):\n",
    "    \"\"\"\n",
    "    Applies unfolding operation to transformedNeural.\n",
    "    \n",
    "    Args:\n",
    "        transformedNeural (torch.Tensor): Input tensor of shape (nBatch, SeqLen, NeuralFeats)\n",
    "        kernelLen (int): Size of the unfolding window\n",
    "        strideLen (int): Stride of the unfolding operation\n",
    "    \n",
    "    Returns:\n",
    "        torch.Tensor: Strided input tensor of shape (nBatch, new_SeqLen, kernelLen * NeuralFeats)\n",
    "    \"\"\"\n",
    "    nBatch, SeqLen, NeuralFeats = transformedNeural.shape\n",
    "    \n",
    "    # Unfolding layer\n",
    "    unfolder = nn.Unfold((kernelLen, 1), dilation=1, padding=0, stride=(strideLen, 1))\n",
    "    \n",
    "    # Apply unfolding transformation\n",
    "    stridedInputs = torch.permute(\n",
    "        unfolder(\n",
    "            torch.unsqueeze(torch.permute(transformedNeural, (0, 2, 1)), 3)\n",
    "        ),\n",
    "        (0, 2, 1),\n",
    "    )\n",
    "    \n",
    "    return stridedInputs\n",
    "\n",
    "# Example usage\n",
    "transformedNeural = torch.randn(64, 500, 256)  # Example tensor (nBatch=4, SeqLen=100, NeuralFeats=64)\n",
    "result = apply_unfolding(transformedNeural, kernelLen=14, strideLen=4)\n",
    "print(result.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0735,  1.2617,  0.8449,  0.1679, -0.8414, -1.3461, -0.6233,  1.1961,\n",
       "        -1.4940,  0.7175, -1.8987,  0.7655, -0.0109,  1.5910,  1.2007, -1.0333,\n",
       "        -0.0179, -1.7113, -0.3060, -0.6826])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[0, 0, 0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.2617)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformedNeural[0, 1, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
