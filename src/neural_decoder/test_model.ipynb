{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mae import MAE\n",
    "from bit import BiT\n",
    "from dataset import SpeechDataset\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import pickle\n",
    "import torch\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
       "        [0., 0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
       "        [0., 0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
       "        [0., 0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
       "        [0., 0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf],\n",
       "        [-inf, -inf, -inf, -inf, -inf, 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [-inf, -inf, -inf, -inf, -inf, 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [-inf, -inf, -inf, -inf, -inf, 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [-inf, -inf, -inf, -inf, -inf, 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [-inf, -inf, -inf, -inf, -inf, 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "def create_temporal_attention_mask(num_patches, patches_per_timestep, N):\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    mask = torch.full((num_patches, num_patches), float(\"-inf\"), device=device)\n",
    "\n",
    "    timesteps = num_patches // patches_per_timestep\n",
    "    for t_q in range(timesteps):  # time index of query\n",
    "        for dt in range(N + 1):  # how far back to look\n",
    "            t_k = t_q - dt  # key timestep\n",
    "            if t_k < 0:\n",
    "                continue\n",
    "            q_start = t_q * patches_per_timestep\n",
    "            q_end = (t_q + 1) * patches_per_timestep\n",
    "            k_start = t_k * patches_per_timestep\n",
    "            k_end = (t_k + 1) * patches_per_timestep\n",
    "            # allow attention: set to 0 (non-masked)\n",
    "            mask[q_start:q_end, k_start:k_end] = 0\n",
    "\n",
    "    return mask  # shape: [Num Patches, Num Patches]\n",
    "\n",
    "create_temporal_attention_mask(20, 5, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {}\n",
    "modelName = 'BiT'\n",
    "args['outputDir'] = '/data/willett_data/outputs/' + modelName\n",
    "args['datasetPath'] = '/data/willett_data/ptDecoder_ctc'\n",
    "args['seqLen'] = 150\n",
    "args['maxTimeSeriesLen'] = 1200\n",
    "args['batchSize'] = 64\n",
    "args['lrStart'] = 0.006\n",
    "args['lrEnd'] = 0.006\n",
    "args['patch_height'] = 32\n",
    "args['patch_width'] = 16\n",
    "args['n_heads'] = 64\n",
    "args['mlp_ratio'] = 4\n",
    "args['embedding_dim'] = 1024\n",
    "args['nBatch'] = 30000 #3000\n",
    "args['n_layers'] = 3\n",
    "args['nClasses'] = 40\n",
    "args['nInputFeatures'] = 256\n",
    "args['dropout'] = 0.4\n",
    "args['whiteNoiseSD'] = 0.8\n",
    "args['constantOffsetSD'] = 0.2\n",
    "args['gaussianSmoothWidth'] = 2.0\n",
    "args['l2_decay'] = 1e-5\n",
    "args['device'] = 'cuda:2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load neural data \n",
    "def getDatasetLoaders(\n",
    "    datasetName,\n",
    "    batchSize,\n",
    "):\n",
    "    with open(datasetName, \"rb\") as handle:\n",
    "        loadedData = pickle.load(handle)\n",
    "\n",
    "    def _padding(batch):\n",
    "        X, y, X_lens, y_lens, days = zip(*batch)\n",
    "        X_padded = pad_sequence(X, batch_first=True, padding_value=0)\n",
    "        y_padded = pad_sequence(y, batch_first=True, padding_value=0)\n",
    "\n",
    "        return (\n",
    "            X_padded,\n",
    "            y_padded,\n",
    "            torch.stack(X_lens),\n",
    "            torch.stack(y_lens),\n",
    "            torch.stack(days),\n",
    "        )\n",
    "\n",
    "    train_ds = SpeechDataset(loadedData[\"train\"], transform=None)\n",
    "    test_ds = SpeechDataset(loadedData[\"test\"])\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "        train_ds,\n",
    "        batch_size=batchSize,\n",
    "        shuffle=True,\n",
    "        num_workers=0,\n",
    "        pin_memory=True,\n",
    "        collate_fn=_padding,\n",
    "    )\n",
    "    test_loader = DataLoader(\n",
    "        test_ds,\n",
    "        batch_size=batchSize,\n",
    "        shuffle=False,\n",
    "        num_workers=0,\n",
    "        pin_memory=True,\n",
    "        collate_fn=_padding,\n",
    "    )\n",
    "\n",
    "    return train_loader, test_loader, loadedData\n",
    "\n",
    "\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def pad_to_multiple(tensor, multiple, dim=1, value=0):\n",
    "    \"\"\"\n",
    "    Pads `tensor` along `dim` so that its size is divisible by `multiple`.\n",
    "    \"\"\"\n",
    "    size = tensor.size(dim)\n",
    "    padding_needed = (multiple - size % multiple) % multiple\n",
    "    if padding_needed == 0:\n",
    "        return tensor\n",
    "    pad_dims = [0] * (2 * tensor.dim())\n",
    "    pad_dims[-2 * dim - 1] = padding_needed  # padding at the end\n",
    "    return F.pad(tensor, pad_dims, value=value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 608, 256])\n"
     ]
    }
   ],
   "source": [
    "X, y, X_len, y_len, dayIdx = next(iter(trainLoader))\n",
    "X = pad_to_multiple(X, multiple=32)\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "bit = BiT(trial_size=(X.shape[1], X.shape[2]), patch_size=(args['patch_height'], args['patch_width']), \n",
    "    num_classes=args['nClasses'], dim=args['embedding_dim'], depth=args['n_layers'], heads=args['n_heads'], \n",
    "    mlp_dim_ratio=args['mlp_ratio'], dropout=args['dropout'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76412968\n"
     ]
    }
   ],
   "source": [
    "pytorch_total_params = sum(p.numel() for p in bit.parameters())\n",
    "print(pytorch_total_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
