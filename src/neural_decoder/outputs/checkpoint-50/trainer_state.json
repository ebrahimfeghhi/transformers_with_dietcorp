{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 0.36363636363636365,
  "eval_steps": 50,
  "global_step": 50,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.007272727272727273,
      "grad_norm": 1.8590396642684937,
      "learning_rate": 0.0,
      "loss": 0.3727,
      "step": 1
    },
    {
      "epoch": 0.014545454545454545,
      "grad_norm": 1.6678756475448608,
      "learning_rate": 4e-05,
      "loss": 0.2537,
      "step": 2
    },
    {
      "epoch": 0.02181818181818182,
      "grad_norm": 109.56168365478516,
      "learning_rate": 8e-05,
      "loss": 0.3866,
      "step": 3
    },
    {
      "epoch": 0.02909090909090909,
      "grad_norm": 1.1957018375396729,
      "learning_rate": 0.00012,
      "loss": 0.1567,
      "step": 4
    },
    {
      "epoch": 0.03636363636363636,
      "grad_norm": 0.7011343240737915,
      "learning_rate": 0.00016,
      "loss": 0.1331,
      "step": 5
    },
    {
      "epoch": 0.04363636363636364,
      "grad_norm": 0.7261350750923157,
      "learning_rate": 0.0002,
      "loss": 0.2316,
      "step": 6
    },
    {
      "epoch": 0.05090909090909091,
      "grad_norm": 0.37127405405044556,
      "learning_rate": 0.00019555555555555556,
      "loss": 0.086,
      "step": 7
    },
    {
      "epoch": 0.05818181818181818,
      "grad_norm": 0.2921019494533539,
      "learning_rate": 0.00019111111111111114,
      "loss": 0.0316,
      "step": 8
    },
    {
      "epoch": 0.06545454545454546,
      "grad_norm": 0.27643725275993347,
      "learning_rate": 0.0001866666666666667,
      "loss": 0.1104,
      "step": 9
    },
    {
      "epoch": 0.07272727272727272,
      "grad_norm": 24.72772979736328,
      "learning_rate": 0.00018222222222222224,
      "loss": 0.0905,
      "step": 10
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.40468835830688477,
      "learning_rate": 0.00017777777777777779,
      "loss": 0.0675,
      "step": 11
    },
    {
      "epoch": 0.08727272727272728,
      "grad_norm": 0.5304439663887024,
      "learning_rate": 0.00017333333333333334,
      "loss": 0.1441,
      "step": 12
    },
    {
      "epoch": 0.09454545454545454,
      "grad_norm": 0.34848353266716003,
      "learning_rate": 0.00016888888888888889,
      "loss": 0.2622,
      "step": 13
    },
    {
      "epoch": 0.10181818181818182,
      "grad_norm": 0.20607887208461761,
      "learning_rate": 0.00016444444444444444,
      "loss": 0.1293,
      "step": 14
    },
    {
      "epoch": 0.10909090909090909,
      "grad_norm": 0.21266256272792816,
      "learning_rate": 0.00016,
      "loss": 0.0693,
      "step": 15
    },
    {
      "epoch": 0.11636363636363636,
      "grad_norm": 0.26939377188682556,
      "learning_rate": 0.00015555555555555556,
      "loss": 0.1007,
      "step": 16
    },
    {
      "epoch": 0.12363636363636364,
      "grad_norm": 0.2570895552635193,
      "learning_rate": 0.0001511111111111111,
      "loss": 0.1028,
      "step": 17
    },
    {
      "epoch": 0.13090909090909092,
      "grad_norm": 0.2713363468647003,
      "learning_rate": 0.00014666666666666666,
      "loss": 0.1313,
      "step": 18
    },
    {
      "epoch": 0.13818181818181818,
      "grad_norm": 0.38745227456092834,
      "learning_rate": 0.00014222222222222224,
      "loss": 0.1876,
      "step": 19
    },
    {
      "epoch": 0.14545454545454545,
      "grad_norm": 0.23948213458061218,
      "learning_rate": 0.0001377777777777778,
      "loss": 0.07,
      "step": 20
    },
    {
      "epoch": 0.15272727272727274,
      "grad_norm": 0.21001675724983215,
      "learning_rate": 0.00013333333333333334,
      "loss": 0.063,
      "step": 21
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.3506925404071808,
      "learning_rate": 0.00012888888888888892,
      "loss": 0.1884,
      "step": 22
    },
    {
      "epoch": 0.16727272727272727,
      "grad_norm": 0.19944410026073456,
      "learning_rate": 0.00012444444444444444,
      "loss": 0.0817,
      "step": 23
    },
    {
      "epoch": 0.17454545454545456,
      "grad_norm": 0.2578374445438385,
      "learning_rate": 0.00012,
      "loss": 0.0714,
      "step": 24
    },
    {
      "epoch": 0.18181818181818182,
      "grad_norm": 0.22149847447872162,
      "learning_rate": 0.00011555555555555555,
      "loss": 0.0574,
      "step": 25
    },
    {
      "epoch": 0.1890909090909091,
      "grad_norm": 0.3011452257633209,
      "learning_rate": 0.00011111111111111112,
      "loss": 0.1577,
      "step": 26
    },
    {
      "epoch": 0.19636363636363635,
      "grad_norm": 0.2050095945596695,
      "learning_rate": 0.00010666666666666667,
      "loss": 0.1046,
      "step": 27
    },
    {
      "epoch": 0.20363636363636364,
      "grad_norm": 0.37098339200019836,
      "learning_rate": 0.00010222222222222222,
      "loss": 0.1829,
      "step": 28
    },
    {
      "epoch": 0.2109090909090909,
      "grad_norm": 0.32991328835487366,
      "learning_rate": 9.777777777777778e-05,
      "loss": 0.1648,
      "step": 29
    },
    {
      "epoch": 0.21818181818181817,
      "grad_norm": 0.34114527702331543,
      "learning_rate": 9.333333333333334e-05,
      "loss": 0.1769,
      "step": 30
    },
    {
      "epoch": 0.22545454545454546,
      "grad_norm": 0.31204456090927124,
      "learning_rate": 8.888888888888889e-05,
      "loss": 0.0962,
      "step": 31
    },
    {
      "epoch": 0.23272727272727273,
      "grad_norm": 0.23522542417049408,
      "learning_rate": 8.444444444444444e-05,
      "loss": 0.0879,
      "step": 32
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.1926904320716858,
      "learning_rate": 8e-05,
      "loss": 0.0891,
      "step": 33
    },
    {
      "epoch": 0.24727272727272728,
      "grad_norm": 0.2661961615085602,
      "learning_rate": 7.555555555555556e-05,
      "loss": 0.0845,
      "step": 34
    },
    {
      "epoch": 0.2545454545454545,
      "grad_norm": 0.3453044295310974,
      "learning_rate": 7.111111111111112e-05,
      "loss": 0.0712,
      "step": 35
    },
    {
      "epoch": 0.26181818181818184,
      "grad_norm": 0.30787909030914307,
      "learning_rate": 6.666666666666667e-05,
      "loss": 0.105,
      "step": 36
    },
    {
      "epoch": 0.2690909090909091,
      "grad_norm": 0.272136926651001,
      "learning_rate": 6.222222222222222e-05,
      "loss": 0.1229,
      "step": 37
    },
    {
      "epoch": 0.27636363636363637,
      "grad_norm": 0.2584826350212097,
      "learning_rate": 5.7777777777777776e-05,
      "loss": 0.097,
      "step": 38
    },
    {
      "epoch": 0.28363636363636363,
      "grad_norm": 0.23618802428245544,
      "learning_rate": 5.333333333333333e-05,
      "loss": 0.0597,
      "step": 39
    },
    {
      "epoch": 0.2909090909090909,
      "grad_norm": 0.24449385702610016,
      "learning_rate": 4.888888888888889e-05,
      "loss": 0.0602,
      "step": 40
    },
    {
      "epoch": 0.29818181818181816,
      "grad_norm": 0.14243566989898682,
      "learning_rate": 4.4444444444444447e-05,
      "loss": 0.0189,
      "step": 41
    },
    {
      "epoch": 0.3054545454545455,
      "grad_norm": 0.3042973577976227,
      "learning_rate": 4e-05,
      "loss": 0.1278,
      "step": 42
    },
    {
      "epoch": 0.31272727272727274,
      "grad_norm": 0.13562525808811188,
      "learning_rate": 3.555555555555556e-05,
      "loss": 0.0464,
      "step": 43
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.1902313083410263,
      "learning_rate": 3.111111111111111e-05,
      "loss": 0.0597,
      "step": 44
    },
    {
      "epoch": 0.32727272727272727,
      "grad_norm": 0.1719304621219635,
      "learning_rate": 2.6666666666666667e-05,
      "loss": 0.0628,
      "step": 45
    },
    {
      "epoch": 0.33454545454545453,
      "grad_norm": 0.23821061849594116,
      "learning_rate": 2.2222222222222223e-05,
      "loss": 0.0747,
      "step": 46
    },
    {
      "epoch": 0.3418181818181818,
      "grad_norm": 0.24892407655715942,
      "learning_rate": 1.777777777777778e-05,
      "loss": 0.1119,
      "step": 47
    },
    {
      "epoch": 0.3490909090909091,
      "grad_norm": 52.032657623291016,
      "learning_rate": 1.3333333333333333e-05,
      "loss": 0.2073,
      "step": 48
    },
    {
      "epoch": 0.3563636363636364,
      "grad_norm": 0.20700961351394653,
      "learning_rate": 8.88888888888889e-06,
      "loss": 0.0569,
      "step": 49
    },
    {
      "epoch": 0.36363636363636365,
      "grad_norm": 0.21775314211845398,
      "learning_rate": 4.444444444444445e-06,
      "loss": 0.0803,
      "step": 50
    }
  ],
  "logging_steps": 1,
  "max_steps": 50,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 3.759137069806387e+16,
  "train_batch_size": 16,
  "trial_name": null,
  "trial_params": null
}
