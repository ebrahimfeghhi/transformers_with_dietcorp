{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# Run this once per kernel\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import re\n",
    "import time\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "from edit_distance import SequenceMatcher\n",
    "import torch\n",
    "from dataset import SpeechDataset\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from neural_decoder.dataset import getDatasetLoaders\n",
    "import neural_decoder.lm_utils as lmDecoderUtils\n",
    "from neural_decoder.model import GRUDecoder\n",
    "import pickle\n",
    "import argparse\n",
    "import matplotlib.pyplot as plt\n",
    "from neural_decoder.dataset import getDatasetLoaders\n",
    "import neural_decoder.lm_utils as lmDecoderUtils\n",
    "from neural_decoder.lm_utils import build_llama_1B\n",
    "from neural_decoder.model import GRUDecoder\n",
    "from neural_decoder.bit import BiT_Phoneme\n",
    "import pickle\n",
    "import argparse\n",
    "from lm_utils import _cer_and_wer\n",
    "import json\n",
    "import os\n",
    "import copy\n",
    "from torch.utils.data import Subset\n",
    "from torch.utils.data import ConcatDataset\n",
    "from loss import memo_loss_from_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "saveFolder_data = \"/data/willett_data/paper_results_obi/\"\n",
    "saveFolder_transcripts = \"/data/willett_data/model_transcriptions_comp/\"\n",
    "\n",
    "output_file = 'leia'\n",
    "device = \"cuda:2\"\n",
    "\n",
    "if output_file == 'obi':\n",
    "    model_storage_path = '/data/willett_data/outputs/'\n",
    "elif output_file == 'leia':\n",
    "    model_storage_path = '/data/willett_data/leia_outputs/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_sentence(s):\n",
    "    s = s.lower()\n",
    "    charMarks = ['a','b','c','d','e','f','g','h','i','j','k','l','m','n','o','p','q','r','s','t','u','v','w','x','y','z',\n",
    "                 \"'\", ' ']\n",
    "    ans = []\n",
    "    for i in s:\n",
    "        if(i in charMarks):\n",
    "            ans.append(i)\n",
    "    \n",
    "    return ''.join(ans)\n",
    "\n",
    "\n",
    "base_dir = \"/home3/skaasyap/willett\"\n",
    "\n",
    "load_lm = True\n",
    "# LM decoding hyperparameters\n",
    "acoustic_scale = 0.8\n",
    "blank_penalty = np.log(2)\n",
    "\n",
    "run_for_llm = False\n",
    "\n",
    "if run_for_llm:\n",
    "    return_n_best = True\n",
    "    rescore = False\n",
    "    nbest = 100\n",
    "    print(\"RUNNING IN LLM MODE\")\n",
    "else:\n",
    "    return_n_best = False\n",
    "    rescore = False\n",
    "    nbest = 1\n",
    "    print(\"RUNNING IN N-GRAM MODE\")\n",
    "    \n",
    "if load_lm: \n",
    "        \n",
    "    lmDir = base_dir +'/lm/languageModel'\n",
    "    ngramDecoder = lmDecoderUtils.build_lm_decoder(\n",
    "        lmDir,\n",
    "        acoustic_scale=acoustic_scale, #1.2\n",
    "        nbest=nbest,\n",
    "        beam=18\n",
    "    )\n",
    "    print(\"loaded LM\")\n",
    "    \n",
    "    load_lm = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing to shared output file\n"
     ]
    }
   ],
   "source": [
    "models_to_run = ['neurips_transformer_time_masked_held_out_days_2', \n",
    "                 'neurips_transformer_time_masked_held_out_days_1', \n",
    "                 'neurips_transformer_time_masked_held_out_days']\n",
    "\n",
    "shared_output_file = 'entropy_min'\n",
    "val_save_file = 'entropy_min'\n",
    "seeds_list = [0,1,2,3]\n",
    "\n",
    "\n",
    "if len(shared_output_file) > 0:\n",
    "    print(\"Writing to shared output file\")\n",
    "    write_mode = \"a\"\n",
    "else:\n",
    "    write_mode = \"w\"\n",
    "    \n",
    "evaluate_comp = True\n",
    "run_lm = True\n",
    "\n",
    "memo = True \n",
    "\n",
    "memo_epochs = 1\n",
    "memo_augs = 0\n",
    "if memo_augs:\n",
    "    max_mask_pct = 0.05\n",
    "    num_masks = 20\n",
    "else:\n",
    "    max_mask_pct = 0\n",
    "    num_masks = 0\n",
    "\n",
    "memo_augs = 0\n",
    "\n",
    "nptl_augs = 0\n",
    "nptl_aug_params = [0.2, 0.05] # white noise, constant offset\n",
    "\n",
    "memo_lr = [3e-5, 6e-5, 6e-5]\n",
    "\n",
    "partition = \"competition\" \n",
    "blank_id = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model: neurips_transformer_time_masked_held_out_days_2_seed_0\n",
      "entropy_min_seed_0\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'logits' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 93\u001b[0m\n\u001b[1;32m     90\u001b[0m loss \u001b[39m=\u001b[39m memo_loss_from_logits(logits_aug, adjusted_len, blank_id)\n\u001b[1;32m     92\u001b[0m \u001b[39m# get LI loss \u001b[39;00m\n\u001b[0;32m---> 93\u001b[0m logits \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mconcatenate([logits[:, \u001b[39m1\u001b[39m:], logits[:, \u001b[39m0\u001b[39m:\u001b[39m1\u001b[39m]], axis\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m     95\u001b[0m logits \u001b[39m=\u001b[39m lmDecoderUtils\u001b[39m.\u001b[39mrearrange_speech_logits(logits[\u001b[39mNone\u001b[39;00m, :, :], \n\u001b[1;32m     96\u001b[0m                                                 has_sil\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m     98\u001b[0m decoded \u001b[39m=\u001b[39m lmDecoderUtils\u001b[39m.\u001b[39mlm_decode(ngramDecoder, logits[\u001b[39m0\u001b[39m], \n\u001b[1;32m     99\u001b[0m                             blankPenalty\u001b[39m=\u001b[39mblank_penalty,\n\u001b[1;32m    100\u001b[0m                            returnNBest\u001b[39m=\u001b[39mreturn_n_best, rescore\u001b[39m=\u001b[39mrescore)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'logits' is not defined"
     ]
    }
   ],
   "source": [
    "def get_data_file(path):\n",
    "    suffix_map = {\n",
    "        \"data_log_both\": \"/data/willett_data/ptDecoder_ctc_both\",\n",
    "        \"data\": \"/data/willett_data/ptDecoder_ctc\",\n",
    "        \"data_log_both_held_out_days\": \"/data/willett_data/ptDecoder_ctc_both_held_out_days\",\n",
    "        \"data_log_both_held_out_days_1\": \"/data/willett_data/ptDecoder_ctc_both_held_out_days_1\",\n",
    "        \"data_log_both_held_out_days_2\": \"/data/willett_data/ptDecoder_ctc_both_held_out_days_2\",\n",
    "    }\n",
    "    suffix = path.rsplit('/', 1)[-1]\n",
    "    return suffix_map.get(suffix, path)\n",
    "\n",
    "def reverse_dataset(dataset):\n",
    "    return Subset(dataset, list(reversed(range(len(dataset)))))\n",
    "\n",
    "def get_dataloader(dataset, batch_size=1):\n",
    "    return torch.utils.data.DataLoader(dataset, batch_size=batch_size, \n",
    "                                       shuffle=False, num_workers=0)\n",
    "\n",
    "def decode_sequence(pred, adjusted_len):\n",
    "    pred = torch.argmax(pred[:adjusted_len], dim=-1)\n",
    "    pred = torch.unique_consecutive(pred)\n",
    "    return np.array([i for i in pred.cpu().numpy() if i != 0])\n",
    "\n",
    "\n",
    "for mn, model_name_str in enumerate(models_to_run):\n",
    "    day_cer_dict, total_wer_dict = {}, {}\n",
    "\n",
    "    for seed in seeds_list:\n",
    "        print(f\"Running model: {model_name_str}_seed_{seed}\")\n",
    "        day_cer_dict[seed], total_wer_dict[seed] = [], []\n",
    "\n",
    "        modelPath = f\"{model_storage_path}{model_name_str}_seed_{seed}\"\n",
    "        output_file = f\"{shared_output_file}_seed_{seed}\" if shared_output_file else f\"{model_name_str}_seed_{seed}\"\n",
    "        print(output_file)\n",
    "\n",
    "        with open(f\"{modelPath}/args\", \"rb\") as handle:\n",
    "            args = pickle.load(handle)\n",
    "\n",
    "        data_file = get_data_file(args['datasetPath'])\n",
    "\n",
    "        trainLoaders, testLoaders, loadedData = getDatasetLoaders(data_file, 8)\n",
    "        args.setdefault('mask_token_zero', False)\n",
    "\n",
    "        model = BiT_Phoneme(\n",
    "            patch_size=args['patch_size'], dim=args['dim'], dim_head=args['dim_head'],\n",
    "            nClasses=args['nClasses'], depth=args['depth'], heads=args['heads'],\n",
    "            mlp_dim_ratio=args['mlp_dim_ratio'], dropout=0, input_dropout=0,\n",
    "            look_ahead=args['look_ahead'], gaussianSmoothWidth=args['gaussianSmoothWidth'],\n",
    "            T5_style_pos=args['T5_style_pos'], max_mask_pct=max_mask_pct,\n",
    "            num_masks=num_masks, mask_token_zeros=args['mask_token_zero'], max_mask_channels=0,\n",
    "            num_masks_channels=0, dist_dict_path=None\n",
    "        ).to(device)\n",
    "\n",
    "        model.load_state_dict(torch.load(f\"{modelPath}/modelWeights\", map_location=device), strict=True)\n",
    "        model.eval()\n",
    "\n",
    "        optimizer = torch.optim.AdamW(model.parameters(), lr=memo_lr[mn], weight_decay=0,\n",
    "                                      betas=(args['beta1'], args['beta2']))\n",
    "\n",
    "        for name, p in model.named_parameters():\n",
    "            p.requires_grad = name in {\n",
    "                \"to_patch_embedding.1.weight\", \"to_patch_embedding.1.bias\",\n",
    "                \"to_patch_embedding.2.weight\", \"to_patch_embedding.2.bias\",\n",
    "                \"to_patch_embedding.3.weight\", \"to_patch_embedding.3.bias\"\n",
    "            }\n",
    "\n",
    "        testDayIdxs = np.arange(5)\n",
    "        valDayIdxs = [0, 1, 3, 4, 5] if mn == 2 else [0, 1, 2, 3, 4]\n",
    "\n",
    "        model_outputs = {\"logits\": [], \"logitLengths\": [], \"trueSeqs\": [], \"transcriptions\": []}\n",
    "        total_edit_distance = total_seq_length = 0\n",
    "\n",
    "        for i, testDayIdx in enumerate(testDayIdxs):\n",
    "            ve = valDayIdxs[i]\n",
    "            val_ds = reverse_dataset(SpeechDataset([loadedData['test'][ve]]))\n",
    "            test_ds = reverse_dataset(SpeechDataset([loadedData['competition'][i]]))\n",
    "            combined_ds = ConcatDataset([val_ds, test_ds])\n",
    "            data_loader = get_dataloader(combined_ds)\n",
    "\n",
    "            if memo:\n",
    "                model.train()\n",
    "                for X, y, X_len, y_len, _ in data_loader:\n",
    "                    X, y, X_len, y_len = map(lambda x: x.to(device), [X, y, X_len, y_len])\n",
    "                    dayIdx = torch.tensor([ve], dtype=torch.int64).to(device)\n",
    "                    for _ in range(memo_epochs):\n",
    "                        \n",
    "                        # get memo loss \n",
    "                        logits_aug = model(X, X_len, ve, memo_augs, nptl_augs, nptl_aug_params)\n",
    "                        adjusted_len = model.compute_length(X_len)\n",
    "                        loss = memo_loss_from_logits(logits_aug[1:], adjusted_len, blank_id)\n",
    "                        \n",
    "                        # get LI loss \n",
    "                        logits = logits_aug[0]\n",
    "                        logits = np.concatenate([logits[:, 1:], logits[:, 0:1]], axis=-1)\n",
    "                        \n",
    "                        logits = lmDecoderUtils.rearrange_speech_logits(logits[None, :, :], \n",
    "                                                                        has_sil=True)\n",
    "                        \n",
    "                        decoded = lmDecoderUtils.lm_decode(ngramDecoder, logits[0], \n",
    "                                                    blankPenalty=blank_penalty,\n",
    "                                                   returnNBest=return_n_best, rescore=rescore)\n",
    "                        \n",
    "                        print(decoded)\n",
    "                        optimizer.zero_grad()\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "            model.eval()\n",
    "            day_edit_distance = day_seq_length = 0\n",
    "\n",
    "            with torch.no_grad():\n",
    "                \n",
    "                for i, (X, y, X_len, y_len, _) in enumerate(data_loader):\n",
    "                    \n",
    "                    if i >= len(val_ds):\n",
    "                        break\n",
    "                \n",
    "                    X, y, X_len, y_len = map(lambda x: x.to(device), [X, y, X_len, y_len])\n",
    "                    \n",
    "                    dayIdx = torch.tensor([ve], dtype=torch.int64).to(device)\n",
    "                    pred = model(X, X_len, dayIdx)\n",
    "                    adjustedLens = model.compute_length(X_len)\n",
    "\n",
    "                    for idx in range(pred.shape[0]):\n",
    "                        trueSeq = y[idx][:y_len[idx]].cpu().numpy()\n",
    "                        decoded = decode_sequence(pred[idx], adjustedLens[idx])\n",
    "                        dist = SequenceMatcher(a=trueSeq.tolist(), b=decoded.tolist()).distance()\n",
    "\n",
    "                        total_edit_distance += dist\n",
    "                        total_seq_length += len(trueSeq)\n",
    "                        day_edit_distance += dist\n",
    "                        day_seq_length += len(trueSeq)\n",
    "\n",
    "            day_cer_dict[seed].append(day_edit_distance / day_seq_length)\n",
    "\n",
    "            if evaluate_comp:\n",
    "                \n",
    "                test_ds = SpeechDataset([loadedData[partition][i]])\n",
    "                test_loader = get_dataloader(test_ds)\n",
    "\n",
    "                with torch.no_grad():\n",
    "                    for j, (X, y, X_len, y_len, _) in enumerate(test_loader):\n",
    "                        X, y, X_len, y_len = map(lambda x: x.to(device), [X, y, X_len, y_len])\n",
    "                        dayIdx = torch.tensor([testDayIdx], dtype=torch.int64).to(device)\n",
    "                        pred = model(X, X_len, dayIdx)\n",
    "                        adjustedLens = model.compute_length(X_len)\n",
    "\n",
    "                        for idx in range(pred.shape[0]):\n",
    "                            decoded = decode_sequence(pred[idx], adjustedLens[idx])\n",
    "                            transcript = loadedData[partition][i][\"transcriptions\"][j].strip()\n",
    "                            transcript = re.sub(r\"[^a-zA-Z\\- \\']\", \"\", transcript).replace(\"--\", \"\").lower()\n",
    "\n",
    "                            model_outputs[\"logits\"].append(pred[idx].cpu().numpy())\n",
    "                            model_outputs[\"logitLengths\"].append(adjustedLens[idx].item())\n",
    "                            model_outputs[\"trueSeqs\"].append(y[idx][:y_len[idx]].cpu().numpy())\n",
    "                            model_outputs[\"transcriptions\"].append(transcript)\n",
    "\n",
    "        if run_lm:\n",
    "            print(\"Running LM decoding...\")\n",
    "            nbest_outputs = []\n",
    "            for logits in model_outputs[\"logits\"]:\n",
    "                logits = np.concatenate([logits[:, 1:], logits[:, 0:1]], axis=-1)\n",
    "                logits = lmDecoderUtils.rearrange_speech_logits(logits[None, :, :], has_sil=True)\n",
    "                decoded = lmDecoderUtils.lm_decode(ngramDecoder, logits[0], blankPenalty=blank_penalty,\n",
    "                                                   returnNBest=return_n_best, rescore=rescore)\n",
    "                nbest_outputs.append(decoded)\n",
    "\n",
    "            #if run_for_llm:\n",
    "            #    print(\"SAVING OUTPUTS FOR LLM\")\n",
    "            #    with open(f\"{saveFolder_transcripts}{model_name_str}_seed_{seed}_model_outputs.pkl\", \"wb\") as f:\n",
    "            #        pickle.dump(model_outputs, f)\n",
    "            #    with open(f\"{saveFolder_transcripts}{model_name_str}_seed_{seed}_nbest.pkl\", \"wb\") as f:\n",
    "            #        pickle.dump(nbest_outputs, f)\n",
    "            #else:\n",
    "            model_outputs[\"transcriptions\"] = [convert_sentence(t.strip()) for t in model_outputs[\"transcriptions\"]]\n",
    "            nbest_outputs = [t.strip() for t in nbest_outputs]\n",
    "            cer, wer = _cer_and_wer(nbest_outputs, model_outputs[\"transcriptions\"],\n",
    "                                    outputType='speech', returnCI=True)\n",
    "            total_wer_dict[seed] = wer\n",
    "\n",
    "            out_file = os.path.join(saveFolder_transcripts, output_file)\n",
    "            with open(out_file + '.txt', write_mode, encoding=\"utf-8\") as f:\n",
    "                f.write(\"\\n\".join(nbest_outputs) + \"\\n\")\n",
    "\n",
    "    if val_save_file:\n",
    "        print(f\"SAVING VAL RESULTS FOR {model_name_str}\")\n",
    "        with open(f\"{saveFolder_data}{model_name_str}_{val_save_file}.pkl\", \"wb\") as f:\n",
    "            pickle.dump(day_cer_dict, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "speech-bci",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
