{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home3/ebrahim2/miniconda3/envs/speech-bci/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Run this once per kernel\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import re\n",
    "import time\n",
    "import pickle\n",
    "import numpy as np\n",
    "import sys\n",
    "from edit_distance import SequenceMatcher\n",
    "import torch\n",
    "from dataset import SpeechDataset\n",
    "import matplotlib.pyplot as plt\n",
    "from neural_decoder.dataset import getDatasetLoaders\n",
    "import neural_decoder.lm_utils as lmDecoderUtils\n",
    "from neural_decoder.model import GRUDecoder\n",
    "import pickle\n",
    "import argparse\n",
    "import matplotlib.pyplot as plt\n",
    "from neural_decoder.dataset import getDatasetLoaders\n",
    "import neural_decoder.lm_utils as lmDecoderUtils\n",
    "from neural_decoder.lm_utils import build_llama_1B\n",
    "from neural_decoder.model import GRUDecoder\n",
    "from neural_decoder.bit import BiT_Phoneme\n",
    "import pickle\n",
    "import argparse\n",
    "from lm_utils import _cer_and_wer\n",
    "import json\n",
    "import os\n",
    "import copy\n",
    "from torch.utils.data import ConcatDataset\n",
    "from loss import memo_loss_from_logits, forward_ctc\n",
    "from collections import deque\n",
    "\n",
    "import wandb\n",
    "import math\n",
    "\n",
    "from tta_utils import convert_sentence, compute_lambda, clean_transcription, get_phonemes, get_data_file, reverse_dataset, get_dataloader, decode_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "saveFolder_data = \"/data/willett_data/paper_results_wer/\"\n",
    "saveFolder_transcripts = \"/data/willett_data/model_transcriptions_comp/\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUNNING IN N-GRAM MODE\n",
      "loaded LM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before InitGoogleLogging() is written to STDERR\n",
      "I0616 09:28:23.346814 3598323 brain_speech_decoder.h:52] Reading fst /home3/skaasyap/willett/lm/languageModel/TLG.fst\n",
      "I0616 09:30:48.605950 3598323 brain_speech_decoder.h:81] Reading symbol table /home3/skaasyap/willett/lm/languageModel/words.txt\n"
     ]
    }
   ],
   "source": [
    "base_dir = \"/home3/skaasyap/willett\"\n",
    "\n",
    "load_lm = True\n",
    "\n",
    "# LM decoding hyperparameters\n",
    "acoustic_scale = 0.8\n",
    "blank_penalty = np.log(2)\n",
    "\n",
    "run_for_llm = False\n",
    "\n",
    "if run_for_llm:\n",
    "    return_n_best = True\n",
    "    rescore = False\n",
    "    nbest = 100\n",
    "    print(\"RUNNING IN LLM MODE\")\n",
    "else:\n",
    "    return_n_best = False\n",
    "    rescore = False\n",
    "    nbest = 1\n",
    "    print(\"RUNNING IN N-GRAM MODE\")\n",
    "    \n",
    "if load_lm and 'ngramDecoder' not in globals():\n",
    "        \n",
    "    lmDir = base_dir +'/lm/languageModel'\n",
    "    ngramDecoder = lmDecoderUtils.build_lm_decoder(\n",
    "        lmDir,\n",
    "        acoustic_scale=acoustic_scale, #1.2\n",
    "        nbest=nbest,\n",
    "        beam=18\n",
    "    )\n",
    "    print(\"loaded LM\")\n",
    "    \n",
    "elif load_lm:\n",
    "    print(\"Already loaded LM\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#models_to_run = ['gru_held_out_days_redo']\n",
    "all_models = ['neurips_transformer_time_masked_held_out_days','transformer_held_out_big_0', 'gru_held_out_days_redo']\n",
    "\n",
    "models_to_run = [all_models[1]]\n",
    "\n",
    "shared_output_file = 'transformer_held_out_more_dietcorp'\n",
    "val_save_file = 'transformer_held_out_more_dietcorp'\n",
    "\n",
    "output_file = 'obi'\n",
    "device = \"cuda:2\"\n",
    "\n",
    "if output_file == 'obi':\n",
    "    model_storage_path = '/data/willett_data/outputs/'\n",
    "elif output_file == 'leia':\n",
    "    model_storage_path = '/data/willett_data/leia_outputs/'\n",
    "\n",
    "seeds_list = [0,1,2,3]\n",
    "\n",
    "if len(shared_output_file) > 0:\n",
    "    write_mode = \"a\"\n",
    "else:\n",
    "    write_mode = \"w\"\n",
    "    \n",
    "evaluate_comp = True\n",
    "use_lm = True\n",
    "\n",
    "partition = \"competition\" \n",
    "blank_id = 0\n",
    "num_classes = 41\n",
    "\n",
    "# no tta\n",
    "baseline_args = {\n",
    "    'dropout': 0, \n",
    "    'input_dropout': 0, \n",
    "    'max_mask_pct': 0, \n",
    "    'num_masks': 0, \n",
    "    'gru': False, \n",
    "    'max_day': 14\n",
    "}\n",
    "\n",
    "# corp\n",
    "corp_args = {\n",
    "    'learning_rate': [1e-3], \n",
    "    'repeats': [1],\n",
    "    'adaptation_steps': 1,\n",
    "    'WN+BS': True,\n",
    "    'white_noise': 0.2,\n",
    "    'baseline_shift': 0.05,\n",
    "    'dropout': 0.35, \n",
    "    'input_dropout': 0.2, \n",
    "    'l2_decay': 1e-5, \n",
    "    'max_mask_pct': 0.0, \n",
    "    'num_masks': 0, \n",
    "    'freeze_patch': True,\n",
    "    'gru': False, \n",
    "    'max_day': None\n",
    "}\n",
    "\n",
    "\n",
    "tta_mode = 'corp'\n",
    "\n",
    "if tta_mode == 'corp':\n",
    "    updated_args = corp_args  \n",
    "else:\n",
    "    updated_args = baseline_args\n",
    "\n",
    "skip_models = []\n",
    "skip_seeds = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lm_outputs(tf_logits):\n",
    "    \n",
    "    # prepare logits for n-gram language model decoding \n",
    "    logits_np = tf_logits.detach().cpu().numpy()\n",
    "    logits_np = np.concatenate([\n",
    "        logits_np[:, :, 1:],   # classes 1 to C-1\n",
    "        logits_np[:, :, 0:1]   # class 0, preserved in its own dimension\n",
    "    ], axis=-1)\n",
    "    \n",
    "    logits_np = lmDecoderUtils.rearrange_speech_logits(logits_np, has_sil=True)\n",
    "    \n",
    "    # obtain sentence from n-gram language model \n",
    "    decoded = lmDecoderUtils.lm_decode(\n",
    "        ngramDecoder, logits_np[0],\n",
    "        blankPenalty=blank_penalty,\n",
    "        returnNBest=return_n_best, rescore=rescore\n",
    "    )\n",
    "\n",
    "    decoded = clean_transcription(decoded)\n",
    "    \n",
    "    y_pseudo, y_len_pseudo = get_phonemes(decoded)\n",
    "    \n",
    "    return decoded, y_pseudo, y_len_pseudo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model: transformer_held_out_big_0_seed_0\n",
      "0.001\n",
      "8\n",
      "day  0\n",
      "DAY WER:  0.2897425418880262\n",
      "day  1\n",
      "DAY WER:  0.30851519041506204\n",
      "day  2\n",
      "DAY WER:  0.3243647234678625\n",
      "day  3\n",
      "DAY WER:  0.35055762081784386\n",
      "day  4\n",
      "DAY WER:  0.3456695917588707\n",
      "day  5\n",
      "DAY WER:  0.344225770516153\n",
      "day  6\n",
      "DAY WER:  0.34190347316193054\n",
      "day  7\n",
      "DAY WER:  0.3388811835413777\n",
      "WER ACROSS DAYS:  0.3308304777262649\n",
      "Running model: transformer_held_out_big_0_seed_1\n",
      "0.001\n",
      "8\n",
      "day  0\n",
      "DAY WER:  0.2987331426236208\n",
      "day  1\n",
      "DAY WER:  0.28369704749679076\n",
      "day  2\n",
      "DAY WER:  0.3064275037369208\n",
      "day  3\n",
      "DAY WER:  0.33605947955390336\n",
      "day  4\n",
      "DAY WER:  0.32926363983212514\n",
      "day  5\n",
      "DAY WER:  0.3271444485703676\n",
      "day  6\n",
      "DAY WER:  0.35363103292737935\n",
      "day  7\n",
      "DAY WER:  0.36245954692556637\n",
      "WER ACROSS DAYS:  0.32402741382785727\n",
      "Running model: transformer_held_out_big_0_seed_2\n",
      "0.001\n",
      "8\n",
      "day  0\n",
      "DAY WER:  0.275030649775235\n",
      "day  1\n",
      "DAY WER:  0.28369704749679076\n",
      "day  2\n",
      "DAY WER:  0.3086696562032885\n",
      "day  3\n",
      "DAY WER:  0.32973977695167284\n",
      "day  4\n",
      "DAY WER:  0.35177413201068297\n",
      "day  5\n",
      "DAY WER:  0.32603044931303377\n",
      "day  6\n",
      "DAY WER:  0.35182679296346414\n",
      "day  7\n",
      "DAY WER:  0.3629218677762367\n",
      "WER ACROSS DAYS:  0.3232211247732312\n",
      "Running model: transformer_held_out_big_0_seed_3\n",
      "0.001\n",
      "8\n",
      "day  0\n",
      "DAY WER:  0.2889252145484266\n",
      "day  1\n",
      "DAY WER:  0.3008130081300813\n",
      "day  2\n",
      "DAY WER:  0.3094170403587444\n",
      "day  3\n",
      "DAY WER:  0.3275092936802974\n",
      "day  4\n",
      "DAY WER:  0.33422357878672265\n",
      "day  5\n",
      "DAY WER:  0.32046045302636467\n",
      "day  6\n",
      "DAY WER:  0.3252142534957149\n",
      "day  7\n",
      "DAY WER:  0.32639852057327784\n",
      "WER ACROSS DAYS:  0.3167204192703084\n",
      "SAVING VAL RESULTS FOR transformer_held_out_big_0\n"
     ]
    }
   ],
   "source": [
    "for n_augs in updated_args['repeats']:\n",
    "    \n",
    "    for mn, model_name_str in enumerate(models_to_run):\n",
    "        \n",
    "        if model_name_str in skip_models:\n",
    "            continue\n",
    "        \n",
    "        day_wer_dict, total_wer_dict = {}, {}\n",
    "\n",
    "        for seed in seeds_list:\n",
    "            \n",
    "            if seed in skip_seeds:\n",
    "                continue\n",
    "            \n",
    "            print(f\"Running model: {model_name_str}_seed_{seed}\")\n",
    "            \n",
    "            day_wer_dict[seed] = []\n",
    "\n",
    "            modelPath = f\"{model_storage_path}{model_name_str}_seed_{seed}\"\n",
    "            output_file = f\"{shared_output_file}_seed_{seed}\" if shared_output_file else f\"{model_name_str}_seed_{seed}\"\n",
    "\n",
    "            with open(f\"{modelPath}/args\", \"rb\") as handle:\n",
    "                args = pickle.load(handle)\n",
    "                \n",
    "                \n",
    "            if updated_args['gru']:\n",
    "                \n",
    "                model = GRUDecoder(\n",
    "                    neural_dim=args[\"nInputFeatures\"],\n",
    "                    n_classes=args[\"nClasses\"],\n",
    "                    hidden_dim=args[\"nUnits\"],\n",
    "                    layer_dim=args[\"nLayers\"],\n",
    "                    nDays=args['nDays'],\n",
    "                    dropout=args[\"dropout\"],\n",
    "                    device=device,\n",
    "                    strideLen=args[\"strideLen\"],\n",
    "                    kernelLen=args[\"kernelLen\"],\n",
    "                    gaussianSmoothWidth=args[\"gaussianSmoothWidth\"],\n",
    "                    bidirectional=args[\"bidirectional\"],\n",
    "                    input_dropout=args['input_dropout'], \n",
    "                    max_mask_pct=args['max_mask_pct'],\n",
    "                    num_masks=args['num_masks']\n",
    "                ).to(device)\n",
    "                \n",
    "            else:\n",
    "                \n",
    "                model = BiT_Phoneme(\n",
    "                    patch_size=args['patch_size'], dim=args['dim'], dim_head=args['dim_head'],\n",
    "                    nClasses=args['nClasses'], depth=args['depth'], heads=args['heads'],\n",
    "                    mlp_dim_ratio=args['mlp_dim_ratio'], dropout=updated_args['dropout'], input_dropout=updated_args['input_dropout'],\n",
    "                    look_ahead=args['look_ahead'], gaussianSmoothWidth=args['gaussianSmoothWidth'],\n",
    "                    T5_style_pos=args['T5_style_pos'], max_mask_pct=updated_args['max_mask_pct'],\n",
    "                    num_masks=updated_args['num_masks'], mask_token_zeros=args['mask_token_zero'], max_mask_channels=0,\n",
    "                    num_masks_channels=0, dist_dict_path=None\n",
    "                ).to(device)\n",
    "\n",
    "            data_file = get_data_file(args['datasetPath'])\n",
    "\n",
    "            trainLoader, testLoaders, loadedData = getDatasetLoaders(data_file, 64)\n",
    "                    \n",
    "            args.setdefault('mask_token_zero', False)\n",
    "\n",
    "            model.load_state_dict(torch.load(f\"{modelPath}/modelWeights\", map_location=device), strict=True)\n",
    "\n",
    "            if tta_mode != 'baseline':\n",
    "                print(updated_args['learning_rate'][mn])\n",
    "                optimizer = torch.optim.AdamW(model.parameters(), lr=updated_args['learning_rate'][mn], \n",
    "                                            weight_decay=updated_args['l2_decay'],\n",
    "                                                betas=(args['beta1'], args['beta2']))\n",
    "\n",
    "                if updated_args['freeze_patch']:\n",
    "                    for name, p in model.named_parameters():\n",
    "                        p.requires_grad = name in {\n",
    "                            \"to_patch_embedding.1.weight\", \"to_patch_embedding.1.bias\",\n",
    "                            \"to_patch_embedding.2.weight\", \"to_patch_embedding.2.bias\",\n",
    "                            \"to_patch_embedding.3.weight\", \"to_patch_embedding.3.bias\"\n",
    "                        }\n",
    "\n",
    "            testDayIdxs = np.arange(len(loadedData['test']))\n",
    "            print(len(testDayIdxs))\n",
    "                \n",
    "            model_outputs = {\"logits\": [], \"logitLengths\": [], \"trueSeqs\": [], \"transcriptions\": []}\n",
    "            \n",
    "            decoded_list_all_days = []\n",
    "            transcripts_all_days = []\n",
    "            \n",
    "            for test_day_idx, testDayIdx in enumerate(testDayIdxs):\n",
    "                \n",
    "                print(\"day \", test_day_idx)\n",
    "            \n",
    "                val_ds = SpeechDataset([loadedData['test'][test_day_idx]], return_transcript=True)\n",
    "                data_loader = get_dataloader(val_ds)                        \n",
    "                transcriptions_list = []\n",
    "                decoded_list = []\n",
    "                \n",
    "                test_day_decoded_sents = []\n",
    "                \n",
    "                for trial_idx, (X, y, X_len, y_len, day_idx, transcript) in enumerate(data_loader):\n",
    "                                \n",
    "                    total_start = time.time()\n",
    "                    \n",
    "                    X, y, X_len, y_len = map(lambda x: x.to(device), [X, y, X_len, y_len])\n",
    "                    \n",
    "                    if updated_args['max_day'] is not None:\n",
    "                        day_idx = torch.tensor([updated_args['max_day']], dtype=torch.int64).to(device)\n",
    "                    else:\n",
    "                        day_idx = torch.tensor([day_idx],  dtype=torch.int64).to(device)\n",
    "                        \n",
    "                    adjusted_len = model.compute_length(X_len)\n",
    "                    \n",
    "                    # obtain beam search + LM corrected outputs\n",
    "                    # do this before adaptation on that trial to make \n",
    "                    # sure results are compatabile with a streaming system \n",
    "                    model.eval()\n",
    "                    logits_eval = model(X, X_len, day_idx)\n",
    "                    decoded, y_pseudo, y_len_pseudo = get_lm_outputs(logits_eval)\n",
    "                    \n",
    "                    if tta_mode != 'baseline':\n",
    "                    \n",
    "                        # generate multiple versions of the same input\n",
    "                        if n_augs > 0:\n",
    "                            \n",
    "                            X = X.repeat(n_augs, 1, 1)\n",
    "                            y = y.repeat(n_augs, 1)\n",
    "                            y_len = y_len.repeat(n_augs)\n",
    "                            X_len = X_len.repeat(n_augs)\n",
    "                            adjusted_len = adjusted_len.repeat(n_augs)\n",
    "                            y_pseudo = y_pseudo.unsqueeze(0).repeat(n_augs, 1).to(device) \n",
    "                            y_len_pseudo = y_len_pseudo.repeat(n_augs).to(device)\n",
    "                            \n",
    "                        \n",
    "                        # add white noise and baseline shift augmentations to each sample\n",
    "                        if updated_args['WN+BS'] == True:\n",
    "                            \n",
    "                            X += torch.randn(X.shape, \n",
    "                                        device=device) * updated_args['white_noise']\n",
    "                        \n",
    "                            X += (\n",
    "                                torch.randn([X.shape[0], 1, X.shape[2]], \n",
    "                                device=device)\n",
    "                                * updated_args['baseline_shift']\n",
    "                            )      \n",
    "                        \n",
    "                            \n",
    "                        model.train()\n",
    "\n",
    "                        for _ in range(updated_args['adaptation_steps']):\n",
    "                    \n",
    "                            logits = model(X, X_len, day_idx)\n",
    "                            \n",
    "                            corp_loss = forward_ctc(logits, adjusted_len, y_pseudo, y_len_pseudo)\n",
    "                            \n",
    "                            optimizer.zero_grad()\n",
    "                            corp_loss.backward()\n",
    "                            optimizer.step()\n",
    "        \n",
    "                    model.eval()\n",
    "                    \n",
    "                    decoded_list.append(decoded)\n",
    "                    transcriptions_list.append(clean_transcription(transcript[0]))\n",
    "                        \n",
    "                _, wer = _cer_and_wer(decoded_list, transcriptions_list, outputType=\"speech\", returnCI=False)\n",
    "                print(\"DAY WER: \", wer)\n",
    "                day_wer_dict[seed].append(wer)\n",
    "                \n",
    "                decoded_list_all_days.extend(decoded_list)\n",
    "                transcripts_all_days.extend(transcriptions_list)\n",
    "                \n",
    "            _, wer_total = _cer_and_wer(decoded_list_all_days, transcripts_all_days, outputType=\"speech\", returnCI=False)\n",
    "            total_wer_dict[seed] = wer_total\n",
    "            print(\"WER ACROSS DAYS: \", wer_total)\n",
    "            \n",
    "\n",
    "        if val_save_file:\n",
    "            \n",
    "            val_save_file_updated = val_save_file.replace(\"dietcorp\", f\"diet{n_augs}corp\")\n",
    "            \n",
    "            print(f\"SAVING VAL RESULTS FOR {model_name_str}\")\n",
    "            with open(f\"{saveFolder_data}{model_name_str}_{val_save_file_updated}.pkl\", \"wb\") as f:\n",
    "                pickle.dump(day_wer_dict, f)\n",
    "            with open(f\"{saveFolder_data}{model_name_str}_{val_save_file_updated}_all_days.pkl\", \"wb\") as f:\n",
    "                pickle.dump(total_wer_dict, f)\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "speech-bci",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
