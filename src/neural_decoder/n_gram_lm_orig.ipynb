{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import time\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "from edit_distance import SequenceMatcher\n",
    "import torch\n",
    "from dataset import SpeechDataset\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from neural_decoder.dataset import getDatasetLoaders\n",
    "import neural_decoder.lm_utils as lmDecoderUtils\n",
    "from neural_decoder.model import GRUDecoder\n",
    "import pickle\n",
    "import argparse\n",
    "import matplotlib.pyplot as plt\n",
    "from neural_decoder.dataset import getDatasetLoaders\n",
    "import neural_decoder.lm_utils as lmDecoderUtils\n",
    "from neural_decoder.lm_utils import build_llama_1B\n",
    "from neural_decoder.model import GRUDecoder\n",
    "from neural_decoder.bit import BiT_Phoneme\n",
    "import pickle\n",
    "import argparse\n",
    "from lm_utils import _cer_and_wer\n",
    "import json\n",
    "import os\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_sentence(s):\n",
    "    s = s.lower()\n",
    "    charMarks = ['a','b','c','d','e','f','g','h','i','j','k','l','m','n','o','p','q','r','s','t','u','v','w','x','y','z',\n",
    "                 \"'\", ' ']\n",
    "    ans = []\n",
    "    for i in s:\n",
    "        if(i in charMarks):\n",
    "            ans.append(i)\n",
    "    \n",
    "    return ''.join(ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file = '/data/willett_data/ptDecoder_ctc_both'\n",
    "device = \"cuda:2\"\n",
    "\n",
    "modelPath = \"/data/willett_data/outputs/neurips_gru_baseline_seed_1/\"\n",
    "\n",
    "with open(modelPath + \"/args\", \"rb\") as handle:\n",
    "            args = pickle.load(handle)\n",
    "\n",
    "if 'max_mask_pct' not in args:\n",
    "    args['max_mask_pct'] = 0\n",
    "if 'num_masks' not in args:\n",
    "    args['num_masks'] = 0\n",
    "if 'input_dropout' not in args:\n",
    "    args['input_dropout'] = 0\n",
    "                \n",
    "model = GRUDecoder(\n",
    "        neural_dim=args[\"nInputFeatures\"],\n",
    "        n_classes=args[\"nClasses\"],\n",
    "        hidden_dim=args[\"nUnits\"],\n",
    "        layer_dim=args[\"nLayers\"],\n",
    "        nDays=args['nDays'],\n",
    "        dropout=args[\"dropout\"],\n",
    "        device=device,\n",
    "        strideLen=args[\"strideLen\"],\n",
    "        kernelLen=args[\"kernelLen\"],\n",
    "        gaussianSmoothWidth=args[\"gaussianSmoothWidth\"],\n",
    "        bidirectional=args[\"bidirectional\"],\n",
    "        input_dropout=args['input_dropout'], \n",
    "        max_mask_pct=args['max_mask_pct'],\n",
    "        num_masks=args['num_masks']\n",
    "    ).to(device)\n",
    "\n",
    "\n",
    "\n",
    "model_outputs = {\n",
    "    \"logits\": [],\n",
    "    \"logitLengths\": [],\n",
    "    \"trueSeqs\": [],\n",
    "    \"transcriptions\": [],\n",
    "}\n",
    "\n",
    "trainLoaders, testLoaders, loadedData = getDatasetLoaders(data_file, 8)\n",
    "partition = \"competition\" # \"test\"\n",
    "if partition == \"competition\":\n",
    "    testDayIdxs = [4, 5, 6, 7, 8, 9, 10, 12, 13, 14, 15, 16, 18, 19, 20]\n",
    "elif partition == \"test\":\n",
    "    testDayIdxs = range(len(loadedData[partition]))\n",
    "\n",
    "for i, testDayIdx in enumerate(testDayIdxs):\n",
    "    test_ds = SpeechDataset([loadedData[partition][i]])\n",
    "    test_loader = torch.utils.data.DataLoader(\n",
    "        test_ds, batch_size=1, shuffle=False, num_workers=0\n",
    "    )\n",
    "    for j, (X, y, X_len, y_len, _) in enumerate(test_loader):\n",
    "        X, y, X_len, y_len, dayIdx = (\n",
    "            X.to(device),\n",
    "            y.to(device),\n",
    "            X_len.to(device),\n",
    "            y_len.to(device),\n",
    "            torch.tensor([testDayIdx], dtype=torch.int64).to(device),\n",
    "        )\n",
    "        pred = model.forward(X, X_len, dayIdx)\n",
    "        adjustedLens = ((X_len - model.kernelLen) / model.strideLen).to(torch.int32)\n",
    "\n",
    "        for iterIdx in range(pred.shape[0]):\n",
    "            trueSeq = np.array(y[iterIdx][0 : y_len[iterIdx]].cpu().detach())\n",
    "\n",
    "            model_outputs[\"logits\"].append(pred[iterIdx].cpu().detach().numpy())\n",
    "            model_outputs[\"logitLengths\"].append(\n",
    "                adjustedLens[iterIdx].cpu().detach().item()\n",
    "            )\n",
    "            model_outputs[\"trueSeqs\"].append(trueSeq)\n",
    "\n",
    "        transcript = loadedData[partition][i][\"transcriptions\"][j].strip()\n",
    "        transcript = re.sub(r\"[^a-zA-Z\\- \\']\", \"\", transcript)\n",
    "        transcript = transcript.replace(\"--\", \"\").lower()\n",
    "        model_outputs[\"transcriptions\"].append(transcript)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded LM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before InitGoogleLogging() is written to STDERR\n",
      "I0628 11:38:01.393167 3990267 brain_speech_decoder.h:52] Reading fst /home3/skaasyap/willett/lm/languageModel/TLG.fst\n",
      "I0628 11:40:34.564733 3990267 brain_speech_decoder.h:81] Reading symbol table /home3/skaasyap/willett/lm/languageModel/words.txt\n"
     ]
    }
   ],
   "source": [
    "base_dir = \"/home3/skaasyap/willett\"\n",
    "acoustic_scale = 0.8\n",
    "nbest = 10\n",
    "lmDir = base_dir +'/lm/languageModel'\n",
    "ngramDecoder = lmDecoderUtils.build_lm_decoder(\n",
    "    lmDir,\n",
    "    acoustic_scale=acoustic_scale, #1.2\n",
    "    nbest=nbest,\n",
    "    beam=18\n",
    ")\n",
    "print(\"loaded LM\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "blank_penalty = np.log(2)\n",
    "llm_outputs = []\n",
    "# Generate nbest outputs from 5gram LM\n",
    "start_t = time.time()\n",
    "nbest_outputs = []\n",
    "for j in range(len(model_outputs[\"logits\"])):\n",
    "    logits = model_outputs[\"logits\"][j]\n",
    "    logits = np.concatenate(\n",
    "        [logits[:, 1:], logits[:, 0:1]], axis=-1\n",
    "    )  # Blank is last token\n",
    "    logits = lmDecoderUtils.rearrange_speech_logits(logits[None, :, :], has_sil=True)\n",
    "    nbest = lmDecoderUtils.lm_decode(\n",
    "        ngramDecoder,\n",
    "        logits[0],\n",
    "        blankPenalty=blank_penalty,\n",
    "        returnNBest=True,\n",
    "        rescore=True,\n",
    "    )\n",
    "    nbest_outputs.append(nbest)\n",
    "time_per_sample = (time.time() - start_t) / len(model_outputs[\"logits\"])\n",
    "print(f\"5gram decoding took {time_per_sample} seconds per sample\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "speech3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
