{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home3/ebrahim2/miniconda3/envs/speech-bci/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "base_dir = \"/home3/skaasyap/willett\"\n",
    "batch_size=8\n",
    "device = 'cuda:0'\n",
    "# sentence_path = '/home3/skaasyap/my_list.pkl'\n",
    "\n",
    "import numpy as np\n",
    "import neural_decoder.lm_utils as utils\n",
    "from neural_decoder.dataset import getDatasetLoaders\n",
    "# from neural_decoder.load_models import loadModel, loadTransformerModel, run_forward, run_ngram_model, convert_sentence, original_forward\n",
    "import pickle\n",
    "import wandb\n",
    "import os\n",
    "\n",
    "# with open(sentence_path, 'rb') as f:\n",
    "#     ground_truth_sentences = pickle.load(f)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before InitGoogleLogging() is written to STDERR\n",
      "I0509 10:46:24.108592 1140766 brain_speech_decoder.h:52] Reading fst /home3/skaasyap/willett/lm/languageModel/TLG.fst\n",
      "I0509 10:48:51.937197 1140766 brain_speech_decoder.h:81] Reading symbol table /home3/skaasyap/willett/lm/languageModel/words.txt\n"
     ]
    }
   ],
   "source": [
    "lmDir = base_dir+'/lm/languageModel'\n",
    "ngramDecoder = utils.build_lm_decoder(\n",
    "    lmDir,\n",
    "    acoustic_scale=0.8, #1.2\n",
    "    nbest=1,\n",
    "    beam=18\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ground_truth_sentences' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m model_types\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39mt\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m      5\u001b[0m ground_truths \u001b[39m=\u001b[39m []\n\u001b[0;32m----> 6\u001b[0m ground_truths\u001b[39m.\u001b[39mappend(ground_truth_sentences)\n\u001b[1;32m      7\u001b[0m \u001b[39m# modelNames = ['neurips_transformer_time_masked_seed_0', 'neurips_gru_long_runs_seed_1', 'neurips_gru_long_runs_seed_2', 'neurips_gru_long_runs_seed_3']\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[39m# dataPath_list = ['/home3/skaasyap/willett/data', '/home3/skaasyap/willett/data', '/home3/skaasyap/willett/data', '/home3/skaasyap/willett/data']\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[39m# model_types = ['r', 'r', 'r', 'r'] #transformer or rnn for each path\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ground_truth_sentences' is not defined"
     ]
    }
   ],
   "source": [
    "modelPath = '/home3/skaasyap/willett/outputs/'\n",
    "modelNames = ['neurips_transformer_time_masked_seed_5']\n",
    "dataPath_list = ['/home3/skaasyap/willett/data_log_both']\n",
    "model_types=['t']\n",
    "ground_truths = []\n",
    "ground_truths.append(ground_truth_sentences)\n",
    "# modelNames = ['neurips_transformer_time_masked_seed_0', 'neurips_gru_long_runs_seed_1', 'neurips_gru_long_runs_seed_2', 'neurips_gru_long_runs_seed_3']\n",
    "# dataPath_list = ['/home3/skaasyap/willett/data', '/home3/skaasyap/willett/data', '/home3/skaasyap/willett/data', '/home3/skaasyap/willett/data']\n",
    "# model_types = ['r', 'r', 'r', 'r'] #transformer or rnn for each path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_dirs = [\"/home3/skaasyap/willett/outputs/\", \"/home3/skaasyap/willett/outputs/\",  \"/home3/skaasyap/willett/outputs/\", \"/home3/skaasyap/willett/outputs/\"]\n",
    "# model_names = [\"neurips_transformer_ablation_no_data_log_seed_\", \"neurips_transformer_ablation_no_AdamW_seed_\", \"neurips_transformer_time_masked_10_15_seed_\", \"neurips_transformer_time_masked_15_10_seed_\"]\n",
    "# data_paths = [\"/home3/skaasyap/willett/data\", \"/home3/skaasyap/willett/data_log_both\", \"/home3/skaasyap/willett/data_log_both\", \"/home3/skaasyap/willett/data_log_both\"]\n",
    "# model_types = ['t', 't', 't', 't']\n",
    "# restricted_days_vals = [[], [], [], []]\n",
    "# num_models_counts = [4, 4, 4, 4]\n",
    "model_dirs = [\"/home3/skaasyap/willett/obi_models/outputs/\"]\n",
    "model_names = [\"neurips_gru_data_log_time_masked_lr_schedule_seed_\"]\n",
    "data_paths = [\"/home3/skaasyap/willett/data_log_both\"]\n",
    "model_types = ['r']\n",
    "restricted_days_vals = [[]]\n",
    "num_models_counts = [9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir_list = []\n",
    "model_name_list = []\n",
    "data_path_list = []\n",
    "restricted_days_list = []\n",
    "model_types_list = []\n",
    "for i in range(len(num_models_counts)):\n",
    "    for j in range(num_models_counts[i]):\n",
    "        model_dir_list.append(model_dirs[i])\n",
    "        model_name_list.append(model_names[i] + str(j))\n",
    "        data_path_list.append(data_paths[i])\n",
    "        restricted_days_list.append(restricted_days_vals[i])\n",
    "        model_types_list.append(model_types[i])\n",
    "        \n",
    "\n",
    "# for i in range(0, 4):\n",
    "#     model_name = \"neurips_transformer_time_masked_restricted_days_seed_\" + str(i)\n",
    "#     modelNames.append(model_name)\n",
    "#     dataPath_list.append(\"/home3/skaasyap/willett/data_log_both\")\n",
    "#     model_types.append('t')\n",
    "\n",
    "# for i in range(0, 4):\n",
    "#     model_name = \"neurips_transformer_time_masked_ventral_6v_only_seed_\" + str(i)\n",
    "#     modelNames.append(model_name)\n",
    "#     dataPath_list.append(\"/home3/skaasyap/willett/data_log_both\")\n",
    "#     model_types.append('t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import DataLoader\n",
    "from dataset import SpeechDataset\n",
    "\n",
    "def getDatasetLoadersLocal(\n",
    "    datasetName,\n",
    "    batchSize, \n",
    "    restricted_days=[]\n",
    "):\n",
    "    with open(datasetName, \"rb\") as handle:\n",
    "        loadedData = pickle.load(handle)\n",
    "\n",
    "    def _padding(batch):\n",
    "        X, y, X_lens, y_lens, days = zip(*batch)\n",
    "        X_padded = pad_sequence(X, batch_first=True, padding_value=0)\n",
    "        y_padded = pad_sequence(y, batch_first=True, padding_value=0)\n",
    "\n",
    "        return (\n",
    "            X_padded,\n",
    "            y_padded,\n",
    "            torch.stack(X_lens),\n",
    "            torch.stack(y_lens),\n",
    "            torch.stack(days),\n",
    "        )\n",
    "        \n",
    "  \n",
    "    train_ds = SpeechDataset(loadedData[\"train\"], transform=None, restricted_days=restricted_days)\n",
    "    test_ds = SpeechDataset(loadedData[\"test\"], restricted_days=restricted_days)\n",
    "    comp_data = SpeechDataset(loadedData[\"competition\"], restricted_days = restricted_days)\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "        train_ds,\n",
    "        batch_size=batchSize,\n",
    "        shuffle=True,\n",
    "        num_workers=0,\n",
    "        pin_memory=True,\n",
    "        collate_fn=_padding,\n",
    "    )\n",
    "        \n",
    "    test_loader = DataLoader(\n",
    "        test_ds,\n",
    "        batch_size=batchSize,\n",
    "        shuffle=False,\n",
    "        num_workers=0,\n",
    "        pin_memory=True,\n",
    "        collate_fn=_padding,\n",
    "    )\n",
    "\n",
    "    comp_loader = DataLoader(\n",
    "        comp_data,\n",
    "        batch_size=batchSize,\n",
    "        shuffle=False,\n",
    "        num_workers=0,\n",
    "        pin_memory=True,\n",
    "        collate_fn=_padding,\n",
    "    )\n",
    "\n",
    "    return train_loader, test_loader, comp_loader, loadedData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24\n"
     ]
    }
   ],
   "source": [
    "print(len(loadedData['test']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/home3/skaasyap/willett/data_log_both\", \"rb\") as handle:\n",
    "    loadedData = pickle.load(handle)\n",
    "restricted_days = [15, 16, 17, 18, 19, 20]\n",
    "ground_truth_sentences = []\n",
    "for i in range(len(loadedData['test'])):\n",
    "    if i not in restricted_days:\n",
    "        continue\n",
    "    cur_data = loadedData['test'][i]\n",
    "    for i in range(len(cur_data['transcriptions'])):\n",
    "        ground_truth_sentences.append(cur_data['transcriptions'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "240\n"
     ]
    }
   ],
   "source": [
    "print(len(ground_truth_sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir_list = []\n",
    "model_name_list = []\n",
    "data_path_list = []\n",
    "restricted_days_list = []\n",
    "model_types_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Runnning for neurips_gru_data_log_time_masked_lr_schedule_seed_0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mskaasyap\u001b[0m (\u001b[33mbrain_mae\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.9"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home3/skaasyap/willett/neural_seq_decoder/src/neural_decoder/wandb/run-20250508_043014-10glldwi</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/skaasyap-ucla/Language%20Model/runs/10glldwi' target=\"_blank\">neurips_gru_data_log_time_masked_lr_schedule_seed_0</a></strong> to <a href='https://wandb.ai/skaasyap-ucla/Language%20Model' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/skaasyap-ucla/Language%20Model' target=\"_blank\">https://wandb.ai/skaasyap-ucla/Language%20Model</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/skaasyap-ucla/Language%20Model/runs/10glldwi' target=\"_blank\">https://wandb.ai/skaasyap-ucla/Language%20Model/runs/10glldwi</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home3/skaasyap/miniconda3/envs/willett/lib/python3.9/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3190.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
      "/home3/skaasyap/willett/neural_seq_decoder/src/neural_decoder/augmentations.py:170: UserWarning: Using padding='same' with even kernel lengths and odd dilation may require a zero-padded copy of the input be created (Triggered internally at ../aten/src/ATen/native/Convolution.cpp:895.)\n",
      "  return self.conv(input, weight=self.weight, groups=self.groups, padding=\"same\")\n",
      "/home3/skaasyap/willett/neural_seq_decoder/src/neural_decoder/load_models.py:128: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(pred[iterIdx, 0 : adjustedLens[iterIdx], :]),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ctc loss: 0.741696, cer: 0.161033\n",
      "880 880\n",
      "cer: (0.11804016997784476, 0.1091026106612232, 0.12712668361360016)\n",
      "wer: (0.1740316421167485, 0.16068189230969823, 0.1879085264841552)\n",
      "Runnning for neurips_gru_data_log_time_masked_lr_schedule_seed_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m The nbformat package was not found. It is required to save notebook history.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">neurips_gru_data_log_time_masked_lr_schedule_seed_0</strong> at: <a href='https://wandb.ai/skaasyap-ucla/Language%20Model/runs/10glldwi' target=\"_blank\">https://wandb.ai/skaasyap-ucla/Language%20Model/runs/10glldwi</a><br> View project at: <a href='https://wandb.ai/skaasyap-ucla/Language%20Model' target=\"_blank\">https://wandb.ai/skaasyap-ucla/Language%20Model</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250508_043014-10glldwi/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.9"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home3/skaasyap/willett/neural_seq_decoder/src/neural_decoder/wandb/run-20250508_043104-phc2vm5y</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/skaasyap-ucla/Language%20Model/runs/phc2vm5y' target=\"_blank\">neurips_gru_data_log_time_masked_lr_schedule_seed_1</a></strong> to <a href='https://wandb.ai/skaasyap-ucla/Language%20Model' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/skaasyap-ucla/Language%20Model' target=\"_blank\">https://wandb.ai/skaasyap-ucla/Language%20Model</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/skaasyap-ucla/Language%20Model/runs/phc2vm5y' target=\"_blank\">https://wandb.ai/skaasyap-ucla/Language%20Model/runs/phc2vm5y</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home3/skaasyap/willett/neural_seq_decoder/src/neural_decoder/load_models.py:128: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(pred[iterIdx, 0 : adjustedLens[iterIdx], :]),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ctc loss: 0.750017, cer: 0.160208\n",
      "880 880\n",
      "cer: (0.11771328950713689, 0.10845752242450289, 0.1273171150870996)\n",
      "wer: (0.17312238588834333, 0.15960286318811454, 0.1872583847286348)\n",
      "Runnning for neurips_gru_data_log_time_masked_lr_schedule_seed_2\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">neurips_gru_data_log_time_masked_lr_schedule_seed_1</strong> at: <a href='https://wandb.ai/skaasyap-ucla/Language%20Model/runs/phc2vm5y' target=\"_blank\">https://wandb.ai/skaasyap-ucla/Language%20Model/runs/phc2vm5y</a><br> View project at: <a href='https://wandb.ai/skaasyap-ucla/Language%20Model' target=\"_blank\">https://wandb.ai/skaasyap-ucla/Language%20Model</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250508_043104-phc2vm5y/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.9"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home3/skaasyap/willett/neural_seq_decoder/src/neural_decoder/wandb/run-20250508_043148-imd0230w</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/skaasyap-ucla/Language%20Model/runs/imd0230w' target=\"_blank\">neurips_gru_data_log_time_masked_lr_schedule_seed_2</a></strong> to <a href='https://wandb.ai/skaasyap-ucla/Language%20Model' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/skaasyap-ucla/Language%20Model' target=\"_blank\">https://wandb.ai/skaasyap-ucla/Language%20Model</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/skaasyap-ucla/Language%20Model/runs/imd0230w' target=\"_blank\">https://wandb.ai/skaasyap-ucla/Language%20Model/runs/imd0230w</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home3/skaasyap/willett/neural_seq_decoder/src/neural_decoder/load_models.py:128: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(pred[iterIdx, 0 : adjustedLens[iterIdx], :]),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ctc loss: 0.750989, cer: 0.160827\n",
      "880 880\n",
      "cer: (0.1181491301347474, 0.10910490468109844, 0.12741400780528284)\n",
      "wer: (0.17494089834515367, 0.16145438091320444, 0.1888124547429399)\n",
      "Runnning for neurips_gru_data_log_time_masked_lr_schedule_seed_3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m The nbformat package was not found. It is required to save notebook history.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">neurips_gru_data_log_time_masked_lr_schedule_seed_2</strong> at: <a href='https://wandb.ai/skaasyap-ucla/Language%20Model/runs/imd0230w' target=\"_blank\">https://wandb.ai/skaasyap-ucla/Language%20Model/runs/imd0230w</a><br> View project at: <a href='https://wandb.ai/skaasyap-ucla/Language%20Model' target=\"_blank\">https://wandb.ai/skaasyap-ucla/Language%20Model</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250508_043148-imd0230w/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.9"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home3/skaasyap/willett/neural_seq_decoder/src/neural_decoder/wandb/run-20250508_043234-wo5bu6n4</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/skaasyap-ucla/Language%20Model/runs/wo5bu6n4' target=\"_blank\">neurips_gru_data_log_time_masked_lr_schedule_seed_3</a></strong> to <a href='https://wandb.ai/skaasyap-ucla/Language%20Model' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/skaasyap-ucla/Language%20Model' target=\"_blank\">https://wandb.ai/skaasyap-ucla/Language%20Model</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/skaasyap-ucla/Language%20Model/runs/wo5bu6n4' target=\"_blank\">https://wandb.ai/skaasyap-ucla/Language%20Model/runs/wo5bu6n4</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home3/skaasyap/willett/neural_seq_decoder/src/neural_decoder/load_models.py:128: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(pred[iterIdx, 0 : adjustedLens[iterIdx], :]),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ctc loss: 0.741164, cer: 0.160043\n",
      "880 880\n",
      "cer: (0.11589728689209312, 0.10686920922883919, 0.12500011277110173)\n",
      "wer: (0.1718494271685761, 0.15872726073330828, 0.1853679670459373)\n",
      "Runnning for neurips_gru_data_log_time_masked_lr_schedule_seed_4\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">neurips_gru_data_log_time_masked_lr_schedule_seed_3</strong> at: <a href='https://wandb.ai/skaasyap-ucla/Language%20Model/runs/wo5bu6n4' target=\"_blank\">https://wandb.ai/skaasyap-ucla/Language%20Model/runs/wo5bu6n4</a><br> View project at: <a href='https://wandb.ai/skaasyap-ucla/Language%20Model' target=\"_blank\">https://wandb.ai/skaasyap-ucla/Language%20Model</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250508_043234-wo5bu6n4/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.9"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home3/skaasyap/willett/neural_seq_decoder/src/neural_decoder/wandb/run-20250508_043318-p7tqhaei</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/skaasyap-ucla/Language%20Model/runs/p7tqhaei' target=\"_blank\">neurips_gru_data_log_time_masked_lr_schedule_seed_4</a></strong> to <a href='https://wandb.ai/skaasyap-ucla/Language%20Model' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/skaasyap-ucla/Language%20Model' target=\"_blank\">https://wandb.ai/skaasyap-ucla/Language%20Model</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/skaasyap-ucla/Language%20Model/runs/p7tqhaei' target=\"_blank\">https://wandb.ai/skaasyap-ucla/Language%20Model/runs/p7tqhaei</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home3/skaasyap/willett/neural_seq_decoder/src/neural_decoder/load_models.py:128: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(pred[iterIdx, 0 : adjustedLens[iterIdx], :]),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ctc loss: 0.744886, cer: 0.161487\n",
      "880 880\n",
      "cer: (0.11600624704899574, 0.10706600411336901, 0.12541066215689772)\n",
      "wer: (0.16784869976359337, 0.15496814274909076, 0.18123746099060267)\n",
      "Runnning for neurips_gru_data_log_time_masked_lr_schedule_seed_5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m The nbformat package was not found. It is required to save notebook history.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">neurips_gru_data_log_time_masked_lr_schedule_seed_4</strong> at: <a href='https://wandb.ai/skaasyap-ucla/Language%20Model/runs/p7tqhaei' target=\"_blank\">https://wandb.ai/skaasyap-ucla/Language%20Model/runs/p7tqhaei</a><br> View project at: <a href='https://wandb.ai/skaasyap-ucla/Language%20Model' target=\"_blank\">https://wandb.ai/skaasyap-ucla/Language%20Model</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250508_043318-p7tqhaei/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.9"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home3/skaasyap/willett/neural_seq_decoder/src/neural_decoder/wandb/run-20250508_043404-dyirdr89</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/skaasyap-ucla/Language%20Model/runs/dyirdr89' target=\"_blank\">neurips_gru_data_log_time_masked_lr_schedule_seed_5</a></strong> to <a href='https://wandb.ai/skaasyap-ucla/Language%20Model' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/skaasyap-ucla/Language%20Model' target=\"_blank\">https://wandb.ai/skaasyap-ucla/Language%20Model</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/skaasyap-ucla/Language%20Model/runs/dyirdr89' target=\"_blank\">https://wandb.ai/skaasyap-ucla/Language%20Model/runs/dyirdr89</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home3/skaasyap/willett/neural_seq_decoder/src/neural_decoder/load_models.py:128: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(pred[iterIdx, 0 : adjustedLens[iterIdx], :]),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ctc loss: 0.743850, cer: 0.160167\n",
      "880 880\n",
      "cer: (0.11862129081465878, 0.10911814512417824, 0.12797241797737402)\n",
      "wer: (0.17330423713402437, 0.15967551530634175, 0.18718727451747227)\n",
      "Runnning for neurips_gru_data_log_time_masked_lr_schedule_seed_6\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">neurips_gru_data_log_time_masked_lr_schedule_seed_5</strong> at: <a href='https://wandb.ai/skaasyap-ucla/Language%20Model/runs/dyirdr89' target=\"_blank\">https://wandb.ai/skaasyap-ucla/Language%20Model/runs/dyirdr89</a><br> View project at: <a href='https://wandb.ai/skaasyap-ucla/Language%20Model' target=\"_blank\">https://wandb.ai/skaasyap-ucla/Language%20Model</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250508_043404-dyirdr89/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.9"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home3/skaasyap/willett/neural_seq_decoder/src/neural_decoder/wandb/run-20250508_043449-c3ughl5n</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/skaasyap-ucla/Language%20Model/runs/c3ughl5n' target=\"_blank\">neurips_gru_data_log_time_masked_lr_schedule_seed_6</a></strong> to <a href='https://wandb.ai/skaasyap-ucla/Language%20Model' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/skaasyap-ucla/Language%20Model' target=\"_blank\">https://wandb.ai/skaasyap-ucla/Language%20Model</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/skaasyap-ucla/Language%20Model/runs/c3ughl5n' target=\"_blank\">https://wandb.ai/skaasyap-ucla/Language%20Model/runs/c3ughl5n</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home3/skaasyap/willett/neural_seq_decoder/src/neural_decoder/load_models.py:128: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(pred[iterIdx, 0 : adjustedLens[iterIdx], :]),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ctc loss: 0.748968, cer: 0.159919\n",
      "880 880\n",
      "cer: (0.11789488976864126, 0.1089219560428215, 0.12717705869433343)\n",
      "wer: (0.17148572467721404, 0.15847363319128768, 0.1852315622422285)\n",
      "Runnning for neurips_gru_data_log_time_masked_lr_schedule_seed_7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m The nbformat package was not found. It is required to save notebook history.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">neurips_gru_data_log_time_masked_lr_schedule_seed_6</strong> at: <a href='https://wandb.ai/skaasyap-ucla/Language%20Model/runs/c3ughl5n' target=\"_blank\">https://wandb.ai/skaasyap-ucla/Language%20Model/runs/c3ughl5n</a><br> View project at: <a href='https://wandb.ai/skaasyap-ucla/Language%20Model' target=\"_blank\">https://wandb.ai/skaasyap-ucla/Language%20Model</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250508_043449-c3ughl5n/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.9"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home3/skaasyap/willett/neural_seq_decoder/src/neural_decoder/wandb/run-20250508_043535-vrsgbd48</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/skaasyap-ucla/Language%20Model/runs/vrsgbd48' target=\"_blank\">neurips_gru_data_log_time_masked_lr_schedule_seed_7</a></strong> to <a href='https://wandb.ai/skaasyap-ucla/Language%20Model' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/skaasyap-ucla/Language%20Model' target=\"_blank\">https://wandb.ai/skaasyap-ucla/Language%20Model</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/skaasyap-ucla/Language%20Model/runs/vrsgbd48' target=\"_blank\">https://wandb.ai/skaasyap-ucla/Language%20Model/runs/vrsgbd48</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home3/skaasyap/willett/neural_seq_decoder/src/neural_decoder/load_models.py:128: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(pred[iterIdx, 0 : adjustedLens[iterIdx], :]),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ctc loss: 0.756078, cer: 0.158805\n",
      "880 880\n",
      "cer: (0.12032833327279992, 0.11156078415551725, 0.12951264779429655)\n",
      "wer: (0.17694126204764501, 0.16404445237743784, 0.19044222100143882)\n",
      "Runnning for neurips_gru_data_log_time_masked_lr_schedule_seed_8\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">neurips_gru_data_log_time_masked_lr_schedule_seed_7</strong> at: <a href='https://wandb.ai/skaasyap-ucla/Language%20Model/runs/vrsgbd48' target=\"_blank\">https://wandb.ai/skaasyap-ucla/Language%20Model/runs/vrsgbd48</a><br> View project at: <a href='https://wandb.ai/skaasyap-ucla/Language%20Model' target=\"_blank\">https://wandb.ai/skaasyap-ucla/Language%20Model</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250508_043535-vrsgbd48/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.9"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home3/skaasyap/willett/neural_seq_decoder/src/neural_decoder/wandb/run-20250508_043619-z5p2apf4</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/skaasyap-ucla/Language%20Model/runs/z5p2apf4' target=\"_blank\">neurips_gru_data_log_time_masked_lr_schedule_seed_8</a></strong> to <a href='https://wandb.ai/skaasyap-ucla/Language%20Model' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/skaasyap-ucla/Language%20Model' target=\"_blank\">https://wandb.ai/skaasyap-ucla/Language%20Model</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/skaasyap-ucla/Language%20Model/runs/z5p2apf4' target=\"_blank\">https://wandb.ai/skaasyap-ucla/Language%20Model/runs/z5p2apf4</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home3/skaasyap/willett/neural_seq_decoder/src/neural_decoder/load_models.py:128: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(pred[iterIdx, 0 : adjustedLens[iterIdx], :]),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ctc loss: 0.726974, cer: 0.159383\n",
      "880 880\n",
      "cer: (0.11716848872262375, 0.10799168892752098, 0.12648662794115534)\n",
      "wer: (0.17203127841425714, 0.15836888875650346, 0.18590816136828406)\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(model_name_list)):\n",
    "    \n",
    "    modelName = model_name_list[i]\n",
    "    modelPath = model_dir_list[i]\n",
    "    dataPath = data_path_list[i]\n",
    "    restricted_days = restricted_days_list[i]\n",
    "    print(f\"Runnning for {modelName}\")\n",
    "    \n",
    "    fullPath = f\"{modelPath}{modelName}\"\n",
    "    \n",
    "    args_file = os.path.join(fullPath, \"args\")\n",
    "    with open(args_file, \"rb\") as f:\n",
    "        args = pickle.load(f)\n",
    "\n",
    "    trainLoader, testLoader, loadedData = getDatasetLoaders(\n",
    "        dataPath,\n",
    "        batch_size,\n",
    "        restricted_days=restricted_days,\n",
    "    )\n",
    "\n",
    "    wandb.init(project=\"Language Model\", entity=\"skaasyap-ucla\", config=dict(args), name=modelName)\n",
    "\n",
    "    if(model_types_list[i] == 't'):\n",
    "        model, args = loadTransformerModel(fullPath)\n",
    "        model = model.to(device)\n",
    "        all_logits, trial_lengths, avgDayLoss, cer = run_forward(model, testLoader, device)\n",
    "        \n",
    "    else:\n",
    "        model, args = loadModel(fullPath, device=device)\n",
    "        model = model.to(device)\n",
    "        all_logits, trial_lengths, avgDayLoss, cer = original_forward(model, testLoader, device, comp=False)\n",
    "        \n",
    "    \n",
    "    all_logits = [l.cpu().numpy().astype('float32') for l in all_logits]\n",
    "    trial_lengths = [l.cpu().numpy().astype('int') for l in trial_lengths]\n",
    "    all_logits = [l for batch in all_logits for l in list(batch)]\n",
    "    trial_lengths = [l for batch in trial_lengths for l in list(batch)]\n",
    "    blank_penalty = np.log(2)\n",
    "    llm_outputs = run_ngram_model(all_logits, trial_lengths, ngramDecoder, blank_penalty)\n",
    "\n",
    "    print(len(llm_outputs), len(ground_truth_sentences))\n",
    "\n",
    "    for i in range(len(ground_truth_sentences)):\n",
    "        ground_truth_sentences[i] = ground_truth_sentences[i].strip()\n",
    "        llm_outputs[i] = llm_outputs[i].strip()\n",
    "\n",
    "    for i in range(len(ground_truth_sentences)):\n",
    "        ground_truth_sentences[i] = convert_sentence(ground_truth_sentences[i])\n",
    "\n",
    "    cer, wer = utils._cer_and_wer(llm_outputs, ground_truth_sentences, outputType='speech_sil', returnCI=True)\n",
    "\n",
    "    print(f\"cer: {cer}\") # cer average, confidence interval \n",
    "    print(f\"wer: {wer}\") #wer average, confidence interval\n",
    "    \n",
    "    wandb.log({'cer': cer, 'wer': wer})\n",
    "    \n",
    "    out_file = os.path.join(fullPath, \"llm_outputs\")   # no extension per your spec\n",
    "    os.makedirs(os.path.dirname(out_file), exist_ok=True)\n",
    "    with open(out_file, \"w\", encoding=\"utf-8\") as f:\n",
    "       f.write(\"\\n\".join(llm_outputs))   # one line per LLM output\n",
    "\n",
    "    out_file_stats = os.path.join(fullPath, \"stats\")\n",
    "    os.makedirs(os.path.dirname(out_file_stats), exist_ok=True)\n",
    "    with open(out_file_stats, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(str(cer) + '\\n')\n",
    "        f.write(str(wer) + '\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainLoader, testLoader, compLoader, loadedData = getDatasetLoadersLocal(\n",
    "        dataPath,\n",
    "        batch_size,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/home3/skaasyap/willett/data', \"rb\") as handle:\n",
    "    test = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n"
     ]
    }
   ],
   "source": [
    "test_comp = test['competition']\n",
    "print(len(test_comp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1])\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1])\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1])\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1])\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1])\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1])\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1])\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1])\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1])\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1])\n",
      "tensor([2, 2, 2, 2, 2, 2, 2, 2])\n",
      "tensor([2, 2, 2, 2, 2, 2, 2, 2])\n",
      "tensor([2, 2, 2, 2, 2, 2, 2, 2])\n",
      "tensor([2, 2, 2, 2, 2, 2, 2, 2])\n",
      "tensor([2, 2, 2, 2, 2, 2, 2, 2])\n",
      "tensor([2, 2, 2, 2, 2, 2, 2, 2])\n",
      "tensor([2, 2, 2, 2, 2, 2, 2, 2])\n",
      "tensor([2, 2, 2, 2, 2, 2, 2, 2])\n",
      "tensor([2, 2, 2, 2, 2, 2, 2, 2])\n",
      "tensor([2, 2, 2, 2, 2, 2, 2, 2])\n",
      "tensor([3, 3, 3, 3, 3, 3, 3, 3])\n",
      "tensor([3, 3, 3, 3, 3, 3, 3, 3])\n",
      "tensor([3, 3, 3, 3, 3, 3, 3, 3])\n",
      "tensor([3, 3, 3, 3, 3, 3, 3, 3])\n",
      "tensor([3, 3, 3, 3, 3, 3, 3, 3])\n",
      "tensor([3, 3, 3, 3, 3, 3, 3, 3])\n",
      "tensor([3, 3, 3, 3, 3, 3, 3, 3])\n",
      "tensor([3, 3, 3, 3, 3, 3, 3, 3])\n",
      "tensor([3, 3, 3, 3, 3, 3, 3, 3])\n",
      "tensor([3, 3, 3, 3, 3, 3, 3, 3])\n",
      "tensor([4, 4, 4, 4, 4, 4, 4, 4])\n",
      "tensor([4, 4, 4, 4, 4, 4, 4, 4])\n",
      "tensor([4, 4, 4, 4, 4, 4, 4, 4])\n",
      "tensor([4, 4, 4, 4, 4, 4, 4, 4])\n",
      "tensor([4, 4, 4, 4, 4, 4, 4, 4])\n",
      "tensor([4, 4, 4, 4, 4, 4, 4, 4])\n",
      "tensor([4, 4, 4, 4, 4, 4, 4, 4])\n",
      "tensor([4, 4, 4, 4, 4, 4, 4, 4])\n",
      "tensor([4, 4, 4, 4, 4, 4, 4, 4])\n",
      "tensor([4, 4, 4, 4, 4, 4, 4, 4])\n",
      "tensor([5, 5, 5, 5, 5, 5, 5, 5])\n",
      "tensor([5, 5, 5, 5, 5, 5, 5, 5])\n",
      "tensor([5, 5, 5, 5, 5, 5, 5, 5])\n",
      "tensor([5, 5, 5, 5, 5, 5, 5, 5])\n",
      "tensor([5, 5, 5, 5, 5, 5, 5, 5])\n",
      "tensor([5, 5, 5, 5, 5, 5, 5, 5])\n",
      "tensor([5, 5, 5, 5, 5, 5, 5, 5])\n",
      "tensor([5, 5, 5, 5, 5, 5, 5, 5])\n",
      "tensor([5, 5, 5, 5, 5, 5, 5, 5])\n",
      "tensor([5, 5, 5, 5, 5, 5, 5, 5])\n",
      "tensor([6, 6, 6, 6, 6, 6, 6, 6])\n",
      "tensor([6, 6, 6, 6, 6, 6, 6, 6])\n",
      "tensor([6, 6, 6, 6, 6, 6, 6, 6])\n",
      "tensor([6, 6, 6, 6, 6, 6, 6, 6])\n",
      "tensor([6, 6, 6, 6, 6, 6, 6, 6])\n",
      "tensor([6, 6, 6, 6, 6, 6, 6, 6])\n",
      "tensor([6, 6, 6, 6, 6, 6, 6, 6])\n",
      "tensor([6, 6, 6, 6, 6, 6, 6, 6])\n",
      "tensor([6, 6, 6, 6, 6, 6, 6, 6])\n",
      "tensor([6, 6, 6, 6, 6, 6, 6, 6])\n",
      "tensor([7, 7, 7, 7, 7, 7, 7, 7])\n",
      "tensor([7, 7, 7, 7, 7, 7, 7, 7])\n",
      "tensor([7, 7, 7, 7, 7, 7, 7, 7])\n",
      "tensor([7, 7, 7, 7, 7, 7, 7, 7])\n",
      "tensor([7, 7, 7, 7, 7, 7, 7, 7])\n",
      "tensor([7, 7, 7, 7, 7, 7, 7, 7])\n",
      "tensor([7, 7, 7, 7, 7, 7, 7, 7])\n",
      "tensor([7, 7, 7, 7, 7, 7, 7, 7])\n",
      "tensor([7, 7, 7, 7, 7, 7, 7, 7])\n",
      "tensor([7, 7, 7, 7, 7, 7, 7, 7])\n",
      "tensor([8, 8, 8, 8, 8, 8, 8, 8])\n",
      "tensor([8, 8, 8, 8, 8, 8, 8, 8])\n",
      "tensor([8, 8, 8, 8, 8, 8, 8, 8])\n",
      "tensor([8, 8, 8, 8, 8, 8, 8, 8])\n",
      "tensor([8, 8, 8, 8, 8, 8, 8, 8])\n",
      "tensor([8, 8, 8, 8, 8, 8, 8, 8])\n",
      "tensor([8, 8, 8, 8, 8, 8, 8, 8])\n",
      "tensor([8, 8, 8, 8, 8, 8, 8, 8])\n",
      "tensor([8, 8, 8, 8, 8, 8, 8, 8])\n",
      "tensor([8, 8, 8, 8, 8, 8, 8, 8])\n",
      "tensor([9, 9, 9, 9, 9, 9, 9, 9])\n",
      "tensor([9, 9, 9, 9, 9, 9, 9, 9])\n",
      "tensor([9, 9, 9, 9, 9, 9, 9, 9])\n",
      "tensor([9, 9, 9, 9, 9, 9, 9, 9])\n",
      "tensor([9, 9, 9, 9, 9, 9, 9, 9])\n",
      "tensor([9, 9, 9, 9, 9, 9, 9, 9])\n",
      "tensor([9, 9, 9, 9, 9, 9, 9, 9])\n",
      "tensor([9, 9, 9, 9, 9, 9, 9, 9])\n",
      "tensor([9, 9, 9, 9, 9, 9, 9, 9])\n",
      "tensor([9, 9, 9, 9, 9, 9, 9, 9])\n",
      "tensor([10, 10, 10, 10, 10, 10, 10, 10])\n",
      "tensor([10, 10, 10, 10, 10, 10, 10, 10])\n",
      "tensor([10, 10, 10, 10, 10, 10, 10, 10])\n",
      "tensor([10, 10, 10, 10, 10, 10, 10, 10])\n",
      "tensor([10, 10, 10, 10, 10, 10, 10, 10])\n",
      "tensor([10, 10, 10, 10, 10, 10, 10, 10])\n",
      "tensor([10, 10, 10, 10, 10, 10, 10, 10])\n",
      "tensor([10, 10, 10, 10, 10, 10, 10, 10])\n",
      "tensor([10, 10, 10, 10, 10, 10, 10, 10])\n",
      "tensor([10, 10, 10, 10, 10, 10, 10, 10])\n",
      "tensor([11, 11, 11, 11, 11, 11, 11, 11])\n",
      "tensor([11, 11, 11, 11, 11, 11, 11, 11])\n",
      "tensor([11, 11, 11, 11, 11, 11, 11, 11])\n",
      "tensor([11, 11, 11, 11, 11, 11, 11, 11])\n",
      "tensor([11, 11, 11, 11, 11, 11, 11, 11])\n",
      "tensor([11, 11, 11, 11, 11, 11, 11, 11])\n",
      "tensor([11, 11, 11, 11, 11, 11, 11, 11])\n",
      "tensor([11, 11, 11, 11, 11, 11, 11, 11])\n",
      "tensor([11, 11, 11, 11, 11, 11, 11, 11])\n",
      "tensor([11, 11, 11, 11, 11, 11, 11, 11])\n",
      "tensor([12, 12, 12, 12, 12, 12, 12, 12])\n",
      "tensor([12, 12, 12, 12, 12, 12, 12, 12])\n",
      "tensor([12, 12, 12, 12, 12, 12, 12, 12])\n",
      "tensor([12, 12, 12, 12, 12, 12, 12, 12])\n",
      "tensor([12, 12, 12, 12, 12, 12, 12, 12])\n",
      "tensor([12, 12, 12, 12, 12, 12, 12, 12])\n",
      "tensor([12, 12, 12, 12, 12, 12, 12, 12])\n",
      "tensor([12, 12, 12, 12, 12, 12, 12, 12])\n",
      "tensor([12, 12, 12, 12, 12, 12, 12, 12])\n",
      "tensor([12, 12, 12, 12, 12, 12, 12, 12])\n",
      "tensor([13, 13, 13, 13, 13, 13, 13, 13])\n",
      "tensor([13, 13, 13, 13, 13, 13, 13, 13])\n",
      "tensor([13, 13, 13, 13, 13, 13, 13, 13])\n",
      "tensor([13, 13, 13, 13, 13, 13, 13, 13])\n",
      "tensor([13, 13, 13, 13, 13, 13, 13, 13])\n",
      "tensor([13, 13, 13, 13, 13, 13, 13, 13])\n",
      "tensor([13, 13, 13, 13, 13, 13, 13, 13])\n",
      "tensor([13, 13, 13, 13, 13, 13, 13, 13])\n",
      "tensor([13, 13, 13, 13, 13, 13, 13, 13])\n",
      "tensor([13, 13, 13, 13, 13, 13, 13, 13])\n",
      "tensor([14, 14, 14, 14, 14, 14, 14, 14])\n",
      "tensor([14, 14, 14, 14, 14, 14, 14, 14])\n",
      "tensor([14, 14, 14, 14, 14, 14, 14, 14])\n",
      "tensor([14, 14, 14, 14, 14, 14, 14, 14])\n",
      "tensor([14, 14, 14, 14, 14, 14, 14, 14])\n",
      "tensor([14, 14, 14, 14, 14, 14, 14, 14])\n",
      "tensor([14, 14, 14, 14, 14, 14, 14, 14])\n",
      "tensor([14, 14, 14, 14, 14, 14, 14, 14])\n",
      "tensor([14, 14, 14, 14, 14, 14, 14, 14])\n",
      "tensor([14, 14, 14, 14, 14, 14, 14, 14])\n"
     ]
    }
   ],
   "source": [
    "for X, y, X_len, y_len, testDayIdx in compLoader:\n",
    "    print(testDayIdx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home3/skaasyap/willett/data_log_both\n"
     ]
    }
   ],
   "source": [
    "print(dataPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "fullPath = \"/home3/skaasyap/willett/speechBaseline4\"\n",
    "args_file = os.path.join(fullPath, \"args\")\n",
    "with open(args_file, \"rb\") as f:\n",
    "    args = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'outputDir': '/data/willett_data/outputs/speechBaseline4', 'datasetPath': '/data/willett_data/ptDecoder_ctc', 'seqLen': 150, 'maxTimeSeriesLen': 1200, 'batchSize': 64, 'lrStart': 0.02, 'lrEnd': 0.02, 'nUnits': 1024, 'nBatch': 10000, 'nLayers': 5, 'seed': 0, 'nClasses': 40, 'nInputFeatures': 256, 'dropout': 0.4, 'whiteNoiseSD': 0.8, 'constantOffsetSD': 0.2, 'gaussianSmoothWidth': 2.0, 'strideLen': 4, 'kernelLen': 32, 'bidirectional': True, 'l2_decay': 1e-05}\n"
     ]
    }
   ],
   "source": [
    "print(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Runnning for neurips_gru_datalog_lr_scheduler_seed_0\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">neurips_gru_datalog_lr_scheduler_seed_9</strong> at: <a href='https://wandb.ai/skaasyap-ucla/Language%20Model/runs/0s0xnrl0' target=\"_blank\">https://wandb.ai/skaasyap-ucla/Language%20Model/runs/0s0xnrl0</a><br> View project at: <a href='https://wandb.ai/skaasyap-ucla/Language%20Model' target=\"_blank\">https://wandb.ai/skaasyap-ucla/Language%20Model</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250508_024329-0s0xnrl0/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.9"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home3/skaasyap/willett/neural_seq_decoder/src/neural_decoder/wandb/run-20250508_025206-8a7751qh</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/skaasyap-ucla/Language%20Model/runs/8a7751qh' target=\"_blank\">neurips_gru_datalog_lr_scheduler_seed_0</a></strong> to <a href='https://wandb.ai/skaasyap-ucla/Language%20Model' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/skaasyap-ucla/Language%20Model' target=\"_blank\">https://wandb.ai/skaasyap-ucla/Language%20Model</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/skaasyap-ucla/Language%20Model/runs/8a7751qh' target=\"_blank\">https://wandb.ai/skaasyap-ucla/Language%20Model/runs/8a7751qh</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home3/skaasyap/willett/neural_seq_decoder/src/neural_decoder/load_models.py:128: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(pred[iterIdx, 0 : adjustedLens[iterIdx], :]),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ctc loss: 32.847910, cer: 2.810417\n",
      "1200 880\n",
      "Runnning for neurips_gru_datalog_lr_scheduler_seed_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m The nbformat package was not found. It is required to save notebook history.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">neurips_gru_datalog_lr_scheduler_seed_0</strong> at: <a href='https://wandb.ai/skaasyap-ucla/Language%20Model/runs/8a7751qh' target=\"_blank\">https://wandb.ai/skaasyap-ucla/Language%20Model/runs/8a7751qh</a><br> View project at: <a href='https://wandb.ai/skaasyap-ucla/Language%20Model' target=\"_blank\">https://wandb.ai/skaasyap-ucla/Language%20Model</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250508_025206-8a7751qh/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.9"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home3/skaasyap/willett/neural_seq_decoder/src/neural_decoder/wandb/run-20250508_025340-6w5xz704</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/skaasyap-ucla/Language%20Model/runs/6w5xz704' target=\"_blank\">neurips_gru_datalog_lr_scheduler_seed_1</a></strong> to <a href='https://wandb.ai/skaasyap-ucla/Language%20Model' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/skaasyap-ucla/Language%20Model' target=\"_blank\">https://wandb.ai/skaasyap-ucla/Language%20Model</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/skaasyap-ucla/Language%20Model/runs/6w5xz704' target=\"_blank\">https://wandb.ai/skaasyap-ucla/Language%20Model/runs/6w5xz704</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home3/skaasyap/willett/neural_seq_decoder/src/neural_decoder/load_models.py:128: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(pred[iterIdx, 0 : adjustedLens[iterIdx], :]),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ctc loss: 33.073574, cer: 2.814062\n",
      "1200 880\n",
      "Runnning for neurips_gru_datalog_lr_scheduler_seed_2\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">neurips_gru_datalog_lr_scheduler_seed_1</strong> at: <a href='https://wandb.ai/skaasyap-ucla/Language%20Model/runs/6w5xz704' target=\"_blank\">https://wandb.ai/skaasyap-ucla/Language%20Model/runs/6w5xz704</a><br> View project at: <a href='https://wandb.ai/skaasyap-ucla/Language%20Model' target=\"_blank\">https://wandb.ai/skaasyap-ucla/Language%20Model</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250508_025340-6w5xz704/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.9"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home3/skaasyap/willett/neural_seq_decoder/src/neural_decoder/wandb/run-20250508_025525-g6v6fbk6</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/skaasyap-ucla/Language%20Model/runs/g6v6fbk6' target=\"_blank\">neurips_gru_datalog_lr_scheduler_seed_2</a></strong> to <a href='https://wandb.ai/skaasyap-ucla/Language%20Model' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/skaasyap-ucla/Language%20Model' target=\"_blank\">https://wandb.ai/skaasyap-ucla/Language%20Model</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/skaasyap-ucla/Language%20Model/runs/g6v6fbk6' target=\"_blank\">https://wandb.ai/skaasyap-ucla/Language%20Model/runs/g6v6fbk6</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home3/skaasyap/willett/neural_seq_decoder/src/neural_decoder/load_models.py:128: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(pred[iterIdx, 0 : adjustedLens[iterIdx], :]),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ctc loss: 33.234466, cer: 2.818229\n",
      "1200 880\n",
      "Runnning for neurips_gru_datalog_lr_scheduler_seed_3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m The nbformat package was not found. It is required to save notebook history.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">neurips_gru_datalog_lr_scheduler_seed_2</strong> at: <a href='https://wandb.ai/skaasyap-ucla/Language%20Model/runs/g6v6fbk6' target=\"_blank\">https://wandb.ai/skaasyap-ucla/Language%20Model/runs/g6v6fbk6</a><br> View project at: <a href='https://wandb.ai/skaasyap-ucla/Language%20Model' target=\"_blank\">https://wandb.ai/skaasyap-ucla/Language%20Model</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250508_025525-g6v6fbk6/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.9"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home3/skaasyap/willett/neural_seq_decoder/src/neural_decoder/wandb/run-20250508_025703-iq8pp2bh</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/skaasyap-ucla/Language%20Model/runs/iq8pp2bh' target=\"_blank\">neurips_gru_datalog_lr_scheduler_seed_3</a></strong> to <a href='https://wandb.ai/skaasyap-ucla/Language%20Model' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/skaasyap-ucla/Language%20Model' target=\"_blank\">https://wandb.ai/skaasyap-ucla/Language%20Model</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/skaasyap-ucla/Language%20Model/runs/iq8pp2bh' target=\"_blank\">https://wandb.ai/skaasyap-ucla/Language%20Model/runs/iq8pp2bh</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home3/skaasyap/willett/neural_seq_decoder/src/neural_decoder/load_models.py:128: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(pred[iterIdx, 0 : adjustedLens[iterIdx], :]),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ctc loss: 32.971442, cer: 2.821979\n",
      "1200 880\n",
      "Runnning for neurips_gru_datalog_lr_scheduler_seed_4\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">neurips_gru_datalog_lr_scheduler_seed_3</strong> at: <a href='https://wandb.ai/skaasyap-ucla/Language%20Model/runs/iq8pp2bh' target=\"_blank\">https://wandb.ai/skaasyap-ucla/Language%20Model/runs/iq8pp2bh</a><br> View project at: <a href='https://wandb.ai/skaasyap-ucla/Language%20Model' target=\"_blank\">https://wandb.ai/skaasyap-ucla/Language%20Model</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250508_025703-iq8pp2bh/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.9"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home3/skaasyap/willett/neural_seq_decoder/src/neural_decoder/wandb/run-20250508_025842-wst3qmac</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/skaasyap-ucla/Language%20Model/runs/wst3qmac' target=\"_blank\">neurips_gru_datalog_lr_scheduler_seed_4</a></strong> to <a href='https://wandb.ai/skaasyap-ucla/Language%20Model' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/skaasyap-ucla/Language%20Model' target=\"_blank\">https://wandb.ai/skaasyap-ucla/Language%20Model</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/skaasyap-ucla/Language%20Model/runs/wst3qmac' target=\"_blank\">https://wandb.ai/skaasyap-ucla/Language%20Model/runs/wst3qmac</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home3/skaasyap/willett/neural_seq_decoder/src/neural_decoder/load_models.py:128: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(pred[iterIdx, 0 : adjustedLens[iterIdx], :]),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ctc loss: 32.992435, cer: 2.810938\n",
      "1200 880\n",
      "Runnning for neurips_gru_datalog_lr_scheduler_seed_5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m The nbformat package was not found. It is required to save notebook history.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">neurips_gru_datalog_lr_scheduler_seed_4</strong> at: <a href='https://wandb.ai/skaasyap-ucla/Language%20Model/runs/wst3qmac' target=\"_blank\">https://wandb.ai/skaasyap-ucla/Language%20Model/runs/wst3qmac</a><br> View project at: <a href='https://wandb.ai/skaasyap-ucla/Language%20Model' target=\"_blank\">https://wandb.ai/skaasyap-ucla/Language%20Model</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250508_025842-wst3qmac/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.9"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home3/skaasyap/willett/neural_seq_decoder/src/neural_decoder/wandb/run-20250508_030017-r59mb9pm</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/skaasyap-ucla/Language%20Model/runs/r59mb9pm' target=\"_blank\">neurips_gru_datalog_lr_scheduler_seed_5</a></strong> to <a href='https://wandb.ai/skaasyap-ucla/Language%20Model' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/skaasyap-ucla/Language%20Model' target=\"_blank\">https://wandb.ai/skaasyap-ucla/Language%20Model</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/skaasyap-ucla/Language%20Model/runs/r59mb9pm' target=\"_blank\">https://wandb.ai/skaasyap-ucla/Language%20Model/runs/r59mb9pm</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home3/skaasyap/willett/neural_seq_decoder/src/neural_decoder/load_models.py:128: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(pred[iterIdx, 0 : adjustedLens[iterIdx], :]),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ctc loss: 32.754993, cer: 2.819688\n",
      "1200 880\n",
      "Runnning for neurips_gru_datalog_lr_scheduler_seed_6\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">neurips_gru_datalog_lr_scheduler_seed_5</strong> at: <a href='https://wandb.ai/skaasyap-ucla/Language%20Model/runs/r59mb9pm' target=\"_blank\">https://wandb.ai/skaasyap-ucla/Language%20Model/runs/r59mb9pm</a><br> View project at: <a href='https://wandb.ai/skaasyap-ucla/Language%20Model' target=\"_blank\">https://wandb.ai/skaasyap-ucla/Language%20Model</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250508_030017-r59mb9pm/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.9"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home3/skaasyap/willett/neural_seq_decoder/src/neural_decoder/wandb/run-20250508_030201-qxqxpzx6</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/skaasyap-ucla/Language%20Model/runs/qxqxpzx6' target=\"_blank\">neurips_gru_datalog_lr_scheduler_seed_6</a></strong> to <a href='https://wandb.ai/skaasyap-ucla/Language%20Model' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/skaasyap-ucla/Language%20Model' target=\"_blank\">https://wandb.ai/skaasyap-ucla/Language%20Model</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/skaasyap-ucla/Language%20Model/runs/qxqxpzx6' target=\"_blank\">https://wandb.ai/skaasyap-ucla/Language%20Model/runs/qxqxpzx6</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home3/skaasyap/willett/neural_seq_decoder/src/neural_decoder/load_models.py:128: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(pred[iterIdx, 0 : adjustedLens[iterIdx], :]),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ctc loss: 32.661901, cer: 2.822812\n",
      "1200 880\n",
      "Runnning for neurips_gru_datalog_lr_scheduler_seed_7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m The nbformat package was not found. It is required to save notebook history.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">neurips_gru_datalog_lr_scheduler_seed_6</strong> at: <a href='https://wandb.ai/skaasyap-ucla/Language%20Model/runs/qxqxpzx6' target=\"_blank\">https://wandb.ai/skaasyap-ucla/Language%20Model/runs/qxqxpzx6</a><br> View project at: <a href='https://wandb.ai/skaasyap-ucla/Language%20Model' target=\"_blank\">https://wandb.ai/skaasyap-ucla/Language%20Model</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250508_030201-qxqxpzx6/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.9"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home3/skaasyap/willett/neural_seq_decoder/src/neural_decoder/wandb/run-20250508_030342-erctblut</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/skaasyap-ucla/Language%20Model/runs/erctblut' target=\"_blank\">neurips_gru_datalog_lr_scheduler_seed_7</a></strong> to <a href='https://wandb.ai/skaasyap-ucla/Language%20Model' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/skaasyap-ucla/Language%20Model' target=\"_blank\">https://wandb.ai/skaasyap-ucla/Language%20Model</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/skaasyap-ucla/Language%20Model/runs/erctblut' target=\"_blank\">https://wandb.ai/skaasyap-ucla/Language%20Model/runs/erctblut</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home3/skaasyap/willett/neural_seq_decoder/src/neural_decoder/load_models.py:128: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(pred[iterIdx, 0 : adjustedLens[iterIdx], :]),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ctc loss: 33.087695, cer: 2.823125\n",
      "1200 880\n",
      "Runnning for neurips_gru_datalog_lr_scheduler_seed_8\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">neurips_gru_datalog_lr_scheduler_seed_7</strong> at: <a href='https://wandb.ai/skaasyap-ucla/Language%20Model/runs/erctblut' target=\"_blank\">https://wandb.ai/skaasyap-ucla/Language%20Model/runs/erctblut</a><br> View project at: <a href='https://wandb.ai/skaasyap-ucla/Language%20Model' target=\"_blank\">https://wandb.ai/skaasyap-ucla/Language%20Model</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250508_030342-erctblut/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.9"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home3/skaasyap/willett/neural_seq_decoder/src/neural_decoder/wandb/run-20250508_030523-f1jccr64</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/skaasyap-ucla/Language%20Model/runs/f1jccr64' target=\"_blank\">neurips_gru_datalog_lr_scheduler_seed_8</a></strong> to <a href='https://wandb.ai/skaasyap-ucla/Language%20Model' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/skaasyap-ucla/Language%20Model' target=\"_blank\">https://wandb.ai/skaasyap-ucla/Language%20Model</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/skaasyap-ucla/Language%20Model/runs/f1jccr64' target=\"_blank\">https://wandb.ai/skaasyap-ucla/Language%20Model/runs/f1jccr64</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home3/skaasyap/willett/neural_seq_decoder/src/neural_decoder/load_models.py:128: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(pred[iterIdx, 0 : adjustedLens[iterIdx], :]),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ctc loss: 33.171315, cer: 2.819688\n",
      "1200 880\n",
      "Runnning for neurips_gru_datalog_lr_scheduler_seed_9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m The nbformat package was not found. It is required to save notebook history.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">neurips_gru_datalog_lr_scheduler_seed_8</strong> at: <a href='https://wandb.ai/skaasyap-ucla/Language%20Model/runs/f1jccr64' target=\"_blank\">https://wandb.ai/skaasyap-ucla/Language%20Model/runs/f1jccr64</a><br> View project at: <a href='https://wandb.ai/skaasyap-ucla/Language%20Model' target=\"_blank\">https://wandb.ai/skaasyap-ucla/Language%20Model</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250508_030523-f1jccr64/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.9"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home3/skaasyap/willett/neural_seq_decoder/src/neural_decoder/wandb/run-20250508_030657-5a26jsv4</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/skaasyap-ucla/Language%20Model/runs/5a26jsv4' target=\"_blank\">neurips_gru_datalog_lr_scheduler_seed_9</a></strong> to <a href='https://wandb.ai/skaasyap-ucla/Language%20Model' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/skaasyap-ucla/Language%20Model' target=\"_blank\">https://wandb.ai/skaasyap-ucla/Language%20Model</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/skaasyap-ucla/Language%20Model/runs/5a26jsv4' target=\"_blank\">https://wandb.ai/skaasyap-ucla/Language%20Model/runs/5a26jsv4</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home3/skaasyap/willett/neural_seq_decoder/src/neural_decoder/load_models.py:128: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(pred[iterIdx, 0 : adjustedLens[iterIdx], :]),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ctc loss: 33.221589, cer: 2.815729\n",
      "1200 880\n"
     ]
    }
   ],
   "source": [
    "# for i, (modelName, dataPath) in enumerate(zip(modelNames, dataPath_list)):\n",
    "\n",
    "modelPath = '/home3/skaasyap/willett/obi_models/outputs/'\n",
    "modelName_base = 'neurips_gru_data_log_time_masked_lr_schedule_seed_0'\n",
    "dataPath = '/home3/skaasyap/willett/data_log_both'\n",
    "model_types = []\n",
    "model_types.append('r')\n",
    "device = 'cuda:3'\n",
    "i=0\n",
    "\n",
    "for i in range(0, 10):\n",
    "    modelName = modelName_base + str(i)\n",
    "    print(f\"Runnning for {modelName}\")\n",
    "\n",
    "    fullPath = f\"{modelPath}{modelName}\"\n",
    "\n",
    "    args_file = os.path.join(fullPath, \"args\")\n",
    "    with open(args_file, \"rb\") as f:\n",
    "        args = pickle.load(f)\n",
    "        \n",
    "    trainLoader, testLoader, compLoader, loadedData = getDatasetLoadersLocal(\n",
    "        dataPath,\n",
    "        batch_size,\n",
    "    )\n",
    "\n",
    "    wandb.init(project=\"Language Model\", entity=\"skaasyap-ucla\", config=dict(args), name=modelName)\n",
    "\n",
    "    if(model_types[0] == 't'):\n",
    "        model, args = loadTransformerModel(fullPath)\n",
    "        model = model.to(device)\n",
    "        all_logits, trial_lengths, avgDayLoss, cer = run_forward(model, compLoader, device)\n",
    "        –\n",
    "    else:\n",
    "        model, args = loadModel(fullPath, device=device)\n",
    "        model = model.to(device)\n",
    "        all_logits, trial_lengths, avgDayLoss, cer = original_forward(model, compLoader, device, comp=True)\n",
    "        \n",
    "    all_logits = [l.cpu().numpy().astype('float32') for l in all_logits]\n",
    "    trial_lengths = [l.cpu().numpy().astype('int') for l in trial_lengths]\n",
    "    all_logits = [l for batch in all_logits for l in list(batch)]\n",
    "    trial_lengths = [l for batch in trial_lengths for l in list(batch)]\n",
    "    blank_penalty = np.log(2)\n",
    "    llm_outputs = run_ngram_model(all_logits, trial_lengths, ngramDecoder, blank_penalty)\n",
    "\n",
    "    print(len(llm_outputs), len(ground_truth_sentences))\n",
    "\n",
    "    for i in range(len(llm_outputs)):\n",
    "        # ground_truth_sentences[i] = ground_truth_sentences[i].strip()\n",
    "        llm_outputs[i] = llm_outputs[i].strip()\n",
    "\n",
    "    # for i in range(len(ground_truth_sentences)):\n",
    "    #     ground_truth_sentences[i] = convert_sentence(ground_truth_sentences[i])\n",
    "\n",
    "    # cer, wer = utils._cer_and_wer(llm_outputs, ground_truth_sentences, outputType='speech_sil', returnCI=True)\n",
    "\n",
    "    # print(f\"cer: {cer}\") # cer average, confidence interval \n",
    "    # print(f\"wer: {wer}\") #wer average, confidence interval\n",
    "\n",
    "    # wandb.log({'cer': cer, 'wer': wer})\n",
    "\n",
    "    out_file = os.path.join(fullPath, \"comp_outputs_rerun\")   # no extension per your spec\n",
    "    os.makedirs(os.path.dirname(out_file), exist_ok=True)\n",
    "    with open(out_file, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(\"\\n\".join(llm_outputs))   # one line per LLM output\n",
    "\n",
    "    # out_file_stats = os.path.join(fullPath, \"stats\")\n",
    "    # os.makedirs(os.path.dirname(out_file_stats), exist_ok=True)\n",
    "    # with open(out_file_stats, \"w\", encoding=\"utf-8\") as f:\n",
    "    #     f.write(str(cer) + '\\n')\n",
    "    #     f.write(str(wer) + '\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('/home3/skaasyap/willett/data_log_both_held_out_days', \"rb\") as handle:\n",
    "    loadedData = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['They do that here.', \"She's not feeling too great today.\", 'Much more crime than ever before.', 'How does this grab you.', \"With Jim's schedule.\", 'What do you want to do.', \"We didn't even call them.\", \"Venezuela has the world's largest oil reserves.\", 'When we decided to move.', \"What's it like from an artist's point of view?\", \"I don't think they're in a conspiracy.\", 'We get upgraded.', 'These are the voyages of the Starship Enterprise.', 'Sort of the ground level.', 'Are you a boy or a girl?', 'I would say about ten or fifteen years ago.', 'This is the first time.', 'I do pull for Chicago.', 'If you have a drug testing program.', 'A lot of people get convicted.', \"They're always laying people off.\", 'May of last year.', \"We've always gone to a lot of movies in our life.\", 'Our financial budget.', 'Sort of seems to be taking.', 'Is that putting too fine a point on it?', 'Make or break you.', 'That sort of stuff.', 'But this is usually not the case.', 'We are not real consistent with this.', 'He probably knows.', 'Especially if you write like papers.', 'You have to cut each thing.', 'Desperate times call for desperate measures.', 'In our particular situation.', \"When she realizes he's in the house.\", \"I want him back, but it's not my decision.\", 'In this stage of my life.', \"It's carbon so that makes sense.\", 'Do you all get together often.', 'For the first time in years, I began to feel joy.', 'Cats are pretty independent.', 'It just tells a story about life.', 'Opinion is going to be heard.', 'I guess about a week ago.', 'My mother worked.', \"Yes you can get an idea of what's going on.\", 'Heat oil in a medium pan over medium high heat.', 'Find someone and pay them to do it.', 'It was a decision he would come to regret.', 'So we put hers in.', 'I wanted to get out and see some things.', 'Which is a good idea.', 'Paid attention to them.', 'What is the vision for the future of this city?', 'However, that decision was overturned on appeal.', \"She's gone three mornings.\", 'A medical problem.', 'Take those subjects.', 'This is one of those things.', 'The freeze just got them.', 'When I go into the hot tub before I go swimming.', 'It was about five hundred pages.', 'That kind of calms him down for the most part.', 'What is the most enjoyable part of your job?', 'Feel free to use the color scheme of your choice.', \"It's not an easy decision to make.\", 'So, it should be an easy decision, right?', 'That was kind of fun.', \"You wouldn't know that.\", \"You don't have an annual fee there.\", \"When they recognize that it's their tax money.\", 'They thought it was too much of a bother.', 'The Southwest Medical Center.', 'I think sooner or later.', \"Got to see Pike's Peak.\", 'That was the one from California.', \"At this point, it's up in the air, he said.\", 'How did the situation get to this point?', 'When you find the right cookbook.', 'My taxes have gone up.', 'There were no other injuries in the collision.', 'So far, no casualties have been reported.', 'I like doing that part.', 'It just flew all over the place.', \"It's very hard to say.\", \"It's a pleasure to meet you.\", \"It wasn't like prekindergarten.\", \"So they'll stop me.\", 'That takes a lot of time.', 'It takes forever to get a call through.', 'It weighs less than the line.', \"I wouldn't want to spend more than two nights.\", 'Translated and edited by Voices of Ukraine.', 'One day would be sufficient.', \"I've had that happen.\", 'There are some smart ones out there.', 'The phase of the moon.', 'A six hundred dollar three piece suit.', 'A lot of companies are.', 'You realize why we were in the Middle East.', \"You don't use any credit cards.\", \"You're more fun though.\", 'She thought long and hard about this decision.', 'I bought it for cheaper.', 'Anyway, I hope you enjoy it as much as I do.', \"But I think I'd like it.\", 'A nursing home or anything.', 'Worked in fast food restaurants.', 'When I think of crime.', \"But it's well worth it and everything.\", \"I'm going to.\", 'Somebody quite young gets certain kinds of cancer.', 'He is also a member of the Royal Irish Academy.', \"It's because you've been there.\", \"It's a lot like camping.\", \"It's just me in the house.\", \"Senior citizen's home.\", 'How did we get to this point?', 'I see it go anywhere.', 'It was unusual, to say the least.', 'If I had a third one.', 'To what do I owe the pleasure of your company?', 'I guess I did not.', 'We will miss every once in a while.', 'What had gone on.', 'Better running automobiles.', 'That sounds real good.', 'I believe I would probably tend towards that.', 'My husband and all the men.', 'I think she loved that dog more than I did.', 'People do it for their children.', 'Everyone grow up and mature.', \"Anybody tries to hurt them I won't even blink.\", 'On the radiator behind the dresser.', 'We ended up watching it for a couple of hours.', 'I have an hour here.', 'Bunch of books that I read.', 'It was a pleasure talking to you.', 'Like any lottery.', \"I decided to do it I haven't talked before.\", \"He's almost a teenager.\", \"I think it's a little bit inefficient.\", 'There was some really nasty patronizing.', 'The kitchen table.', 'We will worry about who he is later.', 'I was in education and in administration.', \"He's gotten good service.\", 'Which leads me to my next point.', 'Especially with teenagers.', \"A lot of things we don't like.\", 'We change our rights with our social status.', 'That really adds up too.', \"We're close enough so they can do that.\", \"People seem to enjoy it, so it's a good thing.\", \"She'd much rather be here with me.\", 'I could do it now.', 'A decision is expected in August at the earliest.', \"They're just too weird to work on now.\", 'And what was the point of it all?', \"I just don't understand that.\", 'Gouging your eyes out.', 'He said what did you get a deal for?', 'That was all we ever saw.', \"We don't ever catch enough to eat.\", 'You have children I take it.', \"They won't take those.\", 'I like sound tracks a lot.', \"I'm calling you from work.\", 'They had chosen Santa Barbara.', \"He wouldn't really talk about it.\", 'Who was that with?', \"I'm also in Dallas.\", \"We're probably reaching a successful stage.\", 'What do you think about places?', 'It is just wonderful to talk to you.', 'Then other groups come in and do the services.', 'They had permanent tickets.', 'Harm or injury.', 'That concerned me.', 'You have to have a roof over your head.', 'Houston and San Antonio.', 'It was overnight.', 'What have you seen?', 'Moving around.', 'Came out around the first of the year.', \"They're not going to change that to meters.\", \"They're going to go on a cruise.\", 'I had to work in an elderly home.', \"If there's a game on.\", 'Which makes a difference.', \"There's no other way.\", 'Well that sounds wonderful.', \"Couldn't catch one to save your life.\", \"It's a real good concept.\", 'Do you have pets?', \"It's a miniature.\", \"I'm an engineer.\", 'It was very modern.', \"My mom's like I am.\", 'Whatever pop we drink.', 'It was an interesting theory.', 'Is it a way of raising the prices of illegal guns?', 'I feel the same way.', \"I don't think we gained any weight from it.\", 'I always wanted to go to school for nursing.', 'It seems like you get hit the worst.', 'On the south side is all glass.', 'You go outside and play.', \"I'm not sure about the name.\", \"Why don't you tell me about yours?\", \"It's situational.\", 'In the common areas and in the island.', \"If they're above the knee they turn into shorts.\", 'In a new house everything is white.', 'We have an eleven year old.', 'They were pretty much in good taste.', \"I wasn't really keeping count.\", 'Winning a sweepstakes.', \"I don't really know how to resolve this.\", 'Something back in the sixties.', 'I had a call the other day from Birmingham.', 'Running their country for them.', 'No income taxes in Texas.', 'I have many a time called him to come get me.', 'Where are they going to get the money?', 'At least in this country.', \"It means that I don't have to cook.\", 'Frequently purchase and read.', 'It was just so realistic.', \"God will take care of us when it's our time.\", 'I wish I could.', \"Don't overcook it though.\", 'Everybody is there to have a good time.', 'Neither kid likes to practice.', 'You know we have to think about that.', 'You had pretty good luck with one coat type paint.', 'I hope I never have to use them.', \"Wouldn't have the language barrier certainly.\", 'I agree with you.', 'Monday night is real good with me.', 'I just finally ended up going to see it.', 'A pretty significantly small number.', 'I would like my next car to have good gas mileage.', 'Actually I even understood it better.', \"They don't want it to change their lifestyle.\", 'Some of them were even better behaved.', 'Are you going to trade it in on this new one?', \"It's not industrial engineering.\", \"They're saying other people were.\", 'Driving for Thanksgiving.', 'He had a hot pad.', 'It would make me sick.', 'I was thrilled to death.', 'I just came in from outside.', 'Then we get out of that phase.', 'I know which one it is.', 'Which ones are you watching?', \"I don't think I would have insurance.\", 'He suddenly got sick.', \"I think that I don't.\", 'I do agree with you.', 'I guess I need to put it on paper and turn it in.', 'Cultural change within the management first.', 'Exercise is not supposed to do that to you.', 'The house is forty years old.', 'I am nervous in Dallas.', \"It's not that much of a bother really.\", 'They waited a couple years.', \"It's the other way around.\", 'Three hours difference.', 'Actually the Lions are pretty good.', 'In hospitals.', 'Survey system.', 'They consider it violent.', \"I've been there.\", 'At the higher echelons.', 'Your favorite inexpensive places.', 'I think they need that.', 'I have discovered that.', \"That's a great salad in summertime.\", 'My kids were quite small.', \"I haven't seen too many lately.\", 'I have fun doing it.', 'They cross pollinate just by bees.', \"He's written a lot of books.\", \"I'm just a regular looking guy.\", \"I think that's a possibility.\", 'We jumped in on the western tip.', 'We have a hot tub in the back.', \"Maybe we'll get your guy.\", 'As near as I could tell.', \"She didn't have to do anything anymore.\", 'I heard it on the radio.', 'Beyond a reasonable doubt.', 'Especially in the presidential elections.', 'She had to go back to work.', 'I got it right after high school.', 'I was going to say I always enjoyed that.', \"It's hard not to like it.\", 'Who did work back in nineteen eighty six?', 'At first that always kind of bothered me.', \"There's an employment problem.\", 'I think she has problems with that.', 'In rebellion against the United States.', \"That's kind of funny.\", 'You have to do something.', 'At night you can go walking in the shallows.', 'Tour sort of thing.', \"I think that's real dangerous.\", 'You have to really just get an accurate amount.', 'I remember when I was that age.', 'That gives us special time together too.', 'Except you get to taste the product instead.', \"I think you'll get a real kick out of it.\", 'Under the stands.', \"They're actually going to extend it.\", \"That's kind of a basic thing of economics.\", 'They need to make a living.', \"See that's the thing.\", 'No thinking involved.', \"Sometimes it doesn't work.\", 'They had people who did.', 'I want to take a few of these.', \"I certainly can't argue with that.\", 'Look at the statistics.', \"They just couldn't.\", 'His side of the family.', \"That's probably the worst.\", 'Neither one of us knew much about cars.', \"Our son's not as interested in it as our daughter.\", \"I have to say that I'm honestly for it.\", 'I have not been out of school that long.', \"It's really cute.\", 'The test is a booger.', \"I just didn't know.\", 'An undergraduate degree.', 'I was careful to keep her away.', \"It's been really good.\", 'You are the one who signed up.', 'Overcast and threatening rain all day.', 'What do you do?', 'Something besides license plates and tiddlywinks.', \"We don't listen to any elevator music at my house.\", \"We don't want them back this year.\", 'That sounds really nice.', \"We're heavy into that too.\", 'That is just personal feeling.', 'Children of my own.', \"I can't even remember.\", 'The little boy dies.', \"I've seen Pretty Woman and Dances With Wolves.\", 'It destroys their libido.', \"I've seen them on TV.\", 'I think that is an excellent program.', \"I'll stick with it while it's good.\", 'To make a little extra money.', 'I would much rather own my own home.', 'It loses it somewhere.', 'Who did you vote for?', \"It's hard for me to imagine that.\", 'When you stop to think of it.', 'How much coverage?', 'I used to watch Sixty Minutes as a matter of fact.', 'What good is that?', 'I remember one time up in Nashville.', 'It is very comfortable to drive.', 'After five years.', \"Down here I haven't fished much in Texas.\", \"I'd love to get used to that shotgun.\", 'How long have you been in this house?', 'Even at home here now.', \"I'd probably buy another.\", 'I just got a little booklet.', \"That's what I hear.\", 'He was friends with my children.', 'The stepping bike.', 'I have such a big army outside of my place.', \"You can't do that.\", 'We are really saving a lot of money.', 'How long are we supposed to talk for?', 'What kind of shoes do they wear down there?', 'I guess there are a few things around still.', 'It had to be done.', 'Once the children were grown.', 'You sort of play every now and then.', 'From what I can tell.', \"Not just some doctor's office somewhere.\", \"He's out of there.\", 'I was born in sixty seven.', 'Check our teeth once a year at least.', 'Is everything still pretty square?', \"Wasn't allowed to run a lawn mower.\", 'The organization can use the help too.', \"He couldn't even check the oil.\", 'For a hundred dollars.', \"That's always fun.\", \"He's been put away.\", \"I haven't really heard much about that recently.\", 'When the kids get older.', \"The victims' families and things.\", 'Being one of these late in life mothers.', 'The drug dealers.', \"My wife's mother is the only grandparent left.\", \"They're grown now.\", 'I have never skied before.', \"I don't know what we're going to do.\", \"It's second nature.\", 'Find out where the languages are.', \"We don't get to see too many.\", \"It's like a bullet going by.\", 'I mean lunch today was eighteen dollars.', \"It's really unfortunate.\", 'The next morning you want to take them out.', \"If the news we're getting is any good.\", 'If something goes wrong.', \"I haven't seen any.\", 'Used to chase each other all through the house.', \"You don't worry about them too much.\", 'That kind of gas mileage.', \"It really doesn't make any difference.\", 'I was born in Texas and I visited other areas.', 'I guess because I work quite a bit with lawyers.', \"I guess I haven't had that much experience.\", 'Reports and papers and that sort of thing.', 'Spending money that does not belong to them.', 'Does it have to be a special color?', \"That's the freedom of choice.\", \"I don't know too much about it.\", 'My son plays football.', 'See how the family liked it.', \"One's in college already.\", 'Were his civil rights violated?', 'It looks like it would be.', 'Doing laundry by hand and that kind of thing.', \"I don't want stubs in my lawn.\", 'We can keep that out of our minds.', 'Forms for his photography business.', 'We are seeing that here as well.', \"That's what made me happy.\"]\n"
     ]
    }
   ],
   "source": [
    "t = loadedData['test']\n",
    "print(t[0]['transcriptions'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainLoader, testLoader, loadedData = getDatasetLoadersLocal(\n",
    "    \"/home3/skaasyap/willett/data_log_both_held_out_days\",\n",
    "    batch_size,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'DataLoader' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mprint\u001b[39m(testLoader[\u001b[39m0\u001b[39;49m])\n",
      "\u001b[0;31mTypeError\u001b[0m: 'DataLoader' object is not subscriptable"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Runnning for neurips_gru_baseline_seed_seed_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home3/skaasyap/miniconda3/envs/willett/lib/python3.9/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3190.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "stack expects each tensor to be equal size, but got [224, 256] at entry 0 and [454, 256] at entry 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 35\u001b[0m\n\u001b[1;32m     31\u001b[0m test_ds \u001b[39m=\u001b[39m SpeechDataset([loadedData[partition][i]])\n\u001b[1;32m     32\u001b[0m test_loader \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mDataLoader(\n\u001b[1;32m     33\u001b[0m     test_ds, batch_size\u001b[39m=\u001b[39m\u001b[39m8\u001b[39m, shuffle\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, num_workers\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m\n\u001b[1;32m     34\u001b[0m )\n\u001b[0;32m---> 35\u001b[0m \u001b[39mfor\u001b[39;00m j, (X, y, X_len, y_len, _) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(test_loader):\n\u001b[1;32m     36\u001b[0m     X, y, X_len, y_len, dayIdx \u001b[39m=\u001b[39m (\n\u001b[1;32m     37\u001b[0m         X\u001b[39m.\u001b[39mto(device),\n\u001b[1;32m     38\u001b[0m         y\u001b[39m.\u001b[39mto(device),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     41\u001b[0m         torch\u001b[39m.\u001b[39mtensor([testDayIdx], dtype\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mint64)\u001b[39m.\u001b[39mto(device),\n\u001b[1;32m     42\u001b[0m     )\n\u001b[1;32m     43\u001b[0m     pred \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mforward(X, dayIdx)\n",
      "File \u001b[0;32m~/miniconda3/envs/willett/lib/python3.9/site-packages/torch/utils/data/dataloader.py:628\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    625\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    626\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    627\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 628\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[1;32m    629\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    630\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    631\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    632\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/miniconda3/envs/willett/lib/python3.9/site-packages/torch/utils/data/dataloader.py:671\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    669\u001b[0m \u001b[39mdef\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    670\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 671\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    672\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[1;32m    673\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/miniconda3/envs/willett/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py:61\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     60\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n\u001b[0;32m---> 61\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcollate_fn(data)\n",
      "File \u001b[0;32m~/miniconda3/envs/willett/lib/python3.9/site-packages/torch/utils/data/_utils/collate.py:265\u001b[0m, in \u001b[0;36mdefault_collate\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m    204\u001b[0m \u001b[39mdef\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mdefault_collate\u001b[39m(batch):\n\u001b[1;32m    205\u001b[0m \u001b[39m    \u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    206\u001b[0m \u001b[39m        Function that takes in a batch of data and puts the elements within the batch\u001b[39;00m\n\u001b[1;32m    207\u001b[0m \u001b[39m        into a tensor with an additional outer dimension - batch size. The exact output type can be\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    263\u001b[0m \u001b[39m            >>> default_collate(batch)  # Handle `CustomType` automatically\u001b[39;00m\n\u001b[1;32m    264\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 265\u001b[0m     \u001b[39mreturn\u001b[39;00m collate(batch, collate_fn_map\u001b[39m=\u001b[39;49mdefault_collate_fn_map)\n",
      "File \u001b[0;32m~/miniconda3/envs/willett/lib/python3.9/site-packages/torch/utils/data/_utils/collate.py:143\u001b[0m, in \u001b[0;36mcollate\u001b[0;34m(batch, collate_fn_map)\u001b[0m\n\u001b[1;32m    140\u001b[0m transposed \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(\u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39mbatch))  \u001b[39m# It may be accessed twice, so we use a list.\u001b[39;00m\n\u001b[1;32m    142\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(elem, \u001b[39mtuple\u001b[39m):\n\u001b[0;32m--> 143\u001b[0m     \u001b[39mreturn\u001b[39;00m [collate(samples, collate_fn_map\u001b[39m=\u001b[39mcollate_fn_map) \u001b[39mfor\u001b[39;00m samples \u001b[39min\u001b[39;00m transposed]  \u001b[39m# Backwards compatibility.\u001b[39;00m\n\u001b[1;32m    144\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    145\u001b[0m     \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/willett/lib/python3.9/site-packages/torch/utils/data/_utils/collate.py:143\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    140\u001b[0m transposed \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(\u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39mbatch))  \u001b[39m# It may be accessed twice, so we use a list.\u001b[39;00m\n\u001b[1;32m    142\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(elem, \u001b[39mtuple\u001b[39m):\n\u001b[0;32m--> 143\u001b[0m     \u001b[39mreturn\u001b[39;00m [collate(samples, collate_fn_map\u001b[39m=\u001b[39;49mcollate_fn_map) \u001b[39mfor\u001b[39;00m samples \u001b[39min\u001b[39;00m transposed]  \u001b[39m# Backwards compatibility.\u001b[39;00m\n\u001b[1;32m    144\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    145\u001b[0m     \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/willett/lib/python3.9/site-packages/torch/utils/data/_utils/collate.py:120\u001b[0m, in \u001b[0;36mcollate\u001b[0;34m(batch, collate_fn_map)\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[39mif\u001b[39;00m collate_fn_map \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    119\u001b[0m     \u001b[39mif\u001b[39;00m elem_type \u001b[39min\u001b[39;00m collate_fn_map:\n\u001b[0;32m--> 120\u001b[0m         \u001b[39mreturn\u001b[39;00m collate_fn_map[elem_type](batch, collate_fn_map\u001b[39m=\u001b[39;49mcollate_fn_map)\n\u001b[1;32m    122\u001b[0m     \u001b[39mfor\u001b[39;00m collate_type \u001b[39min\u001b[39;00m collate_fn_map:\n\u001b[1;32m    123\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(elem, collate_type):\n",
      "File \u001b[0;32m~/miniconda3/envs/willett/lib/python3.9/site-packages/torch/utils/data/_utils/collate.py:163\u001b[0m, in \u001b[0;36mcollate_tensor_fn\u001b[0;34m(batch, collate_fn_map)\u001b[0m\n\u001b[1;32m    161\u001b[0m     storage \u001b[39m=\u001b[39m elem\u001b[39m.\u001b[39mstorage()\u001b[39m.\u001b[39m_new_shared(numel, device\u001b[39m=\u001b[39melem\u001b[39m.\u001b[39mdevice)\n\u001b[1;32m    162\u001b[0m     out \u001b[39m=\u001b[39m elem\u001b[39m.\u001b[39mnew(storage)\u001b[39m.\u001b[39mresize_(\u001b[39mlen\u001b[39m(batch), \u001b[39m*\u001b[39m\u001b[39mlist\u001b[39m(elem\u001b[39m.\u001b[39msize()))\n\u001b[0;32m--> 163\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49mstack(batch, \u001b[39m0\u001b[39;49m, out\u001b[39m=\u001b[39;49mout)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: stack expects each tensor to be equal size, but got [224, 256] at entry 0 and [454, 256] at entry 1"
     ]
    }
   ],
   "source": [
    "with open('/home3/skaasyap/willett/data', \"rb\") as handle:\n",
    "    loadedData = pickle.load(handle)\n",
    "\n",
    "modelPath = '/home3/skaasyap/willett/obi_models/outputs/'\n",
    "modelName = 'neurips_gru_baseline_seed_seed_1'\n",
    "dataPath = '/home3/skaasyap/willett/data'\n",
    "model_types = []\n",
    "model_types.append('r')\n",
    "device = 'cuda:3'\n",
    "i=0\n",
    "print(f\"Runnning for {modelName}\")\n",
    "\n",
    "fullPath = f\"{modelPath}{modelName}\"\n",
    "\n",
    "args_file = os.path.join(fullPath, \"args\")\n",
    "with open(args_file, \"rb\") as f:\n",
    "    args = pickle.load(f)\n",
    "\n",
    "model, args = loadModel(fullPath, device=device)\n",
    "model = model.to(device)\n",
    "# all_logits, trial_lengths, avgDayLoss, cer = original_forward(model, compL, device)\n",
    "all_logits = []\n",
    "\n",
    "partition = \"competition\" # \"test\"\n",
    "if partition == \"competition\":\n",
    "    testDayIdxs = [4, 5, 6, 7, 8, 9, 10, 12, 13, 14, 15, 16, 18, 19, 20]\n",
    "elif partition == \"test\":\n",
    "    testDayIdxs = range(len(loadedData[partition]))\n",
    "\n",
    "for i, testDayIdx in enumerate(testDayIdxs):\n",
    "    test_ds = SpeechDataset([loadedData[partition][i]])\n",
    "    test_loader = torch.utils.data.DataLoader(\n",
    "        test_ds, batch_size=8, shuffle=False, num_workers=0\n",
    "    )\n",
    "    for j, (X, y, X_len, y_len, _) in enumerate(test_loader):\n",
    "        X, y, X_len, y_len, dayIdx = (\n",
    "            X.to(device),\n",
    "            y.to(device),\n",
    "            X_len.to(device),\n",
    "            y_len.to(device),\n",
    "            torch.tensor([testDayIdx], dtype=torch.int64).to(device),\n",
    "        )\n",
    "        pred = model.forward(X, dayIdx)\n",
    "        \n",
    "        all_logits.append(pred)\n",
    "\n",
    "\n",
    "all_logits = [l.cpu().numpy().astype('float32') for l in all_logits]\n",
    "trial_lengths = [l.cpu().numpy().astype('int') for l in trial_lengths]\n",
    "all_logits = [l for batch in all_logits for l in list(batch)]\n",
    "trial_lengths = [l for batch in trial_lengths for l in list(batch)]\n",
    "blank_penalty = np.log(2)\n",
    "llm_outputs = run_ngram_model(all_logits, trial_lengths, ngramDecoder, blank_penalty)\n",
    "\n",
    "print(len(llm_outputs), len(ground_truth_sentences))\n",
    "\n",
    "for i in range(len(llm_outputs)):\n",
    "    # ground_truth_sentences[i] = ground_truth_sentences[i].strip()\n",
    "    llm_outputs[i] = llm_outputs[i].strip()\n",
    "\n",
    "\n",
    "out_file = os.path.join(fullPath, \"comp_outputs_rerun\")   # no extension per your spec\n",
    "os.makedirs(os.path.dirname(out_file), exist_ok=True)\n",
    "with open(out_file, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(\"\\n\".join(llm_outputs)) \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function get_output() {\n",
    " if [ -z “$1” ]; then\n",
    "  echo “Usage: get_output <folder_name>”\n",
    "  return 1\n",
    " fi\n",
    " # Exclude both optimizer and optimizer_ctc files/directories\n",
    " # (Alternatively, use --exclude ‘optimizer*’ to match any name that starts with “optimizer”)\n",
    " rsync -av \\\n",
    "    --exclude ‘optimizer’ \\\n",
    "    --exclude ‘optimizer_ctc’ \\\n",
    "    skaasyap@obiwan.ee.ucla.edu:/data/willett_data/outputs/“$1\" \\\n",
    "    /Users/shrek/comp_outputs/\n",
    "}\n",
    "function send_output() {\n",
    " if [ -z “$1” ]; then\n",
    "  echo “Usage: send_output <folder_name>”\n",
    "  return 1\n",
    " fi\n",
    " scp -r /Users/shrek/comp_outputs/$1 skaasyap@leia.ee.ucla.edu:/home3/skaasyap/willett/outputs/\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "willett",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
