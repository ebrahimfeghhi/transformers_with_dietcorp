{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import time\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "from edit_distance import SequenceMatcher\n",
    "import torch\n",
    "from dataset import SpeechDataset\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from neural_decoder.dataset import getDatasetLoaders\n",
    "import neural_decoder.lm_utils as lmDecoderUtils\n",
    "from neural_decoder.model import GRUDecoder\n",
    "import pickle\n",
    "import argparse\n",
    "import matplotlib.pyplot as plt\n",
    "from neural_decoder.dataset import getDatasetLoaders\n",
    "import neural_decoder.lm_utils as lmDecoderUtils\n",
    "from neural_decoder.model import GRUDecoder\n",
    "from neural_decoder.bit import BiT_Phoneme\n",
    "import pickle\n",
    "import argparse\n",
    "from lm_utils import _cer_and_wer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_sentence(s):\n",
    "    s = s.lower()\n",
    "    charMarks = ['a','b','c','d','e','f','g','h','i','j','k','l','m','n','o','p','q','r','s','t','u','v','w','x','y','z',\n",
    "                 \"'\", ' ']\n",
    "    ans = []\n",
    "    for i in s:\n",
    "        if(i in charMarks):\n",
    "            ans.append(i)\n",
    "    \n",
    "    return ''.join(ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file = 'obi'\n",
    "base_dir = \"/home3/skaasyap/willett\"\n",
    "\n",
    "if output_file == 'obi':\n",
    "    model_storage_path = '/data/willett_data/outputs/'\n",
    "elif output_file == 'leia':\n",
    "    model_storage_path = '/data/willett_data/leia_outputs/'\n",
    "    \n",
    "device = 'cuda:0'\n",
    "load_lm = True\n",
    "# LM decoding hyperparameters\n",
    "acoustic_scale = 0.8\n",
    "blank_penalty = np.log(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "if load_lm: \n",
    "        \n",
    "    lmDir = base_dir +'/lm/languageModel'\n",
    "    ngramDecoder = lmDecoderUtils.build_lm_decoder(\n",
    "        lmDir,\n",
    "        acoustic_scale=acoustic_scale, #1.2\n",
    "        nbest=1,\n",
    "        beam=18\n",
    "    )\n",
    "    print(\"loaded LM\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get model predictions\n",
    "## Always check to make sure val perf matches wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading GRU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1143292/1382384046.py:145: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(pred[iterIdx, 0 : adjustedLens[iterIdx], :]),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model performance:  0.2184804589162643\n",
      "N-gram decoding took 0.08480333469130776 seconds per sample\n",
      "CER and WER after 3-gram LM:  (0.1512366977808448, 0.14072161265911193, 0.16212402124336683) (0.20531005637388616, 0.19118545381086435, 0.22002661907244062)\n"
     ]
    }
   ],
   "source": [
    "models_to_run = ['neurips_gru_baseline_seed_2']\n",
    "partition = \"test\" # \"test\"\n",
    "fill_max_day = False\n",
    "\n",
    "for model in models_to_run:\n",
    "    \n",
    "    modelPath = f\"{model_storage_path}{model}\"\n",
    "    \n",
    "    with open(modelPath + \"/args\", \"rb\") as handle:\n",
    "        args = pickle.load(handle)\n",
    "    \n",
    "    \n",
    "    if args['datasetPath'] == 'data_log_both':\n",
    "        data_file = 'ptDecoder_ctc_both'\n",
    "    elif args['datasetPath'] == 'data':\n",
    "        data_file = 'ptDecoder_ctc'\n",
    "    else:\n",
    "        data_file = args['datasetPath']\n",
    "    \n",
    "    trainLoaders, testLoaders, loadedData = getDatasetLoaders(\n",
    "        args[\"datasetPath\"], 8\n",
    "    )\n",
    "    \n",
    "    # if true, model is a GRU\n",
    "    if 'nInputFeatures' in args.keys():\n",
    "        \n",
    "        if 'max_mask_pct' not in args:\n",
    "            args['max_mask_pct'] = 0\n",
    "        if 'num_masks' not in args:\n",
    "            args['num_masks'] = 0\n",
    "        if 'input_dropout' not in args:\n",
    "            args['input_dropout'] = 0\n",
    "            \n",
    "        print(\"Loading GRU\")\n",
    "        model = GRUDecoder(\n",
    "            neural_dim=args[\"nInputFeatures\"],\n",
    "            n_classes=args[\"nClasses\"],\n",
    "            hidden_dim=args[\"nUnits\"],\n",
    "            layer_dim=args[\"nLayers\"],\n",
    "            nDays=args['nDays'],\n",
    "            dropout=args[\"dropout\"],\n",
    "            device=args[\"device\"],\n",
    "            strideLen=args[\"strideLen\"],\n",
    "            kernelLen=args[\"kernelLen\"],\n",
    "            gaussianSmoothWidth=args[\"gaussianSmoothWidth\"],\n",
    "            bidirectional=args[\"bidirectional\"],\n",
    "            input_dropout=args['input_dropout'], \n",
    "            max_mask_pct=args['max_mask_pct'],\n",
    "            num_masks=args['num_masks']\n",
    "        ).to(device)\n",
    "\n",
    "    else:\n",
    "        \n",
    "        if 'mask_token_zero' not in args:\n",
    "            args['mask_token_zero'] = False\n",
    "        \n",
    "        print(\"Loading TRANSFORMER\")\n",
    "        \n",
    "        # Instantiate model\n",
    "        model = BiT_Phoneme(\n",
    "            patch_size=args['patch_size'],\n",
    "            dim=args['dim'],\n",
    "            dim_head=args['dim_head'],\n",
    "            nClasses=args['nClasses'],\n",
    "            depth=args['depth'],\n",
    "            heads=args['heads'],\n",
    "            mlp_dim_ratio=args['mlp_dim_ratio'],\n",
    "            dropout=args['dropout'],\n",
    "            input_dropout=args['input_dropout'],\n",
    "            look_ahead=args['look_ahead'],\n",
    "            gaussianSmoothWidth=args['gaussianSmoothWidth'],\n",
    "            T5_style_pos=args['T5_style_pos'],\n",
    "            max_mask_pct=args['max_mask_pct'],\n",
    "            num_masks=args['num_masks'], \n",
    "            mask_token_zeros=args['mask_token_zero'], \n",
    "            num_masks_channels=0, \n",
    "            max_mask_channels=0, \n",
    "            dist_dict_path=0, \n",
    "        ).to(device)\n",
    "        \n",
    "        \n",
    "    ckpt_path = modelPath + '/modelWeights'\n",
    "    model.load_state_dict(torch.load(ckpt_path, map_location=device), strict=True)\n",
    "    \n",
    "    model.eval()\n",
    "\n",
    "    model_outputs = {\n",
    "        \"logits\": [],\n",
    "        \"logitLengths\": [],\n",
    "        \"trueSeqs\": [],\n",
    "        \"transcriptions\": [],\n",
    "    }\n",
    "    \n",
    "    total_edit_distance = 0\n",
    "    total_seq_length = 0\n",
    "\n",
    "    if partition == \"competition\":\n",
    "        testDayIdxs = [4, 5, 6, 7, 8, 9, 10, 12, 13, 14, 15, 16, 18, 19, 20]\n",
    "    elif partition == \"test\":\n",
    "        testDayIdxs = range(len(loadedData[partition])) \n",
    "        \n",
    "    ground_truth_sentences = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        \n",
    "        for i, testDayIdx in enumerate(testDayIdxs):\n",
    "            \n",
    "            test_ds = SpeechDataset([loadedData[partition][i]])\n",
    "            test_loader = torch.utils.data.DataLoader(\n",
    "                test_ds, batch_size=1, shuffle=False, num_workers=0\n",
    "            )\n",
    "            \n",
    "            for j, (X, y, X_len, y_len, _) in enumerate(test_loader):\n",
    "                        \n",
    "                X, y, X_len, y_len, dayIdx = (\n",
    "                    X.to(device),\n",
    "                    y.to(device),\n",
    "                    X_len.to(device),\n",
    "                    y_len.to(device),\n",
    "                    torch.tensor([testDayIdx], dtype=torch.int64).to(device),\n",
    "                )\n",
    "                \n",
    "                if fill_max_day:\n",
    "                    dayIdx.fill_(args['maxDay'])\n",
    "                \n",
    "                pred = model.forward(X, X_len, dayIdx)\n",
    "                \n",
    "                if hasattr(model, 'compute_length'):\n",
    "                    adjustedLens = model.compute_length(X_len)\n",
    "                else:\n",
    "                    adjustedLens = ((X_len - model.kernelLen) / model.strideLen).to(torch.int32)\n",
    "                    \n",
    "                for iterIdx in range(pred.shape[0]):\n",
    "                    trueSeq = np.array(y[iterIdx][0 : y_len[iterIdx]].cpu().detach())\n",
    "                    model_outputs[\"logits\"].append(pred[iterIdx].cpu().detach().numpy())\n",
    "                    \n",
    "                    model_outputs[\"logitLengths\"].append(\n",
    "                        adjustedLens[iterIdx].cpu().detach().item()\n",
    "                    )\n",
    "                    \n",
    "                    model_outputs[\"trueSeqs\"].append(trueSeq)\n",
    "                    \n",
    "                    decodedSeq = torch.argmax(\n",
    "                        torch.tensor(pred[iterIdx, 0 : adjustedLens[iterIdx], :]),\n",
    "                        dim=-1,\n",
    "                    ) \n",
    "                    \n",
    "                    decodedSeq = torch.unique_consecutive(decodedSeq, dim=-1)\n",
    "                    decodedSeq = decodedSeq.cpu().detach().numpy()\n",
    "                    decodedSeq = np.array([i for i in decodedSeq if i != 0])\n",
    "                    \n",
    "                    matcher = SequenceMatcher(\n",
    "                        a=trueSeq.tolist(), b=decodedSeq.tolist()\n",
    "                    )\n",
    "                    \n",
    "                    total_edit_distance += matcher.distance()\n",
    "                    total_seq_length += len(trueSeq)\n",
    "                    \n",
    "                transcript = loadedData[partition][i][\"transcriptions\"][j].strip()\n",
    "                transcript = re.sub(r\"[^a-zA-Z\\- \\']\", \"\", transcript)\n",
    "                transcript = transcript.replace(\"--\", \"\").lower()\n",
    "                model_outputs[\"transcriptions\"].append(transcript)\n",
    "\n",
    "        cer = total_edit_distance / total_seq_length\n",
    "        \n",
    "        print(\"Model performance: \", cer)\n",
    "\n",
    "        if load_lm:\n",
    "            \n",
    "            llm_outputs = []\n",
    "            start_t = time.time()\n",
    "            nbest_outputs = []\n",
    "            \n",
    "            for j in range(len(model_outputs[\"logits\"])):\n",
    "                \n",
    "                logits = model_outputs[\"logits\"][j]\n",
    "                \n",
    "                logits = np.concatenate(\n",
    "                    [logits[:, 1:], logits[:, 0:1]], axis=-1\n",
    "                )  # Blank is last token\n",
    "                \n",
    "                logits = lmDecoderUtils.rearrange_speech_logits(logits[None, :, :], has_sil=True)\n",
    "                \n",
    "                nbest = lmDecoderUtils.lm_decode(\n",
    "                    ngramDecoder,\n",
    "                    logits[0],\n",
    "                    blankPenalty=blank_penalty,\n",
    "                    returnNBest=False,\n",
    "                    rescore=False,\n",
    "                )\n",
    "                \n",
    "                nbest_outputs.append(nbest)\n",
    "                \n",
    "            time_per_sample = (time.time() - start_t) / len(model_outputs[\"logits\"])\n",
    "            print(f\"N-gram decoding took {time_per_sample} seconds per sample\")\n",
    "\n",
    "            #for i in range(len(model_outputs[\"transcriptions\"])):\n",
    "            #    new_trans = [ord(c) for c in model_outputs[\"transcriptions\"][i]] + [0]\n",
    "            #    model_outputs[\"transcriptions\"][i] = np.array(new_trans)\n",
    "                \n",
    "            for i in range(len(model_outputs[\"transcriptions\"])):\n",
    "                model_outputs[\"transcriptions\"][i] = model_outputs[\"transcriptions\"][i].strip()\n",
    "                nbest_outputs[i] = nbest_outputs[i].strip()\n",
    "            \n",
    "            # lower case + remove puncs\n",
    "            for i in range(len(model_outputs[\"transcriptions\"])):\n",
    "                model_outputs[\"transcriptions\"][i] = convert_sentence(model_outputs[\"transcriptions\"][i])\n",
    "\n",
    "            cer, wer = _cer_and_wer(nbest_outputs, model_outputs[\"transcriptions\"], \n",
    "                                outputType='speech', returnCI=True)\n",
    "\n",
    "            print(\"CER and WER after 3-gram LM: \", cer, wer)            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hello'"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = 'helLo.'\n",
    "convert_sentence(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'outputDir': '/data/willett_data/outputs/neurips_transformer_time_masked_seed_3',\n",
       " 'datasetPath': '/data/willett_data/ptDecoder_ctc_both',\n",
       " 'modelName': 'neurips_transformer_time_masked_seed_3',\n",
       " 'testing_on_held_out': False,\n",
       " 'maxDay': 15,\n",
       " 'restricted_days': [],\n",
       " 'patch_size': (5, 256),\n",
       " 'dim': 384,\n",
       " 'depth': 7,\n",
       " 'heads': 6,\n",
       " 'mlp_dim_ratio': 4,\n",
       " 'dim_head': 64,\n",
       " 'T5_style_pos': True,\n",
       " 'nClasses': 40,\n",
       " 'whiteNoiseSD': 0.2,\n",
       " 'gaussianSmoothWidth': 2.0,\n",
       " 'constantOffsetSD': 0.05,\n",
       " 'num_masks': 20,\n",
       " 'max_mask_pct': 0.075,\n",
       " 'l2_decay': 1e-05,\n",
       " 'input_dropout': 0.2,\n",
       " 'dropout': 0.35,\n",
       " 'AdamW': True,\n",
       " 'learning_scheduler': 'multistep',\n",
       " 'gamma': 0.1,\n",
       " 'lrStart': 0.001,\n",
       " 'lrEnd': 0.001,\n",
       " 'batchSize': 64,\n",
       " 'beta1': 0.9,\n",
       " 'beta2': 0.999,\n",
       " 'n_epochs': 600,\n",
       " 'milestones': [400],\n",
       " 'look_ahead': 0,\n",
       " 'extra_notes': '',\n",
       " 'device': 'cuda:0',\n",
       " 'seed': 3,\n",
       " 'load_pretrained_model': '',\n",
       " 'mask_token_zero': False}"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "speech-bci",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
