{
  "os": "Linux-6.8.0-1030-aws-x86_64-with-glibc2.35",
  "python": "CPython 3.11.13",
  "startedAt": "2025-08-08T18:55:37.321543Z",
  "program": "/home/ubuntu/transformers_with_dietcorp/src/neural_decoder/call_llama_finetuning.py",
  "codePath": "src/neural_decoder/call_llama_finetuning.py",
  "codePathLocal": "call_llama_finetuning.py",
  "git": {
    "remote": "https://github.com/ebrahimfeghhi/transformers_with_dietcorp.git",
    "commit": "e0cea83b03f9efc048167cd56c4de27776fc5b58"
  },
  "email": "efeghhi@gmail.com",
  "root": "/home/ubuntu/transformers_with_dietcorp/src/neural_decoder",
  "host": "ip-172-31-44-246",
  "executable": "/home/ubuntu/miniconda/envs/unsloth_env/bin/python",
  "cpu_count": 32,
  "cpu_count_logical": 64,
  "gpu": "NVIDIA L40S",
  "gpu_count": 1,
  "disk": {
    "/": {
      "total": "416055988224",
      "used": "364299907072"
    }
  },
  "memory": {
    "total": "533739081728"
  },
  "gpu_nvidia": [
    {
      "name": "NVIDIA L40S",
      "memoryTotal": "48305799168",
      "cudaCores": 18176,
      "architecture": "Ada",
      "uuid": "GPU-1085c5db-bd8c-c5bb-173a-59e756af5d86"
    }
  ],
  "cudaVersion": "12.4",
  "writerId": "xwu1tsebbdhhixvokpxomsddjk7vqq0i"
}